{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT prediction using transfer learning with AutoRT\n",
    "\n",
    "In this notebook, I will walk you through an example about transfer learning in AutoRT for accurate RT prediction using a small training data (5141 peptides). This is how users should use AutoRT in most cases.If there are variable modifications other than Oxidation on M in your dataset, you have to retrain the base model used by AutoRT in transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## install cuda library for tensorflow 2.5\n",
    "! conda install cudatoolkit=11.2\n",
    "! conda install -c fastchan cudnn=8.1.0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'AutoRT'...\n",
      "remote: Enumerating objects: 233, done.\u001b[K\n",
      "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
      "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
      "remote: Total 233 (delta 41), reused 24 (delta 12), pack-reused 148\u001b[K\n",
      "Receiving objects: 100% (233/233), 590.92 MiB | 61.52 MiB/s, done.\n",
      "Resolving deltas: 100% (107/107), done.\n",
      "Checking out files: 100% (41/41), done.\n",
      "total 4\n",
      "drwxr-xr-x 6 bw10 zhanglab 4096 Aug 19 16:06 AutoRT\n",
      "Requirement already satisfied: tensorflow==2.5.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from -r AutoRT/requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: matplotlib in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from -r AutoRT/requirements.txt (line 2)) (3.4.3)\n",
      "Requirement already satisfied: pandas in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from -r AutoRT/requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: scikit-learn in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from -r AutoRT/requirements.txt (line 4)) (0.24.2)\n",
      "Requirement already satisfied: numpy==1.19.2 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from -r AutoRT/requirements.txt (line 5)) (1.19.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (0.37.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (3.12.2)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.34.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from matplotlib->-r AutoRT/requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from matplotlib->-r AutoRT/requirements.txt (line 2)) (8.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from matplotlib->-r AutoRT/requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from matplotlib->-r AutoRT/requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from matplotlib->-r AutoRT/requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from pandas->-r AutoRT/requirements.txt (line 3)) (2020.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from scikit-learn->-r AutoRT/requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from scikit-learn->-r AutoRT/requirements.txt (line 4)) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from scikit-learn->-r AutoRT/requirements.txt (line 4)) (0.15.1)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: setuptools in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (47.3.1.post20200616)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.35.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (0.4.5)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.26.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/bw10/software/anaconda3/envs/autort/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->-r AutoRT/requirements.txt (line 1)) (3.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "## install AutoRT\n",
    "! git clone https://github.com/bzhanglab/AutoRT\n",
    "! ls -l -t\n",
    "! pip install -r AutoRT/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example dataset\n",
    "\n",
    "In this example, we will use a dataset used in the original AutoRT paper. It is from a label free dataset and all the peptides are from a single fraction. For MS/MS searching, a fixed modification of Carbamidomethyl (C) and a variable modifications of Oxidation (M) were used. Since all C amino acids were modified, we don't need to encode modified C in AutoRT. For amino acid M, there should have two versions in the dataset, so we need to encode modified M and unmodified M. We use \"M\" to represent unmodified M and use \"1\" to represent modified M (Oxidation [M]).This should be consistent with the encoding for modifications in the training data used for base models.\n",
    "\n",
    "The example data is in the folder **AutoRT/example/**: data/28CPTAC_COprospective_W_VU_20150810_05CO037_f01_normal_train.tsv\n",
    "\n",
    "Go to the folder **AutoRT/example/**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/wenbo/test/AutoRT/example\n"
     ]
    }
   ],
   "source": [
    "## go to the folder example\n",
    "%cd AutoRT/example/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all the data in the foler **AutoRT/example/**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\r\n",
      "drwxr-xr-x 2 bw10 zhanglab 4096 Aug 19 15:48 data\r\n",
      "-rw-r--r-- 1 bw10 zhanglab  385 Aug 19 15:48 train_model_from_scratch.sh\r\n",
      "-rw-r--r-- 1 bw10 zhanglab  362 Aug 19 15:48 transfer_learning.sh\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique peptides in the training data: 5141\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1APYQGPDAVPGALDYK</td>\n",
       "      <td>37.797092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1CCCSYNIGR</td>\n",
       "      <td>18.298540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1CFNYEIR</td>\n",
       "      <td>28.325425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1FLGDNAHLSIINEYLSQSYQK</td>\n",
       "      <td>61.661926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1GYAEEAPYDAIHVGAAAPVVPQALIDQLKPGGR</td>\n",
       "      <td>64.956116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    x          y\n",
       "0                   1APYQGPDAVPGALDYK  37.797092\n",
       "1                          1CCCSYNIGR  18.298540\n",
       "2                            1CFNYEIR  28.325425\n",
       "3              1FLGDNAHLSIINEYLSQSYQK  61.661926\n",
       "4  1GYAEEAPYDAIHVGAAAPVVPQALIDQLKPGGR  64.956116"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"data/28CPTAC_COprospective_W_VU_20150810_05CO037_f01_normal_train.tsv\",sep=\"\\t\")\n",
    "print(\"The number of unique peptides in the training data: %d\" % (train_data.shape[0]))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RT distribution in the training data is shown below. The unit of the RT in the data is minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"331.674375pt\" version=\"1.1\" viewBox=\"0 0 351.282059 331.674375\" width=\"351.282059pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 331.674375 \n",
       "L 351.282059 331.674375 \n",
       "L 351.282059 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 62.86875 294.118125 \n",
       "L 341.86875 294.118125 \n",
       "L 341.86875 22.318125 \n",
       "L 62.86875 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 75.550568 294.118125 \n",
       "L 80.623295 294.118125 \n",
       "L 80.623295 292.836654 \n",
       "L 75.550568 292.836654 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 80.623295 294.118125 \n",
       "L 85.696023 294.118125 \n",
       "L 85.696023 294.118125 \n",
       "L 80.623295 294.118125 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 85.696023 294.118125 \n",
       "L 90.76875 294.118125 \n",
       "L 90.76875 282.584886 \n",
       "L 85.696023 282.584886 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 90.76875 294.118125 \n",
       "L 95.841477 294.118125 \n",
       "L 95.841477 246.703698 \n",
       "L 90.76875 246.703698 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_7\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 95.841477 294.118125 \n",
       "L 100.914205 294.118125 \n",
       "L 100.914205 213.385452 \n",
       "L 95.841477 213.385452 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 100.914205 294.118125 \n",
       "L 105.986932 294.118125 \n",
       "L 105.986932 185.19309 \n",
       "L 100.914205 185.19309 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 105.986932 294.118125 \n",
       "L 111.059659 294.118125 \n",
       "L 111.059659 181.348677 \n",
       "L 105.986932 181.348677 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 111.059659 294.118125 \n",
       "L 116.132386 294.118125 \n",
       "L 116.132386 146.74896 \n",
       "L 111.059659 146.74896 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 116.132386 294.118125 \n",
       "L 121.205114 294.118125 \n",
       "L 121.205114 142.904546 \n",
       "L 116.132386 142.904546 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 121.205114 294.118125 \n",
       "L 126.277841 294.118125 \n",
       "L 126.277841 105.741887 \n",
       "L 121.205114 105.741887 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 126.277841 294.118125 \n",
       "L 131.350568 294.118125 \n",
       "L 131.350568 100.616003 \n",
       "L 126.277841 100.616003 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 131.350568 294.118125 \n",
       "L 136.423295 294.118125 \n",
       "L 136.423295 86.519822 \n",
       "L 131.350568 86.519822 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 136.423295 294.118125 \n",
       "L 141.496023 294.118125 \n",
       "L 141.496023 58.32746 \n",
       "L 136.423295 58.32746 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 141.496023 294.118125 \n",
       "L 146.56875 294.118125 \n",
       "L 146.56875 35.260982 \n",
       "L 141.496023 35.260982 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_17\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 146.56875 294.118125 \n",
       "L 151.641477 294.118125 \n",
       "L 151.641477 81.393938 \n",
       "L 146.56875 81.393938 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 151.641477 294.118125 \n",
       "L 156.714205 294.118125 \n",
       "L 156.714205 113.430713 \n",
       "L 151.641477 113.430713 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_19\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 156.714205 294.118125 \n",
       "L 161.786932 294.118125 \n",
       "L 161.786932 74.986583 \n",
       "L 156.714205 74.986583 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_20\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 161.786932 294.118125 \n",
       "L 166.859659 294.118125 \n",
       "L 166.859659 50.638634 \n",
       "L 161.786932 50.638634 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_21\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 166.859659 294.118125 \n",
       "L 171.932386 294.118125 \n",
       "L 171.932386 76.268054 \n",
       "L 166.859659 76.268054 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_22\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 171.932386 294.118125 \n",
       "L 177.005114 294.118125 \n",
       "L 177.005114 104.460416 \n",
       "L 171.932386 104.460416 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_23\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 177.005114 294.118125 \n",
       "L 182.077841 294.118125 \n",
       "L 182.077841 68.579228 \n",
       "L 177.005114 68.579228 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_24\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 182.077841 294.118125 \n",
       "L 187.150568 294.118125 \n",
       "L 187.150568 89.082764 \n",
       "L 182.077841 89.082764 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_25\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 187.150568 294.118125 \n",
       "L 192.223295 294.118125 \n",
       "L 192.223295 53.201576 \n",
       "L 187.150568 53.201576 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_26\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 192.223295 294.118125 \n",
       "L 197.296023 294.118125 \n",
       "L 197.296023 91.645706 \n",
       "L 192.223295 91.645706 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_27\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 197.296023 294.118125 \n",
       "L 202.36875 294.118125 \n",
       "L 202.36875 77.549525 \n",
       "L 197.296023 77.549525 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_28\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 202.36875 294.118125 \n",
       "L 207.441477 294.118125 \n",
       "L 207.441477 80.112467 \n",
       "L 202.36875 80.112467 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_29\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 207.441477 294.118125 \n",
       "L 212.514205 294.118125 \n",
       "L 212.514205 77.549525 \n",
       "L 207.441477 77.549525 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_30\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 212.514205 294.118125 \n",
       "L 217.586932 294.118125 \n",
       "L 217.586932 78.830996 \n",
       "L 212.514205 78.830996 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_31\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 217.586932 294.118125 \n",
       "L 222.659659 294.118125 \n",
       "L 222.659659 101.897474 \n",
       "L 217.586932 101.897474 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_32\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 222.659659 294.118125 \n",
       "L 227.732386 294.118125 \n",
       "L 227.732386 105.741887 \n",
       "L 222.659659 105.741887 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_33\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 227.732386 294.118125 \n",
       "L 232.805114 294.118125 \n",
       "L 232.805114 118.556597 \n",
       "L 227.732386 118.556597 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_34\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 232.805114 294.118125 \n",
       "L 237.877841 294.118125 \n",
       "L 237.877841 154.437786 \n",
       "L 232.805114 154.437786 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_35\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 237.877841 294.118125 \n",
       "L 242.950568 294.118125 \n",
       "L 242.950568 174.941322 \n",
       "L 237.877841 174.941322 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_36\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 242.950568 294.118125 \n",
       "L 248.023295 294.118125 \n",
       "L 248.023295 149.311902 \n",
       "L 242.950568 149.311902 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_37\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 248.023295 294.118125 \n",
       "L 253.096023 294.118125 \n",
       "L 253.096023 158.282199 \n",
       "L 248.023295 158.282199 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_38\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 253.096023 294.118125 \n",
       "L 258.16875 294.118125 \n",
       "L 258.16875 178.785735 \n",
       "L 253.096023 178.785735 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_39\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 258.16875 294.118125 \n",
       "L 263.241477 294.118125 \n",
       "L 263.241477 198.0078 \n",
       "L 258.16875 198.0078 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_40\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 263.241477 294.118125 \n",
       "L 268.314205 294.118125 \n",
       "L 268.314205 195.444858 \n",
       "L 263.241477 195.444858 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_41\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 268.314205 294.118125 \n",
       "L 273.386932 294.118125 \n",
       "L 273.386932 221.074278 \n",
       "L 268.314205 221.074278 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_42\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 273.386932 294.118125 \n",
       "L 278.459659 294.118125 \n",
       "L 278.459659 224.918691 \n",
       "L 273.386932 224.918691 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_43\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 278.459659 294.118125 \n",
       "L 283.532386 294.118125 \n",
       "L 283.532386 231.326046 \n",
       "L 278.459659 231.326046 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_44\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 283.532386 294.118125 \n",
       "L 288.605114 294.118125 \n",
       "L 288.605114 232.607517 \n",
       "L 283.532386 232.607517 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_45\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 288.605114 294.118125 \n",
       "L 293.677841 294.118125 \n",
       "L 293.677841 251.829582 \n",
       "L 288.605114 251.829582 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_46\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 293.677841 294.118125 \n",
       "L 298.750568 294.118125 \n",
       "L 298.750568 264.644292 \n",
       "L 293.677841 264.644292 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_47\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 298.750568 294.118125 \n",
       "L 303.823295 294.118125 \n",
       "L 303.823295 263.362821 \n",
       "L 298.750568 263.362821 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_48\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 303.823295 294.118125 \n",
       "L 308.896023 294.118125 \n",
       "L 308.896023 272.333118 \n",
       "L 303.823295 272.333118 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_49\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 308.896023 294.118125 \n",
       "L 313.96875 294.118125 \n",
       "L 313.96875 281.303415 \n",
       "L 308.896023 281.303415 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_50\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 313.96875 294.118125 \n",
       "L 319.041477 294.118125 \n",
       "L 319.041477 290.273712 \n",
       "L 313.96875 290.273712 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_51\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 319.041477 294.118125 \n",
       "L 324.114205 294.118125 \n",
       "L 324.114205 290.273712 \n",
       "L 319.041477 290.273712 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_52\">\n",
       "    <path clip-path=\"url(#p8440cefe77)\" d=\"M 324.114205 294.118125 \n",
       "L 329.186932 294.118125 \n",
       "L 329.186932 268.488705 \n",
       "L 324.114205 268.488705 \n",
       "z\n",
       "\" style=\"fill:#008000;opacity:0.75;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 74.022788 294.118125 \n",
       "L 74.022788 22.318125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"mabe96268bd\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"74.022788\" xlink:href=\"#mabe96268bd\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(70.841538 308.716563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 126.125892 294.118125 \n",
       "L 126.125892 22.318125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"126.125892\" xlink:href=\"#mabe96268bd\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(119.763392 308.716563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 178.228996 294.118125 \n",
       "L 178.228996 22.318125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"178.228996\" xlink:href=\"#mabe96268bd\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <defs>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(171.866496 308.716563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 230.332101 294.118125 \n",
       "L 230.332101 22.318125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.332101\" xlink:href=\"#mabe96268bd\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(223.969601 308.716563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 282.435205 294.118125 \n",
       "L 282.435205 22.318125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"282.435205\" xlink:href=\"#mabe96268bd\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(276.072705 308.716563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 334.538309 294.118125 \n",
       "L 334.538309 22.318125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"334.538309\" xlink:href=\"#mabe96268bd\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 100 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(324.994559 308.716563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- RT (minute) -->\n",
       "     <defs>\n",
       "      <path d=\"M 44.390625 34.1875 \n",
       "Q 47.5625 33.109375 50.5625 29.59375 \n",
       "Q 53.5625 26.078125 56.59375 19.921875 \n",
       "L 66.609375 0 \n",
       "L 56 0 \n",
       "L 46.6875 18.703125 \n",
       "Q 43.0625 26.03125 39.671875 28.421875 \n",
       "Q 36.28125 30.8125 30.421875 30.8125 \n",
       "L 19.671875 30.8125 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "L 9.8125 72.90625 \n",
       "L 32.078125 72.90625 \n",
       "Q 44.578125 72.90625 50.734375 67.671875 \n",
       "Q 56.890625 62.453125 56.890625 51.90625 \n",
       "Q 56.890625 45.015625 53.6875 40.46875 \n",
       "Q 50.484375 35.9375 44.390625 34.1875 \n",
       "z\n",
       "M 19.671875 64.796875 \n",
       "L 19.671875 38.921875 \n",
       "L 32.078125 38.921875 \n",
       "Q 39.203125 38.921875 42.84375 42.21875 \n",
       "Q 46.484375 45.515625 46.484375 51.90625 \n",
       "Q 46.484375 58.296875 42.84375 61.546875 \n",
       "Q 39.203125 64.796875 32.078125 64.796875 \n",
       "z\n",
       "\" id=\"DejaVuSans-82\"/>\n",
       "      <path d=\"M -0.296875 72.90625 \n",
       "L 61.375 72.90625 \n",
       "L 61.375 64.59375 \n",
       "L 35.5 64.59375 \n",
       "L 35.5 0 \n",
       "L 25.59375 0 \n",
       "L 25.59375 64.59375 \n",
       "L -0.296875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-84\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "      <path d=\"M 31 75.875 \n",
       "Q 24.46875 64.65625 21.28125 53.65625 \n",
       "Q 18.109375 42.671875 18.109375 31.390625 \n",
       "Q 18.109375 20.125 21.3125 9.0625 \n",
       "Q 24.515625 -2 31 -13.1875 \n",
       "L 23.1875 -13.1875 \n",
       "Q 15.875 -1.703125 12.234375 9.375 \n",
       "Q 8.59375 20.453125 8.59375 31.390625 \n",
       "Q 8.59375 42.28125 12.203125 53.3125 \n",
       "Q 15.828125 64.359375 23.1875 75.875 \n",
       "z\n",
       "\" id=\"DejaVuSans-40\"/>\n",
       "      <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "      <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "      <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-117\"/>\n",
       "      <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "      <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "      <path d=\"M 8.015625 75.875 \n",
       "L 15.828125 75.875 \n",
       "Q 23.140625 64.359375 26.78125 53.3125 \n",
       "Q 30.421875 42.28125 30.421875 31.390625 \n",
       "Q 30.421875 20.453125 26.78125 9.375 \n",
       "Q 23.140625 -1.703125 15.828125 -13.1875 \n",
       "L 8.015625 -13.1875 \n",
       "Q 14.5 -2 17.703125 9.0625 \n",
       "Q 20.90625 20.125 20.90625 31.390625 \n",
       "Q 20.90625 42.671875 17.703125 53.65625 \n",
       "Q 14.5 64.65625 8.015625 75.875 \n",
       "z\n",
       "\" id=\"DejaVuSans-41\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(172.721875 322.394687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-82\"/>\n",
       "      <use x=\"69.373047\" xlink:href=\"#DejaVuSans-84\"/>\n",
       "      <use x=\"130.457031\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"162.244141\" xlink:href=\"#DejaVuSans-40\"/>\n",
       "      <use x=\"201.257812\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "      <use x=\"298.669922\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"326.453125\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"389.832031\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "      <use x=\"453.210938\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"492.419922\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"553.943359\" xlink:href=\"#DejaVuSans-41\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 62.86875 294.118125 \n",
       "L 341.86875 294.118125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m7f11622ef6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m7f11622ef6\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.0000 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 297.917344)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 62.86875 262.04773 \n",
       "L 341.86875 262.04773 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m7f11622ef6\" y=\"262.04773\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.0025 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 265.846949)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 62.86875 229.977335 \n",
       "L 341.86875 229.977335 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m7f11622ef6\" y=\"229.977335\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.0050 -->\n",
       "      <g transform=\"translate(20.878125 233.776554)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 62.86875 197.906941 \n",
       "L 341.86875 197.906941 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m7f11622ef6\" y=\"197.906941\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.0075 -->\n",
       "      <defs>\n",
       "       <path d=\"M 8.203125 72.90625 \n",
       "L 55.078125 72.90625 \n",
       "L 55.078125 68.703125 \n",
       "L 28.609375 0 \n",
       "L 18.3125 0 \n",
       "L 43.21875 64.59375 \n",
       "L 8.203125 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-55\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 201.706159)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 62.86875 165.836546 \n",
       "L 341.86875 165.836546 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m7f11622ef6\" y=\"165.836546\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.0100 -->\n",
       "      <g transform=\"translate(20.878125 169.635765)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 62.86875 133.766151 \n",
       "L 341.86875 133.766151 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m7f11622ef6\" y=\"133.766151\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.0125 -->\n",
       "      <g transform=\"translate(20.878125 137.56537)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 62.86875 101.695756 \n",
       "L 341.86875 101.695756 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_26\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m7f11622ef6\" y=\"101.695756\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.0150 -->\n",
       "      <g transform=\"translate(20.878125 105.494975)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 62.86875 69.625362 \n",
       "L 341.86875 69.625362 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_28\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m7f11622ef6\" y=\"69.625362\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.0175 -->\n",
       "      <g transform=\"translate(20.878125 73.42458)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <path clip-path=\"url(#p8440cefe77)\" d=\"M 62.86875 37.554967 \n",
       "L 341.86875 37.554967 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_30\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m7f11622ef6\" y=\"37.554967\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 0.0200 -->\n",
       "      <g transform=\"translate(20.878125 41.354186)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- Density -->\n",
       "     <defs>\n",
       "      <path d=\"M 19.671875 64.796875 \n",
       "L 19.671875 8.109375 \n",
       "L 31.59375 8.109375 \n",
       "Q 46.6875 8.109375 53.6875 14.9375 \n",
       "Q 60.6875 21.78125 60.6875 36.53125 \n",
       "Q 60.6875 51.171875 53.6875 57.984375 \n",
       "Q 46.6875 64.796875 31.59375 64.796875 \n",
       "z\n",
       "M 9.8125 72.90625 \n",
       "L 30.078125 72.90625 \n",
       "Q 51.265625 72.90625 61.171875 64.09375 \n",
       "Q 71.09375 55.28125 71.09375 36.53125 \n",
       "Q 71.09375 17.671875 61.125 8.828125 \n",
       "Q 51.171875 0 30.078125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-68\"/>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "      <path d=\"M 32.171875 -5.078125 \n",
       "Q 28.375 -14.84375 24.75 -17.8125 \n",
       "Q 21.140625 -20.796875 15.09375 -20.796875 \n",
       "L 7.90625 -20.796875 \n",
       "L 7.90625 -13.28125 \n",
       "L 13.1875 -13.28125 \n",
       "Q 16.890625 -13.28125 18.9375 -11.515625 \n",
       "Q 21 -9.765625 23.484375 -3.21875 \n",
       "L 25.09375 0.875 \n",
       "L 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 11.921875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-121\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(14.798438 177.226719)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"77.001953\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"138.525391\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"201.904297\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"254.003906\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"281.787109\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"320.996094\" xlink:href=\"#DejaVuSans-121\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_53\">\n",
       "    <path d=\"M 62.86875 294.118125 \n",
       "L 62.86875 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_54\">\n",
       "    <path d=\"M 341.86875 294.118125 \n",
       "L 341.86875 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_55\">\n",
       "    <path d=\"M 62.86875 294.118125 \n",
       "L 341.86875 294.118125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_56\">\n",
       "    <path d=\"M 62.86875 22.318125 \n",
       "L 341.86875 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_18\">\n",
       "    <!-- Histogram of RT -->\n",
       "    <defs>\n",
       "     <path d=\"M 9.8125 72.90625 \n",
       "L 19.671875 72.90625 \n",
       "L 19.671875 43.015625 \n",
       "L 55.515625 43.015625 \n",
       "L 55.515625 72.90625 \n",
       "L 65.375 72.90625 \n",
       "L 65.375 0 \n",
       "L 55.515625 0 \n",
       "L 55.515625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-72\"/>\n",
       "     <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "     <path d=\"M 45.40625 27.984375 \n",
       "Q 45.40625 37.75 41.375 43.109375 \n",
       "Q 37.359375 48.484375 30.078125 48.484375 \n",
       "Q 22.859375 48.484375 18.828125 43.109375 \n",
       "Q 14.796875 37.75 14.796875 27.984375 \n",
       "Q 14.796875 18.265625 18.828125 12.890625 \n",
       "Q 22.859375 7.515625 30.078125 7.515625 \n",
       "Q 37.359375 7.515625 41.375 12.890625 \n",
       "Q 45.40625 18.265625 45.40625 27.984375 \n",
       "z\n",
       "M 54.390625 6.78125 \n",
       "Q 54.390625 -7.171875 48.1875 -13.984375 \n",
       "Q 42 -20.796875 29.203125 -20.796875 \n",
       "Q 24.46875 -20.796875 20.265625 -20.09375 \n",
       "Q 16.0625 -19.390625 12.109375 -17.921875 \n",
       "L 12.109375 -9.1875 \n",
       "Q 16.0625 -11.328125 19.921875 -12.34375 \n",
       "Q 23.78125 -13.375 27.78125 -13.375 \n",
       "Q 36.625 -13.375 41.015625 -8.765625 \n",
       "Q 45.40625 -4.15625 45.40625 5.171875 \n",
       "L 45.40625 9.625 \n",
       "Q 42.625 4.78125 38.28125 2.390625 \n",
       "Q 33.9375 0 27.875 0 \n",
       "Q 17.828125 0 11.671875 7.65625 \n",
       "Q 5.515625 15.328125 5.515625 27.984375 \n",
       "Q 5.515625 40.671875 11.671875 48.328125 \n",
       "Q 17.828125 56 27.875 56 \n",
       "Q 33.9375 56 38.28125 53.609375 \n",
       "Q 42.625 51.21875 45.40625 46.390625 \n",
       "L 45.40625 54.6875 \n",
       "L 54.390625 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-103\"/>\n",
       "     <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "     <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "     <path d=\"M 37.109375 75.984375 \n",
       "L 37.109375 68.5 \n",
       "L 28.515625 68.5 \n",
       "Q 23.6875 68.5 21.796875 66.546875 \n",
       "Q 19.921875 64.59375 19.921875 59.515625 \n",
       "L 19.921875 54.6875 \n",
       "L 34.71875 54.6875 \n",
       "L 34.71875 47.703125 \n",
       "L 19.921875 47.703125 \n",
       "L 19.921875 0 \n",
       "L 10.890625 0 \n",
       "L 10.890625 47.703125 \n",
       "L 2.296875 47.703125 \n",
       "L 2.296875 54.6875 \n",
       "L 10.890625 54.6875 \n",
       "L 10.890625 58.5 \n",
       "Q 10.890625 67.625 15.140625 71.796875 \n",
       "Q 19.390625 75.984375 28.609375 75.984375 \n",
       "z\n",
       "\" id=\"DejaVuSans-102\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(153.819375 16.318125)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-72\"/>\n",
       "     <use x=\"75.195312\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "     <use x=\"102.978516\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     <use x=\"155.078125\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "     <use x=\"194.287109\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"255.46875\" xlink:href=\"#DejaVuSans-103\"/>\n",
       "     <use x=\"318.945312\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"360.058594\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"421.337891\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "     <use x=\"518.75\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"550.537109\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"611.71875\" xlink:href=\"#DejaVuSans-102\"/>\n",
       "     <use x=\"646.923828\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"678.710938\" xlink:href=\"#DejaVuSans-82\"/>\n",
       "     <use x=\"748.083984\" xlink:href=\"#DejaVuSans-84\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p8440cefe77\">\n",
       "   <rect height=\"271.8\" width=\"279\" x=\"62.86875\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 750x750 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "# the histogram of the data\n",
    "plt.hist(train_data['y'], 50, density=True, facecolor='g', alpha=0.75)\n",
    "\n",
    "plt.xlabel('RT (minute)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Histogram of RT')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "\n",
    "#### Base model:\n",
    "The trained base model used here is available at **AutoRT/models/base_models_PXD006109/**. The base model was trained using a large dataset which contains more than 100,000 peptides.The training data for the base model training only contains a fixed modification of Carbamidomethyl (C) and a variable modifications of Oxidation (M).We encoded modified M (Oxidation) using \"1\".\n",
    "\n",
    "#### Experiment-specific RT model training:\n",
    "Below is the command line for training using transfer learning strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-19 15:48:43.904022: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Scaling method: min_max\n",
      "Transfer learning ...\n",
      "\n",
      "Deep learning model: 0\n",
      "Load aa coding data from file ../models/base_models_PXD006109/aa.tsv\n",
      "AA types: 21\n",
      "Longest peptide in training data: 41\n",
      "\n",
      "Use test file tf_model//validation.tsv\n",
      "Longest peptide in test data: 30\n",
      "\n",
      "['1', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
      "RT range: 0 - 98\n",
      "\n",
      "X_train shape:\n",
      "(4626, 48, 21)\n",
      "X_test shape:\n",
      "(515, 48, 21)\n",
      "Modeling start ...\n",
      "2021-08-19 15:48:45.773826: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-19 15:48:45.826699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: NVIDIA TITAN Xp COLLECTORS EDITION computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-08-19 15:48:45.827220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-08-19 15:48:45.830768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:0b:00.0 name: NVIDIA TITAN Xp COLLECTORS EDITION computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-08-19 15:48:45.830852: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-19 15:48:45.833671: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-19 15:48:45.833781: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-19 15:48:45.834702: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-19 15:48:45.834949: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-19 15:48:45.835762: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-08-19 15:48:45.836435: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-19 15:48:45.836562: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-19 15:48:45.841335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2\n",
      "2021-08-19 15:48:45.841636: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-19 15:48:46.173657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: NVIDIA TITAN Xp COLLECTORS EDITION computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-08-19 15:48:46.174098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-08-19 15:48:46.174780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:0b:00.0 name: NVIDIA TITAN Xp COLLECTORS EDITION computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-08-19 15:48:46.178194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2\n",
      "2021-08-19 15:48:46.178244: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-19 15:48:47.834972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-19 15:48:47.835016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 2 \n",
      "2021-08-19 15:48:47.835023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N Y Y \n",
      "2021-08-19 15:48:47.835029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   Y N Y \n",
      "2021-08-19 15:48:47.835037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2:   Y Y N \n",
      "2021-08-19 15:48:47.840466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11404 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp COLLECTORS EDITION, pci bus id: 0000:05:00.0, compute capability: 6.1)\n",
      "2021-08-19 15:48:47.841225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 2103 MB memory) -> physical GPU (device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "2021-08-19 15:48:47.842116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 11424 MB memory) -> physical GPU (device: 2, name: NVIDIA TITAN Xp COLLECTORS EDITION, pci bus id: 0000:0b:00.0, compute capability: 6.1)\n",
      "48\n",
      "Perform transfer learning ...\n",
      "The number of layers: 22\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08bc14d6d0>\n",
      "Use optimizer: Adam from saved model\n",
      "Used optimizer:\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08bfedaa90>\n",
      "{'scaling_method': 'min_max', 'rt_max': 98.9458507777778, 'rt_min': 0.0}\n",
      "Use ReduceLROnPlateau!\n",
      "Use EarlyStopping: 10\n",
      "2021-08-19 15:48:48.750552: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-19 15:48:48.767473: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3598155000 Hz\n",
      "Epoch 1/40\n",
      "2021-08-19 15:48:51.539983: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-19 15:48:51.862855: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2021-08-19 15:48:52.232083: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-19 15:48:52.465217: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "73/73 [==============================] - 6s 24ms/step - loss: 0.0018 - val_loss: 5.2262e-04\n",
      "\n",
      "Cor: 0.9961 - Cor_val: 0.9934, MAE: 1.3379 - MAE_val: 1.3945, R2: 0.9913 - R2_val: 0.986, MedianE: 1.0316 - MedianE_val: 1.0246, dt95: 7.1825 - dt95_val: 7.4873                                                                                                    \n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00052, saving model to tf_model/best_model.hdf5\n",
      "Epoch 2/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 4.5157e-04 - val_loss: 4.6452e-04\n",
      "\n",
      "Cor: 0.9969 - Cor_val: 0.9939, MAE: 1.126 - MAE_val: 1.2154, R2: 0.9934 - R2_val: 0.9876, MedianE: 0.8169 - MedianE_val: 0.8409, dt95: 6.497 - dt95_val: 6.2998                                                                                                    \n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00052 to 0.00046, saving model to tf_model/best_model.hdf5\n",
      "Epoch 3/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 4.0476e-04 - val_loss: 5.7493e-04\n",
      "\n",
      "Cor: 0.9975 - Cor_val: 0.9946, MAE: 1.4849 - MAE_val: 1.642, R2: 0.9911 - R2_val: 0.9846, MedianE: 1.3212 - MedianE_val: 1.4339, dt95: 6.6729 - dt95_val: 7.3293                                                                                                    \n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00046\n",
      "Epoch 4/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.7143e-04 - val_loss: 4.7237e-04\n",
      "\n",
      "Cor: 0.9978 - Cor_val: 0.9946, MAE: 1.1701 - MAE_val: 1.344, R2: 0.9939 - R2_val: 0.9873, MedianE: 0.9423 - MedianE_val: 1.052, dt95: 5.8062 - dt95_val: 6.3832                                                                                                    \n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00046\n",
      "Epoch 5/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 3.3719e-04 - val_loss: 4.4173e-04\n",
      "\n",
      "Cor: 0.998 - Cor_val: 0.9946, MAE: 1.0478 - MAE_val: 1.1925, R2: 0.9947 - R2_val: 0.9882, MedianE: 0.7997 - MedianE_val: 0.8171, dt95: 5.7815 - dt95_val: 6.9367                                                                                                    \n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00046 to 0.00044, saving model to tf_model/best_model.hdf5\n",
      "Epoch 6/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.4691e-04 - val_loss: 4.0598e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9946, MAE: 0.8453 - MAE_val: 1.0507, R2: 0.9963 - R2_val: 0.9891, MedianE: 0.6171 - MedianE_val: 0.6789, dt95: 4.6535 - dt95_val: 6.2268                                                                                                    \n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00044 to 0.00041, saving model to tf_model/best_model.hdf5\n",
      "Epoch 7/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.0446e-04 - val_loss: 4.5702e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9945, MAE: 1.034 - MAE_val: 1.288, R2: 0.9954 - R2_val: 0.9878, MedianE: 0.8732 - MedianE_val: 1.0119, dt95: 4.9414 - dt95_val: 6.2401                                                                                                    \n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00041\n",
      "Epoch 8/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 3.0606e-04 - val_loss: 5.2475e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9945, MAE: 1.2433 - MAE_val: 1.4832, R2: 0.9936 - R2_val: 0.9859, MedianE: 1.0624 - MedianE_val: 1.2051, dt95: 6.1202 - dt95_val: 7.2791                                                                                                    \n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00041\n",
      "Epoch 9/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 4.1652e-04 - val_loss: 4.4862e-04\n",
      "\n",
      "Cor: 0.9981 - Cor_val: 0.9942, MAE: 0.9811 - MAE_val: 1.2318, R2: 0.9956 - R2_val: 0.988, MedianE: 0.7838 - MedianE_val: 0.9048, dt95: 4.9134 - dt95_val: 6.3296                                                                                                    \n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00041\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.8372e-04 - val_loss: 4.5562e-04\n",
      "\n",
      "Cor: 0.9986 - Cor_val: 0.9945, MAE: 1.011 - MAE_val: 1.2628, R2: 0.9955 - R2_val: 0.9878, MedianE: 0.8185 - MedianE_val: 0.8966, dt95: 5.2549 - dt95_val: 6.5088                                                                                                    \n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00041\n",
      "Epoch 11/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.5858e-04 - val_loss: 4.0954e-04\n",
      "\n",
      "Cor: 0.9984 - Cor_val: 0.9946, MAE: 0.8688 - MAE_val: 1.1301, R2: 0.9965 - R2_val: 0.989, MedianE: 0.6947 - MedianE_val: 0.8066, dt95: 4.5905 - dt95_val: 5.8152                                                                                                    \n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00041\n",
      "Epoch 12/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.3591e-04 - val_loss: 4.0922e-04\n",
      "\n",
      "Cor: 0.9987 - Cor_val: 0.9948, MAE: 0.7635 - MAE_val: 1.0708, R2: 0.9972 - R2_val: 0.989, MedianE: 0.5909 - MedianE_val: 0.71, dt95: 4.1137 - dt95_val: 5.761                                                                                                    \n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00041\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.3701e-04 - val_loss: 4.2169e-04\n",
      "\n",
      "Cor: 0.9988 - Cor_val: 0.9947, MAE: 0.7694 - MAE_val: 1.0998, R2: 0.9972 - R2_val: 0.9887, MedianE: 0.6021 - MedianE_val: 0.7649, dt95: 4.0342 - dt95_val: 5.7204                                                                                                    \n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00041\n",
      "Epoch 14/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.2095e-04 - val_loss: 4.0223e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9948, MAE: 0.72 - MAE_val: 1.0463, R2: 0.9975 - R2_val: 0.9892, MedianE: 0.5739 - MedianE_val: 0.6753, dt95: 3.7384 - dt95_val: 5.2443                                                                                                    \n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00041 to 0.00040, saving model to tf_model/best_model.hdf5\n",
      "Epoch 15/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.3640e-04 - val_loss: 3.9644e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9947, MAE: 0.7205 - MAE_val: 1.0706, R2: 0.9975 - R2_val: 0.9894, MedianE: 0.5713 - MedianE_val: 0.7362, dt95: 3.6549 - dt95_val: 5.8494                                                                                                    \n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00040 to 0.00040, saving model to tf_model/best_model.hdf5\n",
      "Epoch 16/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.2604e-04 - val_loss: 3.9138e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9948, MAE: 0.6959 - MAE_val: 1.0585, R2: 0.9977 - R2_val: 0.9895, MedianE: 0.5537 - MedianE_val: 0.7276, dt95: 3.5143 - dt95_val: 5.7935                                                                                                    \n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00040 to 0.00039, saving model to tf_model/best_model.hdf5\n",
      "Epoch 17/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.1719e-04 - val_loss: 3.8782e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9948, MAE: 0.6848 - MAE_val: 1.05, R2: 0.9978 - R2_val: 0.9896, MedianE: 0.5458 - MedianE_val: 0.7203, dt95: 3.4343 - dt95_val: 5.6428                                                                                                    \n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00039 to 0.00039, saving model to tf_model/best_model.hdf5\n",
      "Epoch 18/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.1614e-04 - val_loss: 4.1154e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9948, MAE: 0.775 - MAE_val: 1.1069, R2: 0.9972 - R2_val: 0.989, MedianE: 0.6242 - MedianE_val: 0.7737, dt95: 3.9803 - dt95_val: 5.732                                                                                                    \n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00039\n",
      "Epoch 19/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.0466e-04 - val_loss: 3.8671e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9948, MAE: 0.6612 - MAE_val: 1.035, R2: 0.9979 - R2_val: 0.9896, MedianE: 0.5223 - MedianE_val: 0.7243, dt95: 3.3964 - dt95_val: 5.4057                                                                                                    \n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00039 to 0.00039, saving model to tf_model/best_model.hdf5\n",
      "Epoch 20/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.1457e-04 - val_loss: 4.0921e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9948, MAE: 0.7034 - MAE_val: 1.0813, R2: 0.9977 - R2_val: 0.989, MedianE: 0.5624 - MedianE_val: 0.7612, dt95: 3.5064 - dt95_val: 5.4438                                                                                                    \n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00039\n",
      "Epoch 21/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.9858e-04 - val_loss: 3.9916e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9947, MAE: 0.6251 - MAE_val: 1.0315, R2: 0.998 - R2_val: 0.9893, MedianE: 0.4835 - MedianE_val: 0.6501, dt95: 3.3284 - dt95_val: 5.4939                                                                                                    \n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00039\n",
      "Epoch 22/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.0252e-04 - val_loss: 4.0221e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9948, MAE: 0.631 - MAE_val: 1.0241, R2: 0.998 - R2_val: 0.9892, MedianE: 0.4807 - MedianE_val: 0.6387, dt95: 3.4163 - dt95_val: 5.5379                                                                                                    \n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00039\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 23/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.9499e-04 - val_loss: 3.8746e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9948, MAE: 0.5933 - MAE_val: 1.0183, R2: 0.9982 - R2_val: 0.9896, MedianE: 0.459 - MedianE_val: 0.6408, dt95: 3.1084 - dt95_val: 5.4094                                                                                                    \n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00039\n",
      "Epoch 24/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8805e-04 - val_loss: 3.9231e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9947, MAE: 0.6191 - MAE_val: 1.0495, R2: 0.9981 - R2_val: 0.9895, MedianE: 0.4948 - MedianE_val: 0.7069, dt95: 3.14 - dt95_val: 5.5657                                                                                                    \n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00039\n",
      "Epoch 25/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.9364e-04 - val_loss: 3.8936e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9948, MAE: 0.5976 - MAE_val: 1.0277, R2: 0.9982 - R2_val: 0.9896, MedianE: 0.4678 - MedianE_val: 0.6697, dt95: 3.1282 - dt95_val: 5.279                                                                                                    \n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00039\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 26/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8582e-04 - val_loss: 3.8837e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9948, MAE: 0.5867 - MAE_val: 1.0209, R2: 0.9983 - R2_val: 0.9896, MedianE: 0.4591 - MedianE_val: 0.6683, dt95: 3.0689 - dt95_val: 5.4494                                                                                                    \n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00039\n",
      "Epoch 27/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8576e-04 - val_loss: 3.8289e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9949, MAE: 0.6019 - MAE_val: 1.0312, R2: 0.9983 - R2_val: 0.9897, MedianE: 0.4842 - MedianE_val: 0.6902, dt95: 3.0021 - dt95_val: 5.4217                                                                                                    \n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00039 to 0.00038, saving model to tf_model/best_model.hdf5\n",
      "Epoch 28/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8868e-04 - val_loss: 3.8352e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9949, MAE: 0.6083 - MAE_val: 1.023, R2: 0.9982 - R2_val: 0.9897, MedianE: 0.4853 - MedianE_val: 0.6598, dt95: 3.127 - dt95_val: 5.4824                                                                                                    \n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00038\n",
      "Epoch 29/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8657e-04 - val_loss: 3.8441e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9949, MAE: 0.6148 - MAE_val: 1.0285, R2: 0.9982 - R2_val: 0.9897, MedianE: 0.4825 - MedianE_val: 0.6648, dt95: 3.2435 - dt95_val: 5.5902                                                                                                    \n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00038\n",
      "Epoch 30/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8154e-04 - val_loss: 3.8593e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9948, MAE: 0.5793 - MAE_val: 1.0181, R2: 0.9984 - R2_val: 0.9897, MedianE: 0.4598 - MedianE_val: 0.6592, dt95: 2.9825 - dt95_val: 5.4387                                                                                                    \n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00038\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 31/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7826e-04 - val_loss: 3.8619e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9948, MAE: 0.5752 - MAE_val: 1.015, R2: 0.9984 - R2_val: 0.9897, MedianE: 0.4523 - MedianE_val: 0.6681, dt95: 2.9164 - dt95_val: 5.3551                                                                                                    \n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00038\n",
      "Epoch 32/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8340e-04 - val_loss: 3.8651e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9948, MAE: 0.5772 - MAE_val: 1.0175, R2: 0.9984 - R2_val: 0.9896, MedianE: 0.4549 - MedianE_val: 0.6585, dt95: 2.9585 - dt95_val: 5.2649                                                                                                    \n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00038\n",
      "Epoch 33/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7481e-04 - val_loss: 3.8513e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9948, MAE: 0.5836 - MAE_val: 1.0196, R2: 0.9983 - R2_val: 0.9897, MedianE: 0.4597 - MedianE_val: 0.6698, dt95: 2.9013 - dt95_val: 5.2719                                                                                                    \n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00038\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 34/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7544e-04 - val_loss: 3.8500e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9948, MAE: 0.5749 - MAE_val: 1.0136, R2: 0.9984 - R2_val: 0.9897, MedianE: 0.4497 - MedianE_val: 0.6602, dt95: 2.9138 - dt95_val: 5.3362                                                                                                    \n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00038\n",
      "Epoch 35/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7687e-04 - val_loss: 3.8575e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9948, MAE: 0.5894 - MAE_val: 1.0197, R2: 0.9983 - R2_val: 0.9897, MedianE: 0.4637 - MedianE_val: 0.677, dt95: 2.9656 - dt95_val: 5.3587                                                                                                    \n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00038\n",
      "Epoch 36/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8322e-04 - val_loss: 3.8623e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9948, MAE: 0.577 - MAE_val: 1.0144, R2: 0.9984 - R2_val: 0.9897, MedianE: 0.4555 - MedianE_val: 0.6742, dt95: 2.9386 - dt95_val: 5.3362                                                                                                    \n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00038\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 37/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7633e-04 - val_loss: 3.8510e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9948, MAE: 0.5802 - MAE_val: 1.0141, R2: 0.9984 - R2_val: 0.9897, MedianE: 0.4617 - MedianE_val: 0.6636, dt95: 2.9248 - dt95_val: 5.4182                                                                                                    \n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00038\n",
      "Epoch 00037: early stopping\n",
      "\n",
      "Deep learning model: 1\n",
      "Load aa coding data from file ../models/base_models_PXD006109/aa.tsv\n",
      "AA types: 21\n",
      "Longest peptide in training data: 41\n",
      "\n",
      "Use test file tf_model//validation.tsv\n",
      "Longest peptide in test data: 30\n",
      "\n",
      "['1', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
      "RT range: 0 - 98\n",
      "\n",
      "X_train shape:\n",
      "(4626, 48, 21)\n",
      "X_test shape:\n",
      "(515, 48, 21)\n",
      "Modeling start ...\n",
      "48\n",
      "Perform transfer learning ...\n",
      "The number of layers: 14\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08346621d0>\n",
      "Use optimizer: Adam from saved model\n",
      "Used optimizer:\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08346409d0>\n",
      "{'scaling_method': 'min_max', 'rt_max': 98.9458507777778, 'rt_min': 0.0}\n",
      "Use ReduceLROnPlateau!\n",
      "Use EarlyStopping: 10\n",
      "Epoch 1/40\n",
      "73/73 [==============================] - 4s 19ms/step - loss: 0.0021 - val_loss: 5.6609e-04\n",
      "\n",
      "Cor: 0.9957 - Cor_val: 0.9926, MAE: 1.3172 - MAE_val: 1.4292, R2: 0.991 - R2_val: 0.9848, MedianE: 0.9532 - MedianE_val: 1.003, dt95: 7.4825 - dt95_val: 7.8559                                                                                                    \n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00057, saving model to tf_model/best_model.hdf5\n",
      "Epoch 2/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 5.3073e-04 - val_loss: 5.6877e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9927, MAE: 1.25 - MAE_val: 1.4385, R2: 0.9928 - R2_val: 0.9848, MedianE: 0.9782 - MedianE_val: 1.0534, dt95: 6.5946 - dt95_val: 8.2975                                                                                                    \n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00057\n",
      "Epoch 3/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 4.6966e-04 - val_loss: 5.4355e-04\n",
      "\n",
      "Cor: 0.9977 - Cor_val: 0.9932, MAE: 1.0706 - MAE_val: 1.4022, R2: 0.9948 - R2_val: 0.9854, MedianE: 0.8593 - MedianE_val: 1.0404, dt95: 5.5428 - dt95_val: 7.9632                                                                                                    \n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00057 to 0.00054, saving model to tf_model/best_model.hdf5\n",
      "Epoch 4/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 4.2571e-04 - val_loss: 6.2810e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9927, MAE: 1.1927 - MAE_val: 1.5917, R2: 0.9942 - R2_val: 0.9832, MedianE: 1.027 - MedianE_val: 1.1582, dt95: 5.8297 - dt95_val: 9.4679                                                                                                    \n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00054\n",
      "Epoch 5/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.8986e-04 - val_loss: 5.2145e-04\n",
      "\n",
      "Cor: 0.9983 - Cor_val: 0.9932, MAE: 0.8843 - MAE_val: 1.3551, R2: 0.9964 - R2_val: 0.986, MedianE: 0.7024 - MedianE_val: 0.9228, dt95: 4.6456 - dt95_val: 7.8659                                                                                                    \n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00054 to 0.00052, saving model to tf_model/best_model.hdf5\n",
      "Epoch 6/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.7372e-04 - val_loss: 5.3437e-04\n",
      "\n",
      "Cor: 0.9984 - Cor_val: 0.9931, MAE: 0.9328 - MAE_val: 1.3805, R2: 0.9962 - R2_val: 0.9857, MedianE: 0.7629 - MedianE_val: 0.9599, dt95: 4.6454 - dt95_val: 7.6419                                                                                                    \n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00052\n",
      "Epoch 7/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.7013e-04 - val_loss: 5.5105e-04\n",
      "\n",
      "Cor: 0.9986 - Cor_val: 0.9927, MAE: 0.8129 - MAE_val: 1.3467, R2: 0.9969 - R2_val: 0.9852, MedianE: 0.6355 - MedianE_val: 0.8833, dt95: 4.2999 - dt95_val: 7.9035                                                                                                    \n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00052\n",
      "Epoch 8/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.9845e-04 - val_loss: 5.4905e-04\n",
      "\n",
      "Cor: 0.9986 - Cor_val: 0.9929, MAE: 0.9032 - MAE_val: 1.3972, R2: 0.9965 - R2_val: 0.9853, MedianE: 0.7483 - MedianE_val: 1.0263, dt95: 4.4064 - dt95_val: 7.3589                                                                                                    \n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.4928e-04 - val_loss: 5.3845e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9929, MAE: 0.7182 - MAE_val: 1.3134, R2: 0.9977 - R2_val: 0.9856, MedianE: 0.5841 - MedianE_val: 0.8322, dt95: 3.7144 - dt95_val: 7.4707                                                                                                    \n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00052\n",
      "Epoch 10/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.9877e-04 - val_loss: 5.3740e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9929, MAE: 0.6788 - MAE_val: 1.2924, R2: 0.9978 - R2_val: 0.9856, MedianE: 0.526 - MedianE_val: 0.7838, dt95: 3.5852 - dt95_val: 7.8782                                                                                                    \n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00052\n",
      "Epoch 11/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.0295e-04 - val_loss: 5.5314e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9928, MAE: 0.7335 - MAE_val: 1.3837, R2: 0.9978 - R2_val: 0.9852, MedianE: 0.6172 - MedianE_val: 0.9888, dt95: 3.5617 - dt95_val: 8.2239                                                                                                    \n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.7477e-04 - val_loss: 5.3265e-04\n",
      "\n",
      "Cor: 0.9993 - Cor_val: 0.9929, MAE: 0.5744 - MAE_val: 1.3213, R2: 0.9985 - R2_val: 0.9857, MedianE: 0.457 - MedianE_val: 0.8576, dt95: 2.951 - dt95_val: 8.1526                                                                                                    \n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00052\n",
      "Epoch 13/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.5532e-04 - val_loss: 5.3993e-04\n",
      "\n",
      "Cor: 0.9994 - Cor_val: 0.993, MAE: 0.6243 - MAE_val: 1.3165, R2: 0.9982 - R2_val: 0.9855, MedianE: 0.4766 - MedianE_val: 0.853, dt95: 3.3864 - dt95_val: 7.9994                                                                                                    \n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00052\n",
      "Epoch 14/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 2.5598e-04 - val_loss: 5.1606e-04\n",
      "\n",
      "Cor: 0.9995 - Cor_val: 0.9931, MAE: 0.499 - MAE_val: 1.2794, R2: 0.9989 - R2_val: 0.9862, MedianE: 0.4016 - MedianE_val: 0.8265, dt95: 2.5509 - dt95_val: 7.6881                                                                                                    \n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00052 to 0.00052, saving model to tf_model/best_model.hdf5\n",
      "Epoch 15/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.5344e-04 - val_loss: 5.2920e-04\n",
      "\n",
      "Cor: 0.9995 - Cor_val: 0.993, MAE: 0.5516 - MAE_val: 1.3097, R2: 0.9987 - R2_val: 0.9858, MedianE: 0.4598 - MedianE_val: 0.8388, dt95: 2.7261 - dt95_val: 7.8757                                                                                                    \n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00052\n",
      "Epoch 16/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 2.4387e-04 - val_loss: 5.1442e-04\n",
      "\n",
      "Cor: 0.9994 - Cor_val: 0.9932, MAE: 0.5227 - MAE_val: 1.3109, R2: 0.9988 - R2_val: 0.9862, MedianE: 0.4291 - MedianE_val: 0.864, dt95: 2.635 - dt95_val: 8.0915                                                                                                    \n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00052 to 0.00051, saving model to tf_model/best_model.hdf5\n",
      "Epoch 17/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.4706e-04 - val_loss: 5.1340e-04\n",
      "\n",
      "Cor: 0.9995 - Cor_val: 0.9931, MAE: 0.4801 - MAE_val: 1.2836, R2: 0.999 - R2_val: 0.9862, MedianE: 0.389 - MedianE_val: 0.8209, dt95: 2.4571 - dt95_val: 7.7929                                                                                                    \n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00051 to 0.00051, saving model to tf_model/best_model.hdf5\n",
      "Epoch 18/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 2.4782e-04 - val_loss: 5.1722e-04\n",
      "\n",
      "Cor: 0.9995 - Cor_val: 0.9931, MAE: 0.4774 - MAE_val: 1.2687, R2: 0.9989 - R2_val: 0.9861, MedianE: 0.378 - MedianE_val: 0.7822, dt95: 2.4741 - dt95_val: 7.8159                                                                                                    \n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00051\n",
      "Epoch 19/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 2.4986e-04 - val_loss: 5.0994e-04\n",
      "\n",
      "Cor: 0.9995 - Cor_val: 0.9932, MAE: 0.4585 - MAE_val: 1.2672, R2: 0.999 - R2_val: 0.9863, MedianE: 0.3704 - MedianE_val: 0.8193, dt95: 2.3791 - dt95_val: 8.0517                                                                                                    \n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00051 to 0.00051, saving model to tf_model/best_model.hdf5\n",
      "Epoch 20/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 2.3783e-04 - val_loss: 5.2640e-04\n",
      "\n",
      "Cor: 0.9995 - Cor_val: 0.9931, MAE: 0.5611 - MAE_val: 1.3004, R2: 0.9986 - R2_val: 0.9859, MedianE: 0.4439 - MedianE_val: 0.818, dt95: 2.8927 - dt95_val: 7.8843                                                                                                    \n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00051\n",
      "Epoch 21/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.3279e-04 - val_loss: 5.1801e-04\n",
      "\n",
      "Cor: 0.9996 - Cor_val: 0.9932, MAE: 0.4866 - MAE_val: 1.2902, R2: 0.9989 - R2_val: 0.9861, MedianE: 0.3851 - MedianE_val: 0.8081, dt95: 2.5894 - dt95_val: 8.0952                                                                                                    \n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00051\n",
      "Epoch 22/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.4467e-04 - val_loss: 5.3486e-04\n",
      "\n",
      "Cor: 0.9995 - Cor_val: 0.993, MAE: 0.594 - MAE_val: 1.3633, R2: 0.9985 - R2_val: 0.9857, MedianE: 0.5061 - MedianE_val: 0.9317, dt95: 2.8153 - dt95_val: 8.4491                                                                                                    \n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00051\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 23/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.3169e-04 - val_loss: 5.1577e-04\n",
      "\n",
      "Cor: 0.9996 - Cor_val: 0.9932, MAE: 0.4617 - MAE_val: 1.2703, R2: 0.999 - R2_val: 0.9862, MedianE: 0.3746 - MedianE_val: 0.7873, dt95: 2.341 - dt95_val: 7.8095                                                                                                    \n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00051\n",
      "Epoch 24/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.3598e-04 - val_loss: 5.0241e-04\n",
      "\n",
      "Cor: 0.9996 - Cor_val: 0.9933, MAE: 0.4179 - MAE_val: 1.2708, R2: 0.9992 - R2_val: 0.9865, MedianE: 0.3349 - MedianE_val: 0.8434, dt95: 2.1854 - dt95_val: 8.0998                                                                                                    \n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00051 to 0.00050, saving model to tf_model/best_model.hdf5\n",
      "Epoch 25/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.2788e-04 - val_loss: 5.1236e-04\n",
      "\n",
      "Cor: 0.9996 - Cor_val: 0.9933, MAE: 0.5142 - MAE_val: 1.2847, R2: 0.9989 - R2_val: 0.9863, MedianE: 0.4331 - MedianE_val: 0.8393, dt95: 2.4483 - dt95_val: 7.4109                                                                                                    \n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00050\n",
      "Epoch 26/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.2919e-04 - val_loss: 4.9737e-04\n",
      "\n",
      "Cor: 0.9996 - Cor_val: 0.9933, MAE: 0.4169 - MAE_val: 1.2387, R2: 0.9992 - R2_val: 0.9867, MedianE: 0.3337 - MedianE_val: 0.8095, dt95: 2.1383 - dt95_val: 7.6385                                                                                                    \n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00050 to 0.00050, saving model to tf_model/best_model.hdf5\n",
      "Epoch 27/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.4269e-04 - val_loss: 4.9843e-04\n",
      "\n",
      "Cor: 0.9996 - Cor_val: 0.9933, MAE: 0.3948 - MAE_val: 1.2452, R2: 0.9993 - R2_val: 0.9866, MedianE: 0.3123 - MedianE_val: 0.8083, dt95: 2.0113 - dt95_val: 7.8501                                                                                                    \n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00050\n",
      "Epoch 28/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.2748e-04 - val_loss: 5.0290e-04\n",
      "\n",
      "Cor: 0.9997 - Cor_val: 0.9934, MAE: 0.4477 - MAE_val: 1.2708, R2: 0.9991 - R2_val: 0.9865, MedianE: 0.3682 - MedianE_val: 0.8432, dt95: 2.2015 - dt95_val: 7.6063                                                                                                    \n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00050\n",
      "Epoch 29/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.1738e-04 - val_loss: 5.0320e-04\n",
      "\n",
      "Cor: 0.9997 - Cor_val: 0.9933, MAE: 0.4136 - MAE_val: 1.2621, R2: 0.9992 - R2_val: 0.9865, MedianE: 0.3333 - MedianE_val: 0.8306, dt95: 2.1485 - dt95_val: 7.2833                                                                                                    \n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 30/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.1908e-04 - val_loss: 4.9553e-04\n",
      "\n",
      "Cor: 0.9997 - Cor_val: 0.9933, MAE: 0.3646 - MAE_val: 1.2387, R2: 0.9994 - R2_val: 0.9867, MedianE: 0.2882 - MedianE_val: 0.7903, dt95: 1.9319 - dt95_val: 7.4939                                                                                                    \n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00050 to 0.00050, saving model to tf_model/best_model.hdf5\n",
      "Epoch 31/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.1611e-04 - val_loss: 5.0364e-04\n",
      "\n",
      "Cor: 0.9997 - Cor_val: 0.9933, MAE: 0.3596 - MAE_val: 1.247, R2: 0.9994 - R2_val: 0.9865, MedianE: 0.2867 - MedianE_val: 0.7838, dt95: 1.8871 - dt95_val: 8.0031                                                                                                    \n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00050\n",
      "Epoch 32/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.1465e-04 - val_loss: 5.0786e-04\n",
      "\n",
      "Cor: 0.9997 - Cor_val: 0.9932, MAE: 0.3902 - MAE_val: 1.2576, R2: 0.9993 - R2_val: 0.9864, MedianE: 0.307 - MedianE_val: 0.816, dt95: 2.0117 - dt95_val: 7.9184                                                                                                    \n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00050\n",
      "Epoch 33/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.3446e-04 - val_loss: 5.0699e-04\n",
      "\n",
      "Cor: 0.9997 - Cor_val: 0.9932, MAE: 0.3865 - MAE_val: 1.2606, R2: 0.9993 - R2_val: 0.9864, MedianE: 0.3186 - MedianE_val: 0.7808, dt95: 1.955 - dt95_val: 7.5114                                                                                                    \n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 34/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.1501e-04 - val_loss: 5.0044e-04\n",
      "\n",
      "Cor: 0.9997 - Cor_val: 0.9933, MAE: 0.3353 - MAE_val: 1.2459, R2: 0.9995 - R2_val: 0.9866, MedianE: 0.2639 - MedianE_val: 0.7962, dt95: 1.7498 - dt95_val: 7.4995                                                                                                    \n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00050\n",
      "Epoch 35/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.0740e-04 - val_loss: 4.9880e-04\n",
      "\n",
      "Cor: 0.9997 - Cor_val: 0.9933, MAE: 0.3399 - MAE_val: 1.2475, R2: 0.9995 - R2_val: 0.9866, MedianE: 0.2736 - MedianE_val: 0.8083, dt95: 1.7379 - dt95_val: 7.5938                                                                                                    \n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00050\n",
      "Epoch 36/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.1406e-04 - val_loss: 5.0150e-04\n",
      "\n",
      "Cor: 0.9997 - Cor_val: 0.9933, MAE: 0.3402 - MAE_val: 1.2492, R2: 0.9994 - R2_val: 0.9866, MedianE: 0.275 - MedianE_val: 0.7953, dt95: 1.7427 - dt95_val: 7.6074                                                                                                    \n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 37/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.1011e-04 - val_loss: 4.9875e-04\n",
      "\n",
      "Cor: 0.9997 - Cor_val: 0.9933, MAE: 0.3336 - MAE_val: 1.2474, R2: 0.9995 - R2_val: 0.9866, MedianE: 0.2674 - MedianE_val: 0.7837, dt95: 1.7311 - dt95_val: 7.6295                                                                                                    \n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00050\n",
      "Epoch 38/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.1504e-04 - val_loss: 4.9986e-04\n",
      "\n",
      "Cor: 0.9997 - Cor_val: 0.9933, MAE: 0.349 - MAE_val: 1.2544, R2: 0.9994 - R2_val: 0.9866, MedianE: 0.2862 - MedianE_val: 0.8028, dt95: 1.7809 - dt95_val: 7.5197                                                                                                    \n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00050\n",
      "Epoch 39/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.0833e-04 - val_loss: 4.9933e-04\n",
      "\n",
      "Cor: 0.9998 - Cor_val: 0.9933, MAE: 0.325 - MAE_val: 1.2452, R2: 0.9995 - R2_val: 0.9866, MedianE: 0.2583 - MedianE_val: 0.7861, dt95: 1.6827 - dt95_val: 7.3908                                                                                                    \n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 40/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.0631e-04 - val_loss: 4.9739e-04\n",
      "\n",
      "Cor: 0.9998 - Cor_val: 0.9933, MAE: 0.3146 - MAE_val: 1.2374, R2: 0.9995 - R2_val: 0.9867, MedianE: 0.2466 - MedianE_val: 0.8008, dt95: 1.611 - dt95_val: 7.6544                                                                                                    \n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00050\n",
      "Epoch 00040: early stopping\n",
      "\n",
      "Deep learning model: 2\n",
      "Load aa coding data from file ../models/base_models_PXD006109/aa.tsv\n",
      "AA types: 21\n",
      "Longest peptide in training data: 41\n",
      "\n",
      "Use test file tf_model//validation.tsv\n",
      "Longest peptide in test data: 30\n",
      "\n",
      "['1', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
      "RT range: 0 - 98\n",
      "\n",
      "X_train shape:\n",
      "(4626, 48, 21)\n",
      "X_test shape:\n",
      "(515, 48, 21)\n",
      "Modeling start ...\n",
      "48\n",
      "Perform transfer learning ...\n",
      "The number of layers: 19\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08c263d490>\n",
      "Use optimizer: Adam from saved model\n",
      "Used optimizer:\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08bfddd710>\n",
      "{'scaling_method': 'min_max', 'rt_max': 98.9458507777778, 'rt_min': 0.0}\n",
      "Use ReduceLROnPlateau!\n",
      "Use EarlyStopping: 10\n",
      "Epoch 1/40\n",
      "73/73 [==============================] - 5s 22ms/step - loss: 0.0018 - val_loss: 8.4742e-04\n",
      "\n",
      "Cor: 0.9966 - Cor_val: 0.9942, MAE: 2.112 - MAE_val: 2.1378, R2: 0.9824 - R2_val: 0.9773, MedianE: 1.922 - MedianE_val: 1.8588, dt95: 9.4188 - dt95_val: 9.3746                                                                                                    \n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00085, saving model to tf_model/best_model.hdf5\n",
      "Epoch 2/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 4.8460e-04 - val_loss: 4.8678e-04\n",
      "\n",
      "Cor: 0.9976 - Cor_val: 0.9949, MAE: 1.3547 - MAE_val: 1.4633, R2: 0.9926 - R2_val: 0.987, MedianE: 1.2123 - MedianE_val: 1.1931, dt95: 6.1091 - dt95_val: 6.7526                                                                                                    \n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00085 to 0.00049, saving model to tf_model/best_model.hdf5\n",
      "Epoch 3/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 4.0800e-04 - val_loss: 4.3572e-04\n",
      "\n",
      "Cor: 0.998 - Cor_val: 0.9951, MAE: 1.1469 - MAE_val: 1.2992, R2: 0.9944 - R2_val: 0.9883, MedianE: 0.9784 - MedianE_val: 1.0095, dt95: 5.3972 - dt95_val: 6.3833                                                                                                    \n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00049 to 0.00044, saving model to tf_model/best_model.hdf5\n",
      "Epoch 4/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 4.0479e-04 - val_loss: 3.7634e-04\n",
      "\n",
      "Cor: 0.9984 - Cor_val: 0.9953, MAE: 0.8755 - MAE_val: 1.0922, R2: 0.9963 - R2_val: 0.9899, MedianE: 0.6739 - MedianE_val: 0.7869, dt95: 4.7947 - dt95_val: 5.9793                                                                                                    \n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00044 to 0.00038, saving model to tf_model/best_model.hdf5\n",
      "Epoch 5/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 3.6595e-04 - val_loss: 4.3217e-04\n",
      "\n",
      "Cor: 0.9984 - Cor_val: 0.9951, MAE: 1.068 - MAE_val: 1.3023, R2: 0.9952 - R2_val: 0.9884, MedianE: 0.9197 - MedianE_val: 1.0263, dt95: 5.004 - dt95_val: 6.331                                                                                                    \n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00038\n",
      "Epoch 6/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.6686e-04 - val_loss: 4.2650e-04\n",
      "\n",
      "Cor: 0.9985 - Cor_val: 0.9955, MAE: 1.1276 - MAE_val: 1.3238, R2: 0.9948 - R2_val: 0.9886, MedianE: 0.9843 - MedianE_val: 1.083, dt95: 5.1902 - dt95_val: 6.2566                                                                                                    \n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00038\n",
      "Epoch 7/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.3372e-04 - val_loss: 3.9371e-04\n",
      "\n",
      "Cor: 0.9986 - Cor_val: 0.9951, MAE: 0.8657 - MAE_val: 1.1281, R2: 0.9965 - R2_val: 0.9895, MedianE: 0.6912 - MedianE_val: 0.7857, dt95: 4.5211 - dt95_val: 6.4092                                                                                                    \n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00038\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 3.1475e-04 - val_loss: 3.6696e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9953, MAE: 0.7192 - MAE_val: 1.0433, R2: 0.9975 - R2_val: 0.9902, MedianE: 0.5682 - MedianE_val: 0.6705, dt95: 3.7293 - dt95_val: 6.0126                                                                                                    \n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00038 to 0.00037, saving model to tf_model/best_model.hdf5\n",
      "Epoch 9/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 3.2710e-04 - val_loss: 3.7882e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9951, MAE: 0.7308 - MAE_val: 1.0827, R2: 0.9975 - R2_val: 0.9899, MedianE: 0.5874 - MedianE_val: 0.7615, dt95: 3.6535 - dt95_val: 5.9068                                                                                                    \n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00037\n",
      "Epoch 10/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.1992e-04 - val_loss: 4.4644e-04\n",
      "\n",
      "Cor: 0.9988 - Cor_val: 0.9949, MAE: 0.8941 - MAE_val: 1.1829, R2: 0.996 - R2_val: 0.988, MedianE: 0.6473 - MedianE_val: 0.7664, dt95: 5.2012 - dt95_val: 7.0501                                                                                                    \n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00037\n",
      "Epoch 11/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.2026e-04 - val_loss: 3.9872e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9951, MAE: 0.773 - MAE_val: 1.1093, R2: 0.9973 - R2_val: 0.9893, MedianE: 0.6354 - MedianE_val: 0.7616, dt95: 3.8544 - dt95_val: 6.0589                                                                                                    \n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00037\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.8387e-04 - val_loss: 4.1862e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9953, MAE: 0.9113 - MAE_val: 1.202, R2: 0.9964 - R2_val: 0.9888, MedianE: 0.7599 - MedianE_val: 0.8483, dt95: 4.4985 - dt95_val: 6.6222                                                                                                    \n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00037\n",
      "Epoch 13/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.8929e-04 - val_loss: 3.6641e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9952, MAE: 0.639 - MAE_val: 1.0286, R2: 0.998 - R2_val: 0.9902, MedianE: 0.5093 - MedianE_val: 0.7196, dt95: 3.2435 - dt95_val: 5.7954                                                                                                    \n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00037 to 0.00037, saving model to tf_model/best_model.hdf5\n",
      "Epoch 14/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.6455e-04 - val_loss: 3.8813e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9951, MAE: 0.7177 - MAE_val: 1.0757, R2: 0.9976 - R2_val: 0.9896, MedianE: 0.5859 - MedianE_val: 0.7752, dt95: 3.5735 - dt95_val: 6.2773                                                                                                    \n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00037\n",
      "Epoch 15/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.6587e-04 - val_loss: 3.7131e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9953, MAE: 0.6899 - MAE_val: 1.0827, R2: 0.9979 - R2_val: 0.9901, MedianE: 0.5769 - MedianE_val: 0.773, dt95: 3.3592 - dt95_val: 5.5243                                                                                                    \n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00037\n",
      "Epoch 16/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.7628e-04 - val_loss: 3.6443e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9953, MAE: 0.663 - MAE_val: 1.0493, R2: 0.998 - R2_val: 0.9902, MedianE: 0.5304 - MedianE_val: 0.7068, dt95: 3.3219 - dt95_val: 6.1021                                                                                                    \n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00037 to 0.00036, saving model to tf_model/best_model.hdf5\n",
      "Epoch 17/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.7774e-04 - val_loss: 3.7931e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9953, MAE: 0.731 - MAE_val: 1.0625, R2: 0.9975 - R2_val: 0.9898, MedianE: 0.5619 - MedianE_val: 0.6891, dt95: 3.9391 - dt95_val: 5.8984                                                                                                    \n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00036\n",
      "Epoch 18/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.7548e-04 - val_loss: 3.8803e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9953, MAE: 0.7727 - MAE_val: 1.1469, R2: 0.9975 - R2_val: 0.9896, MedianE: 0.6683 - MedianE_val: 0.9225, dt95: 3.6068 - dt95_val: 5.918                                                                                                    \n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00036\n",
      "Epoch 19/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.5988e-04 - val_loss: 4.0960e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9951, MAE: 0.831 - MAE_val: 1.1432, R2: 0.9969 - R2_val: 0.989, MedianE: 0.6589 - MedianE_val: 0.7457, dt95: 4.2758 - dt95_val: 6.4128                                                                                                    \n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00036\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 20/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.6517e-04 - val_loss: 3.8886e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9952, MAE: 0.7257 - MAE_val: 1.1059, R2: 0.9976 - R2_val: 0.9896, MedianE: 0.6048 - MedianE_val: 0.7904, dt95: 3.6031 - dt95_val: 5.9232                                                                                                    \n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00036\n",
      "Epoch 21/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.4374e-04 - val_loss: 3.7398e-04\n",
      "\n",
      "Cor: 0.9993 - Cor_val: 0.9952, MAE: 0.6362 - MAE_val: 1.0545, R2: 0.9981 - R2_val: 0.99, MedianE: 0.5112 - MedianE_val: 0.7285, dt95: 3.2322 - dt95_val: 5.6444                                                                                                    \n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00036\n",
      "Epoch 22/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 3.0310e-04 - val_loss: 3.5914e-04\n",
      "\n",
      "Cor: 0.9993 - Cor_val: 0.9952, MAE: 0.5244 - MAE_val: 0.9781, R2: 0.9986 - R2_val: 0.9904, MedianE: 0.4093 - MedianE_val: 0.6443, dt95: 2.7432 - dt95_val: 5.7413                                                                                                    \n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00036 to 0.00036, saving model to tf_model/best_model.hdf5\n",
      "Epoch 23/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.6404e-04 - val_loss: 3.7111e-04\n",
      "\n",
      "Cor: 0.9993 - Cor_val: 0.9952, MAE: 0.6055 - MAE_val: 1.0442, R2: 0.9983 - R2_val: 0.9901, MedianE: 0.5035 - MedianE_val: 0.6857, dt95: 2.9706 - dt95_val: 6.1462                                                                                                    \n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00036\n",
      "Epoch 24/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.6006e-04 - val_loss: 3.6024e-04\n",
      "\n",
      "Cor: 0.9993 - Cor_val: 0.9952, MAE: 0.5364 - MAE_val: 0.9925, R2: 0.9986 - R2_val: 0.9903, MedianE: 0.4183 - MedianE_val: 0.6433, dt95: 2.7284 - dt95_val: 5.73                                                                                                    \n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00036\n",
      "Epoch 25/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.5266e-04 - val_loss: 3.8044e-04\n",
      "\n",
      "Cor: 0.9993 - Cor_val: 0.9951, MAE: 0.613 - MAE_val: 1.0562, R2: 0.9983 - R2_val: 0.9898, MedianE: 0.5073 - MedianE_val: 0.7565, dt95: 2.9818 - dt95_val: 6.5018                                                                                                    \n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00036\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 26/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.5948e-04 - val_loss: 3.6941e-04\n",
      "\n",
      "Cor: 0.9993 - Cor_val: 0.9952, MAE: 0.5674 - MAE_val: 1.0237, R2: 0.9984 - R2_val: 0.9901, MedianE: 0.4529 - MedianE_val: 0.6852, dt95: 2.8309 - dt95_val: 6.0607                                                                                                    \n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00036\n",
      "Epoch 27/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.4333e-04 - val_loss: 3.7896e-04\n",
      "\n",
      "Cor: 0.9993 - Cor_val: 0.9952, MAE: 0.6181 - MAE_val: 1.0436, R2: 0.9982 - R2_val: 0.9898, MedianE: 0.493 - MedianE_val: 0.6976, dt95: 3.1977 - dt95_val: 6.0874                                                                                                    \n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00036\n",
      "Epoch 28/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.6462e-04 - val_loss: 3.7144e-04\n",
      "\n",
      "Cor: 0.9993 - Cor_val: 0.9952, MAE: 0.5838 - MAE_val: 1.0415, R2: 0.9984 - R2_val: 0.99, MedianE: 0.4738 - MedianE_val: 0.7125, dt95: 2.8826 - dt95_val: 6.061                                                                                                    \n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00036\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 29/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.4482e-04 - val_loss: 3.8208e-04\n",
      "\n",
      "Cor: 0.9993 - Cor_val: 0.9952, MAE: 0.6304 - MAE_val: 1.0465, R2: 0.9981 - R2_val: 0.9898, MedianE: 0.5029 - MedianE_val: 0.6978, dt95: 3.2866 - dt95_val: 6.0066                                                                                                    \n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00036\n",
      "Epoch 30/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.4357e-04 - val_loss: 3.6721e-04\n",
      "\n",
      "Cor: 0.9994 - Cor_val: 0.9952, MAE: 0.5581 - MAE_val: 1.0214, R2: 0.9985 - R2_val: 0.9902, MedianE: 0.4443 - MedianE_val: 0.696, dt95: 2.7916 - dt95_val: 5.9555                                                                                                    \n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00036\n",
      "Epoch 31/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.4471e-04 - val_loss: 3.8079e-04\n",
      "\n",
      "Cor: 0.9994 - Cor_val: 0.9952, MAE: 0.6247 - MAE_val: 1.0758, R2: 0.9982 - R2_val: 0.9898, MedianE: 0.5114 - MedianE_val: 0.7551, dt95: 3.0434 - dt95_val: 6.0502                                                                                                    \n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00036\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 32/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.3995e-04 - val_loss: 3.7365e-04\n",
      "\n",
      "Cor: 0.9994 - Cor_val: 0.9952, MAE: 0.591 - MAE_val: 1.032, R2: 0.9983 - R2_val: 0.99, MedianE: 0.4708 - MedianE_val: 0.692, dt95: 3.0114 - dt95_val: 5.913                                                                                                    \n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00036\n",
      "Epoch 00032: early stopping\n",
      "\n",
      "Deep learning model: 3\n",
      "Load aa coding data from file ../models/base_models_PXD006109/aa.tsv\n",
      "AA types: 21\n",
      "Longest peptide in training data: 41\n",
      "\n",
      "Use test file tf_model//validation.tsv\n",
      "Longest peptide in test data: 30\n",
      "\n",
      "['1', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
      "RT range: 0 - 98\n",
      "\n",
      "X_train shape:\n",
      "(4626, 48, 21)\n",
      "X_test shape:\n",
      "(515, 48, 21)\n",
      "Modeling start ...\n",
      "48\n",
      "Perform transfer learning ...\n",
      "The number of layers: 26\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08bf66e610>\n",
      "Use optimizer: Adam from saved model\n",
      "Used optimizer:\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08bc056410>\n",
      "{'scaling_method': 'min_max', 'rt_max': 98.9458507777778, 'rt_min': 0.0}\n",
      "Use ReduceLROnPlateau!\n",
      "Use EarlyStopping: 10\n",
      "Epoch 1/40\n",
      "73/73 [==============================] - 5s 20ms/step - loss: 0.0034 - val_loss: 9.3317e-04\n",
      "\n",
      "Cor: 0.9921 - Cor_val: 0.9896, MAE: 2.0799 - MAE_val: 2.0614, R2: 0.9794 - R2_val: 0.975, MedianE: 1.6361 - MedianE_val: 1.4659, dt95: 11.3771 - dt95_val: 10.8443                                                                                                    \n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00093, saving model to tf_model/best_model.hdf5\n",
      "Epoch 2/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "\n",
      "Cor: 0.9931 - Cor_val: 0.9898, MAE: 2.2905 - MAE_val: 2.3478, R2: 0.9767 - R2_val: 0.9703, MedianE: 1.8825 - MedianE_val: 1.8035, dt95: 11.8527 - dt95_val: 12.0819                                                                                                    \n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00093\n",
      "Epoch 3/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0020 - val_loss: 8.7987e-04\n",
      "\n",
      "Cor: 0.9937 - Cor_val: 0.9901, MAE: 1.879 - MAE_val: 2.042, R2: 0.9838 - R2_val: 0.9764, MedianE: 1.4954 - MedianE_val: 1.5441, dt95: 10.1128 - dt95_val: 10.5043                                                                                                    \n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00093 to 0.00088, saving model to tf_model/best_model.hdf5\n",
      "Epoch 4/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0020 - val_loss: 9.0019e-04\n",
      "\n",
      "Cor: 0.9939 - Cor_val: 0.9907, MAE: 1.9049 - MAE_val: 2.1103, R2: 0.9843 - R2_val: 0.9759, MedianE: 1.5833 - MedianE_val: 1.6807, dt95: 9.5695 - dt95_val: 10.461                                                                                                    \n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00088\n",
      "Epoch 5/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0020 - val_loss: 7.8328e-04\n",
      "\n",
      "Cor: 0.9945 - Cor_val: 0.9905, MAE: 1.689 - MAE_val: 1.8953, R2: 0.987 - R2_val: 0.979, MedianE: 1.3421 - MedianE_val: 1.5035, dt95: 8.9087 - dt95_val: 10.0768                                                                                                    \n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00088 to 0.00078, saving model to tf_model/best_model.hdf5\n",
      "Epoch 6/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0019 - val_loss: 9.6556e-04\n",
      "\n",
      "Cor: 0.9941 - Cor_val: 0.9906, MAE: 2.0161 - MAE_val: 2.1902, R2: 0.9826 - R2_val: 0.9741, MedianE: 1.6445 - MedianE_val: 1.7307, dt95: 10.2453 - dt95_val: 11.4827                                                                                                    \n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00078\n",
      "Epoch 7/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0020 - val_loss: 7.6354e-04\n",
      "\n",
      "Cor: 0.9944 - Cor_val: 0.9901, MAE: 1.5337 - MAE_val: 1.7766, R2: 0.9884 - R2_val: 0.9795, MedianE: 1.14 - MedianE_val: 1.2308, dt95: 8.699 - dt95_val: 11.1062                                                                                                    \n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00078 to 0.00076, saving model to tf_model/best_model.hdf5\n",
      "Epoch 8/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 8.8242e-04\n",
      "\n",
      "Cor: 0.9941 - Cor_val: 0.9896, MAE: 1.7478 - MAE_val: 1.924, R2: 0.9847 - R2_val: 0.9764, MedianE: 1.2722 - MedianE_val: 1.2964, dt95: 10.2046 - dt95_val: 10.223                                                                                                    \n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00076\n",
      "Epoch 9/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 9.2847e-04\n",
      "\n",
      "Cor: 0.9951 - Cor_val: 0.9906, MAE: 1.9948 - MAE_val: 2.177, R2: 0.984 - R2_val: 0.9751, MedianE: 1.7153 - MedianE_val: 1.7903, dt95: 9.5913 - dt95_val: 10.0966                                                                                                    \n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00076\n",
      "Epoch 10/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 8.2289e-04\n",
      "\n",
      "Cor: 0.9949 - Cor_val: 0.9908, MAE: 1.6242 - MAE_val: 1.859, R2: 0.9872 - R2_val: 0.978, MedianE: 1.2121 - MedianE_val: 1.2554, dt95: 9.3087 - dt95_val: 11.1991                                                                                                    \n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00076\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 6.8810e-04\n",
      "\n",
      "Cor: 0.9955 - Cor_val: 0.9908, MAE: 1.3646 - MAE_val: 1.6222, R2: 0.9906 - R2_val: 0.9816, MedianE: 0.9993 - MedianE_val: 1.1101, dt95: 7.904 - dt95_val: 9.9093                                                                                                    \n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00076 to 0.00069, saving model to tf_model/best_model.hdf5\n",
      "Epoch 12/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 7.7789e-04\n",
      "\n",
      "Cor: 0.9959 - Cor_val: 0.9912, MAE: 1.613 - MAE_val: 1.8451, R2: 0.9886 - R2_val: 0.9792, MedianE: 1.3068 - MedianE_val: 1.3529, dt95: 8.4088 - dt95_val: 9.9631                                                                                                    \n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00069\n",
      "Epoch 13/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 6.8250e-04\n",
      "\n",
      "Cor: 0.9956 - Cor_val: 0.9909, MAE: 1.3483 - MAE_val: 1.6281, R2: 0.991 - R2_val: 0.9817, MedianE: 0.9859 - MedianE_val: 1.0915, dt95: 7.6911 - dt95_val: 9.098                                                                                                    \n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00069 to 0.00068, saving model to tf_model/best_model.hdf5\n",
      "Epoch 14/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 6.7131e-04\n",
      "\n",
      "Cor: 0.996 - Cor_val: 0.9912, MAE: 1.3267 - MAE_val: 1.6336, R2: 0.9917 - R2_val: 0.982, MedianE: 1.009 - MedianE_val: 1.1259, dt95: 7.1902 - dt95_val: 8.8929                                                                                                    \n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00068 to 0.00067, saving model to tf_model/best_model.hdf5\n",
      "Epoch 15/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 6.6010e-04\n",
      "\n",
      "Cor: 0.996 - Cor_val: 0.9914, MAE: 1.3343 - MAE_val: 1.6569, R2: 0.9917 - R2_val: 0.9823, MedianE: 1.0294 - MedianE_val: 1.0855, dt95: 7.2225 - dt95_val: 9.6727                                                                                                    \n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00067 to 0.00066, saving model to tf_model/best_model.hdf5\n",
      "Epoch 16/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 6.6951e-04\n",
      "\n",
      "Cor: 0.9963 - Cor_val: 0.9912, MAE: 1.3004 - MAE_val: 1.5555, R2: 0.9918 - R2_val: 0.9821, MedianE: 0.9458 - MedianE_val: 0.9824, dt95: 7.4761 - dt95_val: 9.484                                                                                                    \n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00066\n",
      "Epoch 17/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 6.7047e-04\n",
      "\n",
      "Cor: 0.9963 - Cor_val: 0.9912, MAE: 1.254 - MAE_val: 1.5904, R2: 0.9924 - R2_val: 0.982, MedianE: 0.9145 - MedianE_val: 1.051, dt95: 7.0919 - dt95_val: 9.2826                                                                                                    \n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00066\n",
      "Epoch 18/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 7.0394e-04\n",
      "\n",
      "Cor: 0.9959 - Cor_val: 0.991, MAE: 1.3557 - MAE_val: 1.6874, R2: 0.9913 - R2_val: 0.9811, MedianE: 1.0136 - MedianE_val: 1.116, dt95: 7.7719 - dt95_val: 9.1153                                                                                                    \n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00066\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 6.5348e-04\n",
      "\n",
      "Cor: 0.9965 - Cor_val: 0.9916, MAE: 1.2735 - MAE_val: 1.6426, R2: 0.9925 - R2_val: 0.9825, MedianE: 0.9529 - MedianE_val: 1.2004, dt95: 6.906 - dt95_val: 8.9396                                                                                                    \n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00066 to 0.00065, saving model to tf_model/best_model.hdf5\n",
      "Epoch 20/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 6.6971e-04\n",
      "\n",
      "Cor: 0.9966 - Cor_val: 0.9916, MAE: 1.3023 - MAE_val: 1.6895, R2: 0.9925 - R2_val: 0.9821, MedianE: 1.046 - MedianE_val: 1.263, dt95: 6.6436 - dt95_val: 9.0282                                                                                                    \n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00065\n",
      "Epoch 21/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 6.8632e-04\n",
      "\n",
      "Cor: 0.9965 - Cor_val: 0.9913, MAE: 1.3223 - MAE_val: 1.7005, R2: 0.9922 - R2_val: 0.9816, MedianE: 1.0574 - MedianE_val: 1.2616, dt95: 6.9516 - dt95_val: 9.3827                                                                                                    \n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00065\n",
      "Epoch 22/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 6.8178e-04\n",
      "\n",
      "Cor: 0.9966 - Cor_val: 0.9913, MAE: 1.3091 - MAE_val: 1.6908, R2: 0.9923 - R2_val: 0.9817, MedianE: 1.0357 - MedianE_val: 1.2367, dt95: 6.8414 - dt95_val: 9.2092                                                                                                    \n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00065\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 23/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0015 - val_loss: 6.5014e-04\n",
      "\n",
      "Cor: 0.9966 - Cor_val: 0.9914, MAE: 1.1971 - MAE_val: 1.5981, R2: 0.9931 - R2_val: 0.9826, MedianE: 0.9058 - MedianE_val: 1.0587, dt95: 6.568 - dt95_val: 8.6486                                                                                                    \n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00065 to 0.00065, saving model to tf_model/best_model.hdf5\n",
      "Epoch 24/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 6.7025e-04\n",
      "\n",
      "Cor: 0.9965 - Cor_val: 0.9914, MAE: 1.2469 - MAE_val: 1.6386, R2: 0.9926 - R2_val: 0.982, MedianE: 0.9522 - MedianE_val: 1.1112, dt95: 6.7743 - dt95_val: 9.3217                                                                                                    \n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00065\n",
      "Epoch 25/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0015 - val_loss: 6.5475e-04\n",
      "\n",
      "Cor: 0.9966 - Cor_val: 0.9915, MAE: 1.242 - MAE_val: 1.6239, R2: 0.9929 - R2_val: 0.9825, MedianE: 0.9561 - MedianE_val: 1.1234, dt95: 6.66 - dt95_val: 8.8189                                                                                                    \n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00065\n",
      "Epoch 26/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0016 - val_loss: 6.5862e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9916, MAE: 1.2627 - MAE_val: 1.6289, R2: 0.9927 - R2_val: 0.9824, MedianE: 0.9986 - MedianE_val: 1.1556, dt95: 6.8058 - dt95_val: 9.1142                                                                                                    \n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00065\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 27/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0016 - val_loss: 6.4350e-04\n",
      "\n",
      "Cor: 0.9967 - Cor_val: 0.9916, MAE: 1.2092 - MAE_val: 1.6009, R2: 0.9932 - R2_val: 0.9828, MedianE: 0.9436 - MedianE_val: 1.0996, dt95: 6.5189 - dt95_val: 8.803                                                                                                    \n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00065 to 0.00064, saving model to tf_model/best_model.hdf5\n",
      "Epoch 28/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0016 - val_loss: 6.4941e-04\n",
      "\n",
      "Cor: 0.9967 - Cor_val: 0.9915, MAE: 1.2178 - MAE_val: 1.6031, R2: 0.9931 - R2_val: 0.9826, MedianE: 0.9453 - MedianE_val: 1.0892, dt95: 6.5274 - dt95_val: 8.9414                                                                                                    \n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00064\n",
      "Epoch 29/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 6.4422e-04\n",
      "\n",
      "Cor: 0.9967 - Cor_val: 0.9916, MAE: 1.1924 - MAE_val: 1.5813, R2: 0.9932 - R2_val: 0.9827, MedianE: 0.91 - MedianE_val: 1.0526, dt95: 6.4867 - dt95_val: 8.5551                                                                                                    \n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00064\n",
      "Epoch 30/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0016 - val_loss: 6.5205e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9916, MAE: 1.2328 - MAE_val: 1.6033, R2: 0.993 - R2_val: 0.9825, MedianE: 0.9597 - MedianE_val: 1.154, dt95: 6.6822 - dt95_val: 8.6614                                                                                                    \n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00064\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 31/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 6.3982e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9915, MAE: 1.1841 - MAE_val: 1.5737, R2: 0.9933 - R2_val: 0.9829, MedianE: 0.9119 - MedianE_val: 1.0475, dt95: 6.5357 - dt95_val: 8.3026                                                                                                    \n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00064 to 0.00064, saving model to tf_model/best_model.hdf5\n",
      "Epoch 32/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0016 - val_loss: 6.3964e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9916, MAE: 1.1809 - MAE_val: 1.5758, R2: 0.9934 - R2_val: 0.9829, MedianE: 0.9034 - MedianE_val: 1.0953, dt95: 6.5815 - dt95_val: 8.7764                                                                                                    \n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00064 to 0.00064, saving model to tf_model/best_model.hdf5\n",
      "Epoch 33/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 6.4792e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9916, MAE: 1.2146 - MAE_val: 1.6035, R2: 0.9931 - R2_val: 0.9826, MedianE: 0.9444 - MedianE_val: 1.1351, dt95: 6.6334 - dt95_val: 8.6147                                                                                                    \n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00064\n",
      "Epoch 34/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 6.4068e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9916, MAE: 1.1931 - MAE_val: 1.5843, R2: 0.9933 - R2_val: 0.9828, MedianE: 0.9319 - MedianE_val: 1.0714, dt95: 6.457 - dt95_val: 8.5807                                                                                                    \n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00064\n",
      "Epoch 35/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 6.4433e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9916, MAE: 1.2096 - MAE_val: 1.5929, R2: 0.9932 - R2_val: 0.9827, MedianE: 0.9432 - MedianE_val: 1.1028, dt95: 6.5431 - dt95_val: 8.8346                                                                                                    \n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00064\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 36/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0016 - val_loss: 6.3914e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9916, MAE: 1.1888 - MAE_val: 1.5752, R2: 0.9934 - R2_val: 0.9829, MedianE: 0.9223 - MedianE_val: 1.0471, dt95: 6.5253 - dt95_val: 8.5737                                                                                                    \n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00064 to 0.00064, saving model to tf_model/best_model.hdf5\n",
      "Epoch 37/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0014 - val_loss: 6.3532e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9916, MAE: 1.1685 - MAE_val: 1.5566, R2: 0.9935 - R2_val: 0.983, MedianE: 0.8987 - MedianE_val: 1.0293, dt95: 6.5503 - dt95_val: 8.6302                                                                                                    \n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00064 to 0.00064, saving model to tf_model/best_model.hdf5\n",
      "Epoch 38/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 6.3833e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9916, MAE: 1.1782 - MAE_val: 1.5705, R2: 0.9934 - R2_val: 0.9829, MedianE: 0.9044 - MedianE_val: 1.0469, dt95: 6.481 - dt95_val: 8.6641                                                                                                    \n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00064\n",
      "Epoch 39/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 6.3682e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9916, MAE: 1.1726 - MAE_val: 1.5676, R2: 0.9935 - R2_val: 0.9829, MedianE: 0.9008 - MedianE_val: 1.0429, dt95: 6.4465 - dt95_val: 8.6157                                                                                                    \n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00064\n",
      "Epoch 40/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0015 - val_loss: 6.3953e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9916, MAE: 1.182 - MAE_val: 1.5748, R2: 0.9934 - R2_val: 0.9829, MedianE: 0.9062 - MedianE_val: 1.0744, dt95: 6.5039 - dt95_val: 8.7507                                                                                                    \n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00064\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Deep learning model: 4\n",
      "Load aa coding data from file ../models/base_models_PXD006109/aa.tsv\n",
      "AA types: 21\n",
      "Longest peptide in training data: 41\n",
      "\n",
      "Use test file tf_model//validation.tsv\n",
      "Longest peptide in test data: 30\n",
      "\n",
      "['1', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
      "RT range: 0 - 98\n",
      "\n",
      "X_train shape:\n",
      "(4626, 48, 21)\n",
      "X_test shape:\n",
      "(515, 48, 21)\n",
      "Modeling start ...\n",
      "48\n",
      "Perform transfer learning ...\n",
      "The number of layers: 20\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f083464b690>\n",
      "Use optimizer: Adam from saved model\n",
      "Used optimizer:\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08bc0b0d90>\n",
      "{'scaling_method': 'min_max', 'rt_max': 98.9458507777778, 'rt_min': 0.0}\n",
      "Use ReduceLROnPlateau!\n",
      "Use EarlyStopping: 10\n",
      "Epoch 1/40\n",
      "73/73 [==============================] - 4s 20ms/step - loss: 0.0018 - val_loss: 5.6040e-04\n",
      "\n",
      "Cor: 0.9961 - Cor_val: 0.9934, MAE: 1.3802 - MAE_val: 1.4779, R2: 0.9907 - R2_val: 0.985, MedianE: 1.0549 - MedianE_val: 1.0701, dt95: 7.7638 - dt95_val: 8.1672                                                                                                    \n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00056, saving model to tf_model/best_model.hdf5\n",
      "Epoch 2/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 4.5430e-04 - val_loss: 4.7878e-04\n",
      "\n",
      "Cor: 0.9971 - Cor_val: 0.9942, MAE: 1.1518 - MAE_val: 1.2803, R2: 0.9934 - R2_val: 0.9872, MedianE: 0.8484 - MedianE_val: 0.8923, dt95: 6.3215 - dt95_val: 6.9626                                                                                                    \n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00056 to 0.00048, saving model to tf_model/best_model.hdf5\n",
      "Epoch 3/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.4672e-04 - val_loss: 4.3205e-04\n",
      "\n",
      "Cor: 0.9975 - Cor_val: 0.9944, MAE: 1.0259 - MAE_val: 1.1491, R2: 0.9946 - R2_val: 0.9884, MedianE: 0.7552 - MedianE_val: 0.7582, dt95: 5.9372 - dt95_val: 7.0329                                                                                                    \n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00048 to 0.00043, saving model to tf_model/best_model.hdf5\n",
      "Epoch 4/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.8717e-04 - val_loss: 4.2868e-04\n",
      "\n",
      "Cor: 0.9976 - Cor_val: 0.9943, MAE: 0.9676 - MAE_val: 1.125, R2: 0.9951 - R2_val: 0.9885, MedianE: 0.6956 - MedianE_val: 0.7245, dt95: 5.709 - dt95_val: 6.7526                                                                                                    \n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00043 to 0.00043, saving model to tf_model/best_model.hdf5\n",
      "Epoch 5/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.7861e-04 - val_loss: 3.7991e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9949, MAE: 0.8455 - MAE_val: 1.0314, R2: 0.9964 - R2_val: 0.9898, MedianE: 0.639 - MedianE_val: 0.6737, dt95: 4.51 - dt95_val: 5.8898                                                                                                    \n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00043 to 0.00038, saving model to tf_model/best_model.hdf5\n",
      "Epoch 6/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.5758e-04 - val_loss: 4.0316e-04\n",
      "\n",
      "Cor: 0.9983 - Cor_val: 0.9947, MAE: 0.8619 - MAE_val: 1.0854, R2: 0.9964 - R2_val: 0.9892, MedianE: 0.6683 - MedianE_val: 0.7097, dt95: 4.622 - dt95_val: 6.6008                                                                                                    \n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00038\n",
      "Epoch 7/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.4955e-04 - val_loss: 3.8532e-04\n",
      "\n",
      "Cor: 0.9984 - Cor_val: 0.995, MAE: 0.8765 - MAE_val: 1.0985, R2: 0.9964 - R2_val: 0.9897, MedianE: 0.6997 - MedianE_val: 0.7588, dt95: 4.5245 - dt95_val: 6.1278                                                                                                    \n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00038\n",
      "Epoch 8/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.3290e-04 - val_loss: 4.3962e-04\n",
      "\n",
      "Cor: 0.9985 - Cor_val: 0.9947, MAE: 0.9041 - MAE_val: 1.1574, R2: 0.9959 - R2_val: 0.9882, MedianE: 0.673 - MedianE_val: 0.7417, dt95: 5.0972 - dt95_val: 7.2711                                                                                                    \n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00038\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 2.0459e-04 - val_loss: 3.8957e-04\n",
      "\n",
      "Cor: 0.9988 - Cor_val: 0.995, MAE: 0.7601 - MAE_val: 1.0348, R2: 0.9972 - R2_val: 0.9896, MedianE: 0.5827 - MedianE_val: 0.6732, dt95: 4.0716 - dt95_val: 6.3227                                                                                                    \n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00038\n",
      "Epoch 10/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8703e-04 - val_loss: 3.8808e-04\n",
      "\n",
      "Cor: 0.9988 - Cor_val: 0.995, MAE: 0.7509 - MAE_val: 1.0274, R2: 0.9972 - R2_val: 0.9896, MedianE: 0.565 - MedianE_val: 0.6591, dt95: 4.1446 - dt95_val: 5.798                                                                                                    \n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00038\n",
      "Epoch 11/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.0526e-04 - val_loss: 3.9192e-04\n",
      "\n",
      "Cor: 0.9988 - Cor_val: 0.9948, MAE: 0.7122 - MAE_val: 1.0367, R2: 0.9975 - R2_val: 0.9895, MedianE: 0.5374 - MedianE_val: 0.6675, dt95: 3.7693 - dt95_val: 5.7647                                                                                                    \n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00038\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8829e-04 - val_loss: 3.7890e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.995, MAE: 0.6811 - MAE_val: 1.0055, R2: 0.9977 - R2_val: 0.9898, MedianE: 0.5163 - MedianE_val: 0.6182, dt95: 3.6406 - dt95_val: 5.5842                                                                                                    \n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00038 to 0.00038, saving model to tf_model/best_model.hdf5\n",
      "Epoch 13/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8311e-04 - val_loss: 3.5692e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9952, MAE: 0.6497 - MAE_val: 0.9741, R2: 0.9979 - R2_val: 0.9904, MedianE: 0.4914 - MedianE_val: 0.6053, dt95: 3.4231 - dt95_val: 5.6125                                                                                                    \n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00038 to 0.00036, saving model to tf_model/best_model.hdf5\n",
      "Epoch 14/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7516e-04 - val_loss: 3.6765e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9951, MAE: 0.6639 - MAE_val: 0.9916, R2: 0.9977 - R2_val: 0.9902, MedianE: 0.5049 - MedianE_val: 0.6381, dt95: 3.6553 - dt95_val: 5.7162                                                                                                    \n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00036\n",
      "Epoch 15/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7155e-04 - val_loss: 3.8907e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9952, MAE: 0.7959 - MAE_val: 1.0544, R2: 0.997 - R2_val: 0.9896, MedianE: 0.6203 - MedianE_val: 0.6845, dt95: 4.267 - dt95_val: 6.0845                                                                                                    \n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00036\n",
      "Epoch 16/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 1.6693e-04 - val_loss: 3.6672e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9952, MAE: 0.6674 - MAE_val: 0.9935, R2: 0.9978 - R2_val: 0.9902, MedianE: 0.524 - MedianE_val: 0.6327, dt95: 3.4109 - dt95_val: 5.7065                                                                                                    \n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00036\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 17/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 1.5729e-04 - val_loss: 3.6697e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9953, MAE: 0.7054 - MAE_val: 1.0137, R2: 0.9976 - R2_val: 0.9902, MedianE: 0.556 - MedianE_val: 0.6609, dt95: 3.6851 - dt95_val: 5.6979                                                                                                    \n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00036\n",
      "Epoch 18/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.5534e-04 - val_loss: 3.9156e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9952, MAE: 0.7592 - MAE_val: 1.0358, R2: 0.9972 - R2_val: 0.9895, MedianE: 0.5734 - MedianE_val: 0.6438, dt95: 4.1996 - dt95_val: 5.8509                                                                                                    \n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00036\n",
      "Epoch 19/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 1.5705e-04 - val_loss: 3.6060e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9952, MAE: 0.6168 - MAE_val: 0.9735, R2: 0.9981 - R2_val: 0.9903, MedianE: 0.4717 - MedianE_val: 0.5981, dt95: 3.2978 - dt95_val: 5.4622                                                                                                    \n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00036\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 1.5706e-04 - val_loss: 3.5829e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9952, MAE: 0.6201 - MAE_val: 0.972, R2: 0.9981 - R2_val: 0.9904, MedianE: 0.4796 - MedianE_val: 0.6054, dt95: 3.2952 - dt95_val: 5.7048                                                                                                    \n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00036\n",
      "Epoch 21/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 1.5855e-04 - val_loss: 3.5716e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9953, MAE: 0.6052 - MAE_val: 0.9647, R2: 0.9981 - R2_val: 0.9904, MedianE: 0.4629 - MedianE_val: 0.5703, dt95: 3.2813 - dt95_val: 5.2205                                                                                                    \n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00036\n",
      "Epoch 22/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 1.5751e-04 - val_loss: 3.5145e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9953, MAE: 0.5908 - MAE_val: 0.9483, R2: 0.9982 - R2_val: 0.9906, MedianE: 0.4585 - MedianE_val: 0.5864, dt95: 3.153 - dt95_val: 5.3704                                                                                                    \n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00036 to 0.00035, saving model to tf_model/best_model.hdf5\n",
      "Epoch 23/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7268e-04 - val_loss: 3.5759e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9953, MAE: 0.6306 - MAE_val: 0.9765, R2: 0.998 - R2_val: 0.9904, MedianE: 0.4871 - MedianE_val: 0.6281, dt95: 3.355 - dt95_val: 5.4395                                                                                                    \n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00035\n",
      "Epoch 24/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 1.5591e-04 - val_loss: 3.5378e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9953, MAE: 0.5852 - MAE_val: 0.9543, R2: 0.9982 - R2_val: 0.9905, MedianE: 0.4589 - MedianE_val: 0.598, dt95: 3.0607 - dt95_val: 5.3147                                                                                                    \n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00035\n",
      "Epoch 25/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.6052e-04 - val_loss: 3.8736e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9951, MAE: 0.7136 - MAE_val: 1.0238, R2: 0.9975 - R2_val: 0.9896, MedianE: 0.5419 - MedianE_val: 0.6386, dt95: 3.8922 - dt95_val: 5.7051                                                                                                    \n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00035\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 26/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.5159e-04 - val_loss: 3.5677e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9952, MAE: 0.5867 - MAE_val: 0.9567, R2: 0.9982 - R2_val: 0.9904, MedianE: 0.452 - MedianE_val: 0.6055, dt95: 3.076 - dt95_val: 5.2011                                                                                                    \n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00035\n",
      "Epoch 27/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.5208e-04 - val_loss: 3.6250e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9952, MAE: 0.6068 - MAE_val: 0.9727, R2: 0.9981 - R2_val: 0.9903, MedianE: 0.4687 - MedianE_val: 0.6049, dt95: 3.2509 - dt95_val: 5.3513                                                                                                    \n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00035\n",
      "Epoch 28/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.5128e-04 - val_loss: 3.6003e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9953, MAE: 0.6138 - MAE_val: 0.977, R2: 0.9981 - R2_val: 0.9904, MedianE: 0.4771 - MedianE_val: 0.6104, dt95: 3.2774 - dt95_val: 5.4929                                                                                                    \n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00035\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 29/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.5265e-04 - val_loss: 3.6766e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9952, MAE: 0.6373 - MAE_val: 0.9874, R2: 0.998 - R2_val: 0.9902, MedianE: 0.4842 - MedianE_val: 0.6114, dt95: 3.4625 - dt95_val: 5.3766                                                                                                    \n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00035\n",
      "Epoch 30/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.5523e-04 - val_loss: 3.6558e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9952, MAE: 0.6239 - MAE_val: 0.983, R2: 0.9981 - R2_val: 0.9902, MedianE: 0.4764 - MedianE_val: 0.6085, dt95: 3.3813 - dt95_val: 5.5889                                                                                                    \n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00035\n",
      "Epoch 31/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 1.5018e-04 - val_loss: 3.6239e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9952, MAE: 0.6006 - MAE_val: 0.9682, R2: 0.9982 - R2_val: 0.9903, MedianE: 0.4677 - MedianE_val: 0.5847, dt95: 3.2338 - dt95_val: 5.3745                                                                                                    \n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00035\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 32/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 1.4629e-04 - val_loss: 3.6276e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9952, MAE: 0.6052 - MAE_val: 0.9724, R2: 0.9982 - R2_val: 0.9903, MedianE: 0.4708 - MedianE_val: 0.6122, dt95: 3.2194 - dt95_val: 5.356                                                                                                    \n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00035\n",
      "Epoch 00032: early stopping\n",
      "\n",
      "Deep learning model: 5\n",
      "Load aa coding data from file ../models/base_models_PXD006109/aa.tsv\n",
      "AA types: 21\n",
      "Longest peptide in training data: 41\n",
      "\n",
      "Use test file tf_model//validation.tsv\n",
      "Longest peptide in test data: 30\n",
      "\n",
      "['1', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
      "RT range: 0 - 98\n",
      "\n",
      "X_train shape:\n",
      "(4626, 48, 21)\n",
      "X_test shape:\n",
      "(515, 48, 21)\n",
      "Modeling start ...\n",
      "48\n",
      "Perform transfer learning ...\n",
      "The number of layers: 26\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08b0398690>\n",
      "Use optimizer: Adam from saved model\n",
      "Used optimizer:\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08bf942650>\n",
      "{'scaling_method': 'min_max', 'rt_max': 98.9458507777778, 'rt_min': 0.0}\n",
      "Use ReduceLROnPlateau!\n",
      "Use EarlyStopping: 10\n",
      "Epoch 1/40\n",
      "73/73 [==============================] - 5s 30ms/step - loss: 0.0020 - val_loss: 5.1409e-04\n",
      "\n",
      "Cor: 0.996 - Cor_val: 0.9936, MAE: 1.3013 - MAE_val: 1.3897, R2: 0.9911 - R2_val: 0.9862, MedianE: 0.9488 - MedianE_val: 0.9795, dt95: 7.4381 - dt95_val: 7.6627                                                                                                    \n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00051, saving model to tf_model/best_model.hdf5\n",
      "Epoch 2/40\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 5.9071e-04 - val_loss: 5.0836e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9939, MAE: 1.2764 - MAE_val: 1.4167, R2: 0.9924 - R2_val: 0.9864, MedianE: 1.0436 - MedianE_val: 1.0843, dt95: 6.4423 - dt95_val: 7.4038                                                                                                    \n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00051 to 0.00051, saving model to tf_model/best_model.hdf5\n",
      "Epoch 3/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 5.6641e-04 - val_loss: 4.4403e-04\n",
      "\n",
      "Cor: 0.9972 - Cor_val: 0.9941, MAE: 1.046 - MAE_val: 1.2108, R2: 0.9943 - R2_val: 0.9881, MedianE: 0.7515 - MedianE_val: 0.8017, dt95: 6.0117 - dt95_val: 7.1706                                                                                                    \n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00051 to 0.00044, saving model to tf_model/best_model.hdf5\n",
      "Epoch 4/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 4.9282e-04 - val_loss: 5.6291e-04\n",
      "\n",
      "Cor: 0.9974 - Cor_val: 0.9941, MAE: 1.3782 - MAE_val: 1.5006, R2: 0.9916 - R2_val: 0.9849, MedianE: 1.118 - MedianE_val: 1.0797, dt95: 7.1372 - dt95_val: 8.0345                                                                                                    \n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00044\n",
      "Epoch 5/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 4.7416e-04 - val_loss: 4.7961e-04\n",
      "\n",
      "Cor: 0.9978 - Cor_val: 0.9939, MAE: 1.0729 - MAE_val: 1.3318, R2: 0.9949 - R2_val: 0.9872, MedianE: 0.8926 - MedianE_val: 0.9771, dt95: 5.2709 - dt95_val: 7.0742                                                                                                    \n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00044\n",
      "Epoch 6/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 4.5769e-04 - val_loss: 4.6478e-04\n",
      "\n",
      "Cor: 0.9979 - Cor_val: 0.9943, MAE: 1.039 - MAE_val: 1.2735, R2: 0.9948 - R2_val: 0.9875, MedianE: 0.7897 - MedianE_val: 0.8924, dt95: 5.7749 - dt95_val: 6.9795                                                                                                    \n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00044\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 4.4057e-04 - val_loss: 4.7176e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9942, MAE: 1.0128 - MAE_val: 1.333, R2: 0.9954 - R2_val: 0.9874, MedianE: 0.8351 - MedianE_val: 1.0271, dt95: 5.0597 - dt95_val: 6.9759                                                                                                    \n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00044\n",
      "Epoch 8/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 3.9812e-04 - val_loss: 4.2996e-04\n",
      "\n",
      "Cor: 0.9983 - Cor_val: 0.9944, MAE: 0.8546 - MAE_val: 1.192, R2: 0.9964 - R2_val: 0.9885, MedianE: 0.6409 - MedianE_val: 0.8262, dt95: 4.7246 - dt95_val: 6.8007                                                                                                    \n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00044 to 0.00043, saving model to tf_model/best_model.hdf5\n",
      "Epoch 9/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 3.9723e-04 - val_loss: 4.2429e-04\n",
      "\n",
      "Cor: 0.9984 - Cor_val: 0.9945, MAE: 0.8461 - MAE_val: 1.1763, R2: 0.9965 - R2_val: 0.9886, MedianE: 0.654 - MedianE_val: 0.747, dt95: 4.5501 - dt95_val: 7.2424                                                                                                    \n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00043 to 0.00042, saving model to tf_model/best_model.hdf5\n",
      "Epoch 10/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 3.7594e-04 - val_loss: 4.2050e-04\n",
      "\n",
      "Cor: 0.9984 - Cor_val: 0.9944, MAE: 0.8041 - MAE_val: 1.1747, R2: 0.9968 - R2_val: 0.9887, MedianE: 0.6037 - MedianE_val: 0.7695, dt95: 4.4116 - dt95_val: 6.7602                                                                                                    \n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00042 to 0.00042, saving model to tf_model/best_model.hdf5\n",
      "Epoch 11/40\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 3.8688e-04 - val_loss: 4.4440e-04\n",
      "\n",
      "Cor: 0.9985 - Cor_val: 0.9943, MAE: 0.8527 - MAE_val: 1.237, R2: 0.9966 - R2_val: 0.9881, MedianE: 0.6722 - MedianE_val: 0.8389, dt95: 4.4636 - dt95_val: 7.048                                                                                                    \n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00042\n",
      "Epoch 12/40\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 4.0115e-04 - val_loss: 4.3676e-04\n",
      "\n",
      "Cor: 0.9986 - Cor_val: 0.9944, MAE: 0.8275 - MAE_val: 1.2161, R2: 0.9968 - R2_val: 0.9883, MedianE: 0.6417 - MedianE_val: 0.8552, dt95: 4.3379 - dt95_val: 6.5221                                                                                                    \n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00042\n",
      "Epoch 13/40\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 3.8277e-04 - val_loss: 4.2032e-04\n",
      "\n",
      "Cor: 0.9986 - Cor_val: 0.9944, MAE: 0.7435 - MAE_val: 1.1498, R2: 0.9972 - R2_val: 0.9887, MedianE: 0.5634 - MedianE_val: 0.7624, dt95: 3.9699 - dt95_val: 6.936                                                                                                    \n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00042 to 0.00042, saving model to tf_model/best_model.hdf5\n",
      "Epoch 14/40\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 3.6787e-04 - val_loss: 4.4136e-04\n",
      "\n",
      "Cor: 0.9987 - Cor_val: 0.9943, MAE: 0.7976 - MAE_val: 1.2059, R2: 0.997 - R2_val: 0.9882, MedianE: 0.6328 - MedianE_val: 0.8487, dt95: 4.1162 - dt95_val: 6.8537                                                                                                    \n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00042\n",
      "Epoch 15/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 3.5978e-04 - val_loss: 4.4730e-04\n",
      "\n",
      "Cor: 0.9987 - Cor_val: 0.9944, MAE: 0.8306 - MAE_val: 1.2111, R2: 0.9967 - R2_val: 0.988, MedianE: 0.6337 - MedianE_val: 0.8459, dt95: 4.4712 - dt95_val: 7.1582                                                                                                    \n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00042\n",
      "Epoch 16/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 3.6864e-04 - val_loss: 4.5383e-04\n",
      "\n",
      "Cor: 0.9986 - Cor_val: 0.9942, MAE: 0.8387 - MAE_val: 1.2286, R2: 0.9968 - R2_val: 0.9878, MedianE: 0.6575 - MedianE_val: 0.8317, dt95: 4.4187 - dt95_val: 7.3839                                                                                                    \n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00042\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 17/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 3.5502e-04 - val_loss: 4.2578e-04\n",
      "\n",
      "Cor: 0.9988 - Cor_val: 0.9943, MAE: 0.7077 - MAE_val: 1.149, R2: 0.9976 - R2_val: 0.9886, MedianE: 0.5489 - MedianE_val: 0.7455, dt95: 3.7633 - dt95_val: 7.1117                                                                                                    \n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00042\n",
      "Epoch 18/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 3.3604e-04 - val_loss: 4.2867e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9943, MAE: 0.6949 - MAE_val: 1.1457, R2: 0.9976 - R2_val: 0.9885, MedianE: 0.5441 - MedianE_val: 0.764, dt95: 3.7585 - dt95_val: 6.3424                                                                                                    \n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00042\n",
      "Epoch 19/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 3.3766e-04 - val_loss: 4.4749e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9943, MAE: 0.7544 - MAE_val: 1.1965, R2: 0.9973 - R2_val: 0.988, MedianE: 0.5841 - MedianE_val: 0.8304, dt95: 3.9956 - dt95_val: 7.1587                                                                                                    \n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00042\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 20/40\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 3.4392e-04 - val_loss: 4.3385e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9944, MAE: 0.733 - MAE_val: 1.1738, R2: 0.9975 - R2_val: 0.9884, MedianE: 0.5888 - MedianE_val: 0.7924, dt95: 3.7705 - dt95_val: 6.8282                                                                                                    \n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00042\n",
      "Epoch 21/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 3.4670e-04 - val_loss: 4.2266e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9944, MAE: 0.6762 - MAE_val: 1.1378, R2: 0.9978 - R2_val: 0.9887, MedianE: 0.5266 - MedianE_val: 0.7518, dt95: 3.5792 - dt95_val: 6.476                                                                                                    \n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00042\n",
      "Epoch 22/40\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 3.2957e-04 - val_loss: 4.2712e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9944, MAE: 0.7132 - MAE_val: 1.1615, R2: 0.9977 - R2_val: 0.9886, MedianE: 0.5654 - MedianE_val: 0.7807, dt95: 3.6968 - dt95_val: 6.8937                                                                                                    \n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00042\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 23/40\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 3.2775e-04 - val_loss: 4.2489e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9944, MAE: 0.6688 - MAE_val: 1.1389, R2: 0.9978 - R2_val: 0.9886, MedianE: 0.52 - MedianE_val: 0.745, dt95: 3.5786 - dt95_val: 6.8458                                                                                                    \n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00042\n",
      "Epoch 00023: early stopping\n",
      "\n",
      "Deep learning model: 6\n",
      "Load aa coding data from file ../models/base_models_PXD006109/aa.tsv\n",
      "AA types: 21\n",
      "Longest peptide in training data: 41\n",
      "\n",
      "Use test file tf_model//validation.tsv\n",
      "Longest peptide in test data: 30\n",
      "\n",
      "['1', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
      "RT range: 0 - 98\n",
      "\n",
      "X_train shape:\n",
      "(4626, 48, 21)\n",
      "X_test shape:\n",
      "(515, 48, 21)\n",
      "Modeling start ...\n",
      "48\n",
      "Perform transfer learning ...\n",
      "The number of layers: 22\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f0834642150>\n",
      "Use optimizer: Adam from saved model\n",
      "Used optimizer:\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08b029ab10>\n",
      "{'scaling_method': 'min_max', 'rt_max': 98.9458507777778, 'rt_min': 0.0}\n",
      "Use ReduceLROnPlateau!\n",
      "Use EarlyStopping: 10\n",
      "Epoch 1/40\n",
      "73/73 [==============================] - 4s 21ms/step - loss: 0.0019 - val_loss: 5.5168e-04\n",
      "\n",
      "Cor: 0.996 - Cor_val: 0.9929, MAE: 1.2492 - MAE_val: 1.3563, R2: 0.9915 - R2_val: 0.9852, MedianE: 0.8827 - MedianE_val: 0.8508, dt95: 7.599 - dt95_val: 8.2951                                                                                                    \n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00055, saving model to tf_model/best_model.hdf5\n",
      "Epoch 2/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 4.3996e-04 - val_loss: 5.6152e-04\n",
      "\n",
      "Cor: 0.9972 - Cor_val: 0.9941, MAE: 1.3766 - MAE_val: 1.4522, R2: 0.9912 - R2_val: 0.985, MedianE: 1.0514 - MedianE_val: 1.0128, dt95: 7.4612 - dt95_val: 8.1699                                                                                                    \n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00055\n",
      "Epoch 3/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.7772e-04 - val_loss: 4.5436e-04\n",
      "\n",
      "Cor: 0.9978 - Cor_val: 0.9945, MAE: 1.0368 - MAE_val: 1.1833, R2: 0.9946 - R2_val: 0.9878, MedianE: 0.7532 - MedianE_val: 0.7521, dt95: 5.8554 - dt95_val: 6.3618                                                                                                    \n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00055 to 0.00045, saving model to tf_model/best_model.hdf5\n",
      "Epoch 4/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.1008e-04 - val_loss: 4.2098e-04\n",
      "\n",
      "Cor: 0.9979 - Cor_val: 0.9944, MAE: 0.8895 - MAE_val: 1.1149, R2: 0.9959 - R2_val: 0.9887, MedianE: 0.6478 - MedianE_val: 0.7001, dt95: 4.8343 - dt95_val: 6.5181                                                                                                    \n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00045 to 0.00042, saving model to tf_model/best_model.hdf5\n",
      "Epoch 5/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 3.0102e-04 - val_loss: 4.7031e-04\n",
      "\n",
      "Cor: 0.998 - Cor_val: 0.994, MAE: 0.9291 - MAE_val: 1.1669, R2: 0.9955 - R2_val: 0.9874, MedianE: 0.6653 - MedianE_val: 0.6865, dt95: 5.3484 - dt95_val: 7.2736                                                                                                    \n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00042\n",
      "Epoch 6/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.9301e-04 - val_loss: 4.3396e-04\n",
      "\n",
      "Cor: 0.9984 - Cor_val: 0.9944, MAE: 0.8578 - MAE_val: 1.1422, R2: 0.9964 - R2_val: 0.9884, MedianE: 0.6603 - MedianE_val: 0.7525, dt95: 4.4526 - dt95_val: 6.4713                                                                                                    \n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00042\n",
      "Epoch 7/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.6096e-04 - val_loss: 4.6051e-04\n",
      "\n",
      "Cor: 0.9984 - Cor_val: 0.9943, MAE: 0.8921 - MAE_val: 1.1605, R2: 0.9959 - R2_val: 0.9877, MedianE: 0.6447 - MedianE_val: 0.6735, dt95: 5.1519 - dt95_val: 7.1527                                                                                                    \n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00042\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.3494e-04 - val_loss: 4.4818e-04\n",
      "\n",
      "Cor: 0.9986 - Cor_val: 0.9945, MAE: 0.877 - MAE_val: 1.157, R2: 0.9963 - R2_val: 0.988, MedianE: 0.6588 - MedianE_val: 0.7166, dt95: 4.8401 - dt95_val: 7.0043                                                                                                    \n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00042\n",
      "Epoch 9/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.3436e-04 - val_loss: 4.1247e-04\n",
      "\n",
      "Cor: 0.9987 - Cor_val: 0.9945, MAE: 0.7359 - MAE_val: 1.0862, R2: 0.9973 - R2_val: 0.989, MedianE: 0.5674 - MedianE_val: 0.6986, dt95: 3.861 - dt95_val: 6.3209                                                                                                    \n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00042 to 0.00041, saving model to tf_model/best_model.hdf5\n",
      "Epoch 10/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.1930e-04 - val_loss: 4.0127e-04\n",
      "\n",
      "Cor: 0.9988 - Cor_val: 0.9947, MAE: 0.7167 - MAE_val: 1.0518, R2: 0.9975 - R2_val: 0.9893, MedianE: 0.5466 - MedianE_val: 0.6415, dt95: 3.8295 - dt95_val: 6.4488                                                                                                    \n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00041 to 0.00040, saving model to tf_model/best_model.hdf5\n",
      "Epoch 11/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.2157e-04 - val_loss: 4.1204e-04\n",
      "\n",
      "Cor: 0.9988 - Cor_val: 0.9946, MAE: 0.7195 - MAE_val: 1.0999, R2: 0.9975 - R2_val: 0.989, MedianE: 0.5615 - MedianE_val: 0.719, dt95: 3.7202 - dt95_val: 6.0707                                                                                                    \n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00040\n",
      "Epoch 12/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.1403e-04 - val_loss: 4.3418e-04\n",
      "\n",
      "Cor: 0.9988 - Cor_val: 0.9944, MAE: 0.7572 - MAE_val: 1.1239, R2: 0.9972 - R2_val: 0.9884, MedianE: 0.5751 - MedianE_val: 0.6927, dt95: 4.1749 - dt95_val: 6.6544                                                                                                    \n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00040\n",
      "Epoch 13/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.2291e-04 - val_loss: 4.0718e-04\n",
      "\n",
      "Cor: 0.9989 - Cor_val: 0.9946, MAE: 0.6714 - MAE_val: 1.0803, R2: 0.9977 - R2_val: 0.9891, MedianE: 0.5141 - MedianE_val: 0.7006, dt95: 3.494 - dt95_val: 6.1585                                                                                                    \n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00040\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.9103e-04 - val_loss: 4.0686e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9947, MAE: 0.6733 - MAE_val: 1.0748, R2: 0.9978 - R2_val: 0.9891, MedianE: 0.5142 - MedianE_val: 0.6521, dt95: 3.5481 - dt95_val: 6.6131                                                                                                    \n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00040\n",
      "Epoch 15/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.9097e-04 - val_loss: 4.3612e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9946, MAE: 0.7732 - MAE_val: 1.1477, R2: 0.9972 - R2_val: 0.9883, MedianE: 0.5922 - MedianE_val: 0.7411, dt95: 4.0574 - dt95_val: 7.2965                                                                                                    \n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00040\n",
      "Epoch 16/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.9275e-04 - val_loss: 4.1442e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9946, MAE: 0.6899 - MAE_val: 1.0992, R2: 0.9977 - R2_val: 0.9889, MedianE: 0.5454 - MedianE_val: 0.7, dt95: 3.614 - dt95_val: 6.5031                                                                                                    \n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00040\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 17/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7914e-04 - val_loss: 4.0078e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9947, MAE: 0.6352 - MAE_val: 1.0653, R2: 0.998 - R2_val: 0.9893, MedianE: 0.4922 - MedianE_val: 0.6478, dt95: 3.3521 - dt95_val: 6.3399                                                                                                    \n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00040 to 0.00040, saving model to tf_model/best_model.hdf5\n",
      "Epoch 18/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8446e-04 - val_loss: 3.9968e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9947, MAE: 0.6316 - MAE_val: 1.0572, R2: 0.998 - R2_val: 0.9893, MedianE: 0.4739 - MedianE_val: 0.6556, dt95: 3.351 - dt95_val: 6.3984                                                                                                    \n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00040 to 0.00040, saving model to tf_model/best_model.hdf5\n",
      "Epoch 19/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.9061e-04 - val_loss: 3.9486e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9947, MAE: 0.5897 - MAE_val: 1.0388, R2: 0.9982 - R2_val: 0.9894, MedianE: 0.4477 - MedianE_val: 0.63, dt95: 3.1438 - dt95_val: 6.1038                                                                                                    \n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00040 to 0.00039, saving model to tf_model/best_model.hdf5\n",
      "Epoch 20/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7618e-04 - val_loss: 4.0125e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9947, MAE: 0.638 - MAE_val: 1.0745, R2: 0.998 - R2_val: 0.9893, MedianE: 0.5046 - MedianE_val: 0.695, dt95: 3.2166 - dt95_val: 6.1643                                                                                                    \n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00039\n",
      "Epoch 21/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7872e-04 - val_loss: 3.9674e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9947, MAE: 0.5789 - MAE_val: 1.0379, R2: 0.9983 - R2_val: 0.9894, MedianE: 0.4384 - MedianE_val: 0.5966, dt95: 3.0908 - dt95_val: 5.9398                                                                                                    \n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00039\n",
      "Epoch 22/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 1.7459e-04 - val_loss: 3.9338e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9947, MAE: 0.5735 - MAE_val: 1.034, R2: 0.9983 - R2_val: 0.9895, MedianE: 0.4305 - MedianE_val: 0.6019, dt95: 3.0348 - dt95_val: 6.0522                                                                                                    \n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00039 to 0.00039, saving model to tf_model/best_model.hdf5\n",
      "Epoch 23/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8291e-04 - val_loss: 4.0143e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9947, MAE: 0.6115 - MAE_val: 1.0615, R2: 0.9981 - R2_val: 0.9892, MedianE: 0.4716 - MedianE_val: 0.6286, dt95: 3.1876 - dt95_val: 6.2783                                                                                                    \n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00039\n",
      "Epoch 24/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7379e-04 - val_loss: 3.9327e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9947, MAE: 0.5756 - MAE_val: 1.0371, R2: 0.9983 - R2_val: 0.9895, MedianE: 0.4391 - MedianE_val: 0.6136, dt95: 3.0198 - dt95_val: 6.1066                                                                                                    \n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00039 to 0.00039, saving model to tf_model/best_model.hdf5\n",
      "Epoch 25/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7493e-04 - val_loss: 3.9775e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9947, MAE: 0.6062 - MAE_val: 1.0537, R2: 0.9982 - R2_val: 0.9893, MedianE: 0.4758 - MedianE_val: 0.6249, dt95: 3.1717 - dt95_val: 6.4527                                                                                                    \n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00039\n",
      "Epoch 26/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8430e-04 - val_loss: 4.0691e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9946, MAE: 0.6014 - MAE_val: 1.0611, R2: 0.9982 - R2_val: 0.9891, MedianE: 0.4614 - MedianE_val: 0.6212, dt95: 3.2236 - dt95_val: 6.2469                                                                                                    \n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00039\n",
      "Epoch 27/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.8274e-04 - val_loss: 4.0915e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9946, MAE: 0.6226 - MAE_val: 1.0602, R2: 0.998 - R2_val: 0.989, MedianE: 0.4727 - MedianE_val: 0.6457, dt95: 3.3407 - dt95_val: 6.2719                                                                                                    \n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00039\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 28/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7704e-04 - val_loss: 4.0497e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9947, MAE: 0.6048 - MAE_val: 1.0509, R2: 0.9982 - R2_val: 0.9892, MedianE: 0.463 - MedianE_val: 0.616, dt95: 3.1407 - dt95_val: 6.4809                                                                                                    \n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00039\n",
      "Epoch 29/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7416e-04 - val_loss: 4.0739e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9946, MAE: 0.6028 - MAE_val: 1.0557, R2: 0.9982 - R2_val: 0.9891, MedianE: 0.4605 - MedianE_val: 0.6192, dt95: 3.1458 - dt95_val: 6.4441                                                                                                    \n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00039\n",
      "Epoch 30/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.6855e-04 - val_loss: 4.0333e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9946, MAE: 0.5719 - MAE_val: 1.052, R2: 0.9983 - R2_val: 0.9892, MedianE: 0.44 - MedianE_val: 0.6269, dt95: 3.0272 - dt95_val: 6.2844                                                                                                    \n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00039\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 31/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.6365e-04 - val_loss: 4.0445e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9946, MAE: 0.5831 - MAE_val: 1.0518, R2: 0.9983 - R2_val: 0.9892, MedianE: 0.4426 - MedianE_val: 0.6226, dt95: 3.0264 - dt95_val: 6.3921                                                                                                    \n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00039\n",
      "Epoch 32/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.6423e-04 - val_loss: 4.0532e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9946, MAE: 0.5811 - MAE_val: 1.0528, R2: 0.9983 - R2_val: 0.9891, MedianE: 0.4425 - MedianE_val: 0.637, dt95: 3.0594 - dt95_val: 6.3118                                                                                                    \n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00039\n",
      "Epoch 33/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7176e-04 - val_loss: 4.0203e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9946, MAE: 0.5582 - MAE_val: 1.0458, R2: 0.9984 - R2_val: 0.9892, MedianE: 0.4252 - MedianE_val: 0.6051, dt95: 2.9702 - dt95_val: 6.162                                                                                                    \n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00039\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 34/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.7214e-04 - val_loss: 4.0467e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9946, MAE: 0.5757 - MAE_val: 1.0523, R2: 0.9983 - R2_val: 0.9892, MedianE: 0.4387 - MedianE_val: 0.6217, dt95: 3.0412 - dt95_val: 6.3122                                                                                                    \n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00039\n",
      "Epoch 00034: early stopping\n",
      "\n",
      "Deep learning model: 7\n",
      "Load aa coding data from file ../models/base_models_PXD006109/aa.tsv\n",
      "AA types: 21\n",
      "Longest peptide in training data: 41\n",
      "\n",
      "Use test file tf_model//validation.tsv\n",
      "Longest peptide in test data: 30\n",
      "\n",
      "['1', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
      "RT range: 0 - 98\n",
      "\n",
      "X_train shape:\n",
      "(4626, 48, 21)\n",
      "X_test shape:\n",
      "(515, 48, 21)\n",
      "Modeling start ...\n",
      "48\n",
      "Perform transfer learning ...\n",
      "The number of layers: 19\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08b0114450>\n",
      "Use optimizer: Adam from saved model\n",
      "Used optimizer:\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08343b7c50>\n",
      "{'scaling_method': 'min_max', 'rt_max': 98.9458507777778, 'rt_min': 0.0}\n",
      "Use ReduceLROnPlateau!\n",
      "Use EarlyStopping: 10\n",
      "Epoch 1/40\n",
      "73/73 [==============================] - 4s 21ms/step - loss: 0.0030 - val_loss: 5.7341e-04\n",
      "\n",
      "Cor: 0.9946 - Cor_val: 0.9929, MAE: 1.5608 - MAE_val: 1.5162, R2: 0.9884 - R2_val: 0.9846, MedianE: 1.2372 - MedianE_val: 1.161, dt95: 8.1582 - dt95_val: 7.5726                                                                                                    \n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00057, saving model to tf_model/best_model.hdf5\n",
      "Epoch 2/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0014 - val_loss: 5.5030e-04\n",
      "\n",
      "Cor: 0.9951 - Cor_val: 0.9927, MAE: 1.4059 - MAE_val: 1.4324, R2: 0.9902 - R2_val: 0.9853, MedianE: 1.0585 - MedianE_val: 1.0901, dt95: 7.6555 - dt95_val: 6.9601                                                                                                    \n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00057 to 0.00055, saving model to tf_model/best_model.hdf5\n",
      "Epoch 3/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0013 - val_loss: 5.6958e-04\n",
      "\n",
      "Cor: 0.996 - Cor_val: 0.9931, MAE: 1.365 - MAE_val: 1.4421, R2: 0.9905 - R2_val: 0.9847, MedianE: 0.9984 - MedianE_val: 1.0966, dt95: 7.6929 - dt95_val: 7.3131                                                                                                    \n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00055\n",
      "Epoch 4/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0013 - val_loss: 5.1010e-04\n",
      "\n",
      "Cor: 0.9965 - Cor_val: 0.9932, MAE: 1.1509 - MAE_val: 1.2788, R2: 0.993 - R2_val: 0.9863, MedianE: 0.8427 - MedianE_val: 0.8629, dt95: 6.6531 - dt95_val: 6.6982                                                                                                    \n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00055 to 0.00051, saving model to tf_model/best_model.hdf5\n",
      "Epoch 5/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0013 - val_loss: 5.5003e-04\n",
      "\n",
      "Cor: 0.9966 - Cor_val: 0.993, MAE: 1.2919 - MAE_val: 1.4133, R2: 0.9923 - R2_val: 0.9853, MedianE: 1.04 - MedianE_val: 1.0255, dt95: 6.5891 - dt95_val: 8.0774                                                                                                    \n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00051\n",
      "Epoch 6/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0012 - val_loss: 5.2576e-04\n",
      "\n",
      "Cor: 0.9966 - Cor_val: 0.9933, MAE: 1.2098 - MAE_val: 1.3717, R2: 0.993 - R2_val: 0.9859, MedianE: 0.9461 - MedianE_val: 0.9891, dt95: 6.2204 - dt95_val: 7.5784                                                                                                    \n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00051\n",
      "Epoch 7/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0013 - val_loss: 7.1752e-04\n",
      "\n",
      "Cor: 0.9967 - Cor_val: 0.9929, MAE: 1.554 - MAE_val: 1.6307, R2: 0.9881 - R2_val: 0.9808, MedianE: 1.0827 - MedianE_val: 1.0255, dt95: 8.9581 - dt95_val: 9.1598                                                                                                    \n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00051\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0012 - val_loss: 5.0061e-04\n",
      "\n",
      "Cor: 0.9973 - Cor_val: 0.9933, MAE: 1.0225 - MAE_val: 1.2433, R2: 0.9945 - R2_val: 0.9866, MedianE: 0.7422 - MedianE_val: 0.8398, dt95: 5.5318 - dt95_val: 7.4749                                                                                                    \n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00051 to 0.00050, saving model to tf_model/best_model.hdf5\n",
      "Epoch 9/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0013 - val_loss: 5.1993e-04\n",
      "\n",
      "Cor: 0.9972 - Cor_val: 0.9932, MAE: 1.1198 - MAE_val: 1.3353, R2: 0.994 - R2_val: 0.9861, MedianE: 0.8936 - MedianE_val: 0.9572, dt95: 5.6503 - dt95_val: 6.7816                                                                                                    \n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00050\n",
      "Epoch 10/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0012 - val_loss: 5.1557e-04\n",
      "\n",
      "Cor: 0.9971 - Cor_val: 0.9931, MAE: 1.0812 - MAE_val: 1.3049, R2: 0.9941 - R2_val: 0.9862, MedianE: 0.8292 - MedianE_val: 0.9653, dt95: 5.896 - dt95_val: 6.9829                                                                                                    \n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00050\n",
      "Epoch 11/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 5.2865e-04\n",
      "\n",
      "Cor: 0.9974 - Cor_val: 0.9931, MAE: 1.1013 - MAE_val: 1.3429, R2: 0.9942 - R2_val: 0.9858, MedianE: 0.8823 - MedianE_val: 1.0093, dt95: 5.6251 - dt95_val: 7.2272                                                                                                    \n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0012 - val_loss: 5.2470e-04\n",
      "\n",
      "Cor: 0.9975 - Cor_val: 0.9931, MAE: 1.0336 - MAE_val: 1.2815, R2: 0.9946 - R2_val: 0.9859, MedianE: 0.7764 - MedianE_val: 0.8562, dt95: 5.7083 - dt95_val: 7.4291                                                                                                    \n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00050\n",
      "Epoch 13/40\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.0011 - val_loss: 5.0551e-04\n",
      "\n",
      "Cor: 0.9977 - Cor_val: 0.9932, MAE: 0.9733 - MAE_val: 1.2449, R2: 0.9952 - R2_val: 0.9865, MedianE: 0.7462 - MedianE_val: 0.8852, dt95: 5.1755 - dt95_val: 7.1354                                                                                                    \n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00050\n",
      "Epoch 14/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0012 - val_loss: 5.2875e-04\n",
      "\n",
      "Cor: 0.9977 - Cor_val: 0.9934, MAE: 1.1081 - MAE_val: 1.3126, R2: 0.9939 - R2_val: 0.9858, MedianE: 0.8353 - MedianE_val: 0.8556, dt95: 6.2207 - dt95_val: 7.6926                                                                                                    \n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 15/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 4.7982e-04\n",
      "\n",
      "Cor: 0.9979 - Cor_val: 0.9936, MAE: 0.9108 - MAE_val: 1.1867, R2: 0.9956 - R2_val: 0.9871, MedianE: 0.6888 - MedianE_val: 0.8098, dt95: 4.9618 - dt95_val: 7.0011                                                                                                    \n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00050 to 0.00048, saving model to tf_model/best_model.hdf5\n",
      "Epoch 16/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 4.7770e-04\n",
      "\n",
      "Cor: 0.9979 - Cor_val: 0.9936, MAE: 0.8993 - MAE_val: 1.1902, R2: 0.9958 - R2_val: 0.9872, MedianE: 0.682 - MedianE_val: 0.821, dt95: 4.7789 - dt95_val: 7.1304                                                                                                    \n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00048 to 0.00048, saving model to tf_model/best_model.hdf5\n",
      "Epoch 17/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 4.8263e-04\n",
      "\n",
      "Cor: 0.9979 - Cor_val: 0.9936, MAE: 0.919 - MAE_val: 1.1999, R2: 0.9956 - R2_val: 0.9871, MedianE: 0.6965 - MedianE_val: 0.8315, dt95: 4.9233 - dt95_val: 6.6036                                                                                                    \n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00048\n",
      "Epoch 18/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 4.8606e-04\n",
      "\n",
      "Cor: 0.9979 - Cor_val: 0.9935, MAE: 0.9327 - MAE_val: 1.2261, R2: 0.9956 - R2_val: 0.987, MedianE: 0.7245 - MedianE_val: 0.8805, dt95: 4.9072 - dt95_val: 6.9104                                                                                                    \n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00048\n",
      "Epoch 19/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 5.1417e-04\n",
      "\n",
      "Cor: 0.9979 - Cor_val: 0.9933, MAE: 0.9468 - MAE_val: 1.2472, R2: 0.9955 - R2_val: 0.9862, MedianE: 0.7171 - MedianE_val: 0.8509, dt95: 5.0722 - dt95_val: 7.3779                                                                                                    \n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00048\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 4.9376e-04\n",
      "\n",
      "Cor: 0.9979 - Cor_val: 0.9934, MAE: 0.9186 - MAE_val: 1.2134, R2: 0.9957 - R2_val: 0.9868, MedianE: 0.6977 - MedianE_val: 0.8529, dt95: 4.9101 - dt95_val: 7.3984                                                                                                    \n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00048\n",
      "Epoch 21/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0010 - val_loss: 4.9840e-04\n",
      "\n",
      "Cor: 0.9979 - Cor_val: 0.9933, MAE: 0.9364 - MAE_val: 1.2362, R2: 0.9956 - R2_val: 0.9866, MedianE: 0.7307 - MedianE_val: 0.8381, dt95: 4.8973 - dt95_val: 7.3439                                                                                                    \n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00048\n",
      "Epoch 22/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 4.9326e-04\n",
      "\n",
      "Cor: 0.9979 - Cor_val: 0.9934, MAE: 0.9051 - MAE_val: 1.2206, R2: 0.9958 - R2_val: 0.9868, MedianE: 0.6873 - MedianE_val: 0.8548, dt95: 4.7687 - dt95_val: 7.1215                                                                                                    \n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00048\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 4.8692e-04\n",
      "\n",
      "Cor: 0.998 - Cor_val: 0.9935, MAE: 0.8913 - MAE_val: 1.2081, R2: 0.9959 - R2_val: 0.987, MedianE: 0.6771 - MedianE_val: 0.8198, dt95: 4.7108 - dt95_val: 7.0252                                                                                                    \n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00048\n",
      "Epoch 24/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 4.8428e-04\n",
      "\n",
      "Cor: 0.998 - Cor_val: 0.9935, MAE: 0.886 - MAE_val: 1.202, R2: 0.996 - R2_val: 0.987, MedianE: 0.6722 - MedianE_val: 0.8144, dt95: 4.6715 - dt95_val: 7.0308                                                                                                    \n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00048\n",
      "Epoch 25/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 4.8345e-04\n",
      "\n",
      "Cor: 0.998 - Cor_val: 0.9935, MAE: 0.8866 - MAE_val: 1.1923, R2: 0.9959 - R2_val: 0.987, MedianE: 0.6712 - MedianE_val: 0.8202, dt95: 4.6886 - dt95_val: 7.0216                                                                                                    \n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00048\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 26/40\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 4.8204e-04\n",
      "\n",
      "Cor: 0.998 - Cor_val: 0.9935, MAE: 0.8736 - MAE_val: 1.1911, R2: 0.996 - R2_val: 0.9871, MedianE: 0.6537 - MedianE_val: 0.8048, dt95: 4.6279 - dt95_val: 6.94                                                                                                    \n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00048\n",
      "Epoch 00026: early stopping\n",
      "\n",
      "Deep learning model: 8\n",
      "Load aa coding data from file ../models/base_models_PXD006109/aa.tsv\n",
      "AA types: 21\n",
      "Longest peptide in training data: 41\n",
      "\n",
      "Use test file tf_model//validation.tsv\n",
      "Longest peptide in test data: 30\n",
      "\n",
      "['1', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
      "RT range: 0 - 98\n",
      "\n",
      "X_train shape:\n",
      "(4626, 48, 21)\n",
      "X_test shape:\n",
      "(515, 48, 21)\n",
      "Modeling start ...\n",
      "48\n",
      "Perform transfer learning ...\n",
      "The number of layers: 16\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f0834342690>\n",
      "Use optimizer: Adam from saved model\n",
      "Used optimizer:\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08bf68af50>\n",
      "{'scaling_method': 'min_max', 'rt_max': 98.9458507777778, 'rt_min': 0.0}\n",
      "Use ReduceLROnPlateau!\n",
      "Use EarlyStopping: 10\n",
      "Epoch 1/40\n",
      "73/73 [==============================] - 4s 19ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "\n",
      "Cor: 0.9907 - Cor_val: 0.9874, MAE: 4.2121 - MAE_val: 4.3382, R2: 0.9374 - R2_val: 0.927, MedianE: 4.2873 - MedianE_val: 4.3776, dt95: 16.9035 - dt95_val: 17.7274                                                                                                    \n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00273, saving model to tf_model/best_model.hdf5\n",
      "Epoch 2/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "\n",
      "Cor: 0.9944 - Cor_val: 0.9911, MAE: 3.2816 - MAE_val: 3.3259, R2: 0.9612 - R2_val: 0.9548, MedianE: 2.972 - MedianE_val: 2.9875, dt95: 14.3331 - dt95_val: 13.9954                                                                                                    \n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00273 to 0.00169, saving model to tf_model/best_model.hdf5\n",
      "Epoch 3/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 6.8458e-04 - val_loss: 6.7847e-04\n",
      "\n",
      "Cor: 0.9961 - Cor_val: 0.9927, MAE: 1.6606 - MAE_val: 1.8828, R2: 0.9889 - R2_val: 0.9818, MedianE: 1.4579 - MedianE_val: 1.7178, dt95: 7.6237 - dt95_val: 8.2979                                                                                                    \n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00169 to 0.00068, saving model to tf_model/best_model.hdf5\n",
      "Epoch 4/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 6.4452e-04 - val_loss: 5.7881e-04\n",
      "\n",
      "Cor: 0.9968 - Cor_val: 0.9931, MAE: 1.3314 - MAE_val: 1.4756, R2: 0.9916 - R2_val: 0.9845, MedianE: 1.0232 - MedianE_val: 1.0055, dt95: 7.6199 - dt95_val: 8.2173                                                                                                    \n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00068 to 0.00058, saving model to tf_model/best_model.hdf5\n",
      "Epoch 5/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 6.2802e-04 - val_loss: 5.6100e-04\n",
      "\n",
      "Cor: 0.9971 - Cor_val: 0.9929, MAE: 1.1976 - MAE_val: 1.4321, R2: 0.9934 - R2_val: 0.985, MedianE: 0.9162 - MedianE_val: 0.9332, dt95: 6.4134 - dt95_val: 8.625                                                                                                    \n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00058 to 0.00056, saving model to tf_model/best_model.hdf5\n",
      "Epoch 6/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 5.6039e-04 - val_loss: 5.9364e-04\n",
      "\n",
      "Cor: 0.9973 - Cor_val: 0.9929, MAE: 1.3184 - MAE_val: 1.5652, R2: 0.9927 - R2_val: 0.9841, MedianE: 1.1237 - MedianE_val: 1.1681, dt95: 6.4846 - dt95_val: 8.4739                                                                                                    \n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00056\n",
      "Epoch 7/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 5.6963e-04 - val_loss: 6.6304e-04\n",
      "\n",
      "Cor: 0.9973 - Cor_val: 0.9931, MAE: 1.4663 - MAE_val: 1.7419, R2: 0.9912 - R2_val: 0.9822, MedianE: 1.2323 - MedianE_val: 1.3356, dt95: 7.1055 - dt95_val: 9.5835                                                                                                    \n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00056\n",
      "Epoch 8/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 5.4674e-04 - val_loss: 7.2942e-04\n",
      "\n",
      "Cor: 0.9977 - Cor_val: 0.9932, MAE: 1.593 - MAE_val: 1.7842, R2: 0.9892 - R2_val: 0.9805, MedianE: 1.2664 - MedianE_val: 1.3113, dt95: 8.3004 - dt95_val: 9.3492                                                                                                    \n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 5.1959e-04 - val_loss: 6.2808e-04\n",
      "\n",
      "Cor: 0.9978 - Cor_val: 0.9932, MAE: 1.3568 - MAE_val: 1.6485, R2: 0.9926 - R2_val: 0.9832, MedianE: 1.1674 - MedianE_val: 1.2473, dt95: 6.4646 - dt95_val: 8.8416                                                                                                    \n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00056\n",
      "Epoch 10/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 5.1789e-04 - val_loss: 5.6417e-04\n",
      "\n",
      "Cor: 0.9978 - Cor_val: 0.993, MAE: 1.1627 - MAE_val: 1.4965, R2: 0.9944 - R2_val: 0.9849, MedianE: 0.9792 - MedianE_val: 1.104, dt95: 5.5771 - dt95_val: 8.1121                                                                                                    \n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00056\n",
      "Epoch 11/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 4.7671e-04 - val_loss: 6.9159e-04\n",
      "\n",
      "Cor: 0.9976 - Cor_val: 0.9928, MAE: 1.5053 - MAE_val: 1.8309, R2: 0.9913 - R2_val: 0.9815, MedianE: 1.3451 - MedianE_val: 1.4936, dt95: 6.7738 - dt95_val: 9.4821                                                                                                    \n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 4.4687e-04 - val_loss: 4.9885e-04\n",
      "\n",
      "Cor: 0.9981 - Cor_val: 0.9935, MAE: 0.9761 - MAE_val: 1.3282, R2: 0.9957 - R2_val: 0.9866, MedianE: 0.7775 - MedianE_val: 0.9175, dt95: 5.0929 - dt95_val: 7.5757                                                                                                    \n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00056 to 0.00050, saving model to tf_model/best_model.hdf5\n",
      "Epoch 13/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 4.5179e-04 - val_loss: 5.1407e-04\n",
      "\n",
      "Cor: 0.9981 - Cor_val: 0.9935, MAE: 1.0393 - MAE_val: 1.3935, R2: 0.9954 - R2_val: 0.9862, MedianE: 0.852 - MedianE_val: 0.9923, dt95: 5.1779 - dt95_val: 7.4651                                                                                                    \n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00050\n",
      "Epoch 14/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 4.4426e-04 - val_loss: 5.2936e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9934, MAE: 1.0358 - MAE_val: 1.3928, R2: 0.9954 - R2_val: 0.9858, MedianE: 0.8463 - MedianE_val: 0.9604, dt95: 5.1849 - dt95_val: 7.7564                                                                                                    \n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00050\n",
      "Epoch 15/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 4.5850e-04 - val_loss: 5.3212e-04\n",
      "\n",
      "Cor: 0.9981 - Cor_val: 0.9932, MAE: 1.0369 - MAE_val: 1.4094, R2: 0.9953 - R2_val: 0.9857, MedianE: 0.8475 - MedianE_val: 0.9555, dt95: 5.2115 - dt95_val: 7.9798                                                                                                    \n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 4.3877e-04 - val_loss: 4.9758e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9935, MAE: 0.9386 - MAE_val: 1.3212, R2: 0.9961 - R2_val: 0.9867, MedianE: 0.7569 - MedianE_val: 0.8489, dt95: 4.8174 - dt95_val: 7.47                                                                                                    \n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00050 to 0.00050, saving model to tf_model/best_model.hdf5\n",
      "Epoch 17/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 4.1660e-04 - val_loss: 4.9914e-04\n",
      "\n",
      "Cor: 0.9983 - Cor_val: 0.9935, MAE: 0.941 - MAE_val: 1.3268, R2: 0.9961 - R2_val: 0.9866, MedianE: 0.7553 - MedianE_val: 0.8861, dt95: 4.7838 - dt95_val: 7.1345                                                                                                    \n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00050\n",
      "Epoch 18/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 4.1721e-04 - val_loss: 5.2554e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9934, MAE: 1.0335 - MAE_val: 1.4112, R2: 0.9954 - R2_val: 0.9859, MedianE: 0.8461 - MedianE_val: 1.0087, dt95: 5.1671 - dt95_val: 7.6578                                                                                                    \n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00050\n",
      "Epoch 19/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 4.2951e-04 - val_loss: 5.3887e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9933, MAE: 1.0641 - MAE_val: 1.4501, R2: 0.9953 - R2_val: 0.9856, MedianE: 0.889 - MedianE_val: 1.0347, dt95: 5.1675 - dt95_val: 7.7505                                                                                                    \n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 4.2170e-04 - val_loss: 5.4725e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9933, MAE: 1.088 - MAE_val: 1.4685, R2: 0.9951 - R2_val: 0.9853, MedianE: 0.9172 - MedianE_val: 1.0523, dt95: 5.3025 - dt95_val: 8.0976                                                                                                    \n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00050\n",
      "Epoch 21/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 4.0682e-04 - val_loss: 5.4630e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9934, MAE: 1.0933 - MAE_val: 1.4807, R2: 0.9951 - R2_val: 0.9854, MedianE: 0.9257 - MedianE_val: 1.0768, dt95: 5.2346 - dt95_val: 7.9462                                                                                                    \n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00050\n",
      "Epoch 22/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.9718e-04 - val_loss: 5.4358e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9934, MAE: 1.0862 - MAE_val: 1.4684, R2: 0.9951 - R2_val: 0.9854, MedianE: 0.9194 - MedianE_val: 1.054, dt95: 5.3209 - dt95_val: 8.051                                                                                                    \n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 4.2293e-04 - val_loss: 5.4154e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9934, MAE: 1.0787 - MAE_val: 1.4628, R2: 0.9951 - R2_val: 0.9855, MedianE: 0.906 - MedianE_val: 1.0577, dt95: 5.2672 - dt95_val: 7.8747                                                                                                    \n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00050\n",
      "Epoch 24/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 4.4227e-04 - val_loss: 5.1723e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9934, MAE: 0.9774 - MAE_val: 1.3685, R2: 0.9958 - R2_val: 0.9861, MedianE: 0.8015 - MedianE_val: 0.9512, dt95: 4.9392 - dt95_val: 7.743                                                                                                    \n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00050\n",
      "Epoch 25/40\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 4.2810e-04 - val_loss: 5.1633e-04\n",
      "\n",
      "Cor: 0.9983 - Cor_val: 0.9935, MAE: 0.9899 - MAE_val: 1.383, R2: 0.9958 - R2_val: 0.9862, MedianE: 0.8128 - MedianE_val: 0.9636, dt95: 4.9587 - dt95_val: 7.6044                                                                                                    \n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 26/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.9257e-04 - val_loss: 5.2497e-04\n",
      "\n",
      "Cor: 0.9983 - Cor_val: 0.9935, MAE: 1.0249 - MAE_val: 1.4156, R2: 0.9956 - R2_val: 0.9859, MedianE: 0.8554 - MedianE_val: 1.0171, dt95: 5.0151 - dt95_val: 7.6263                                                                                                    \n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00050\n",
      "Epoch 00026: early stopping\n",
      "\n",
      "Deep learning model: 9\n",
      "Load aa coding data from file ../models/base_models_PXD006109/aa.tsv\n",
      "AA types: 21\n",
      "Longest peptide in training data: 41\n",
      "\n",
      "Use test file tf_model//validation.tsv\n",
      "Longest peptide in test data: 30\n",
      "\n",
      "['1', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
      "RT range: 0 - 98\n",
      "\n",
      "X_train shape:\n",
      "(4626, 48, 21)\n",
      "X_test shape:\n",
      "(515, 48, 21)\n",
      "Modeling start ...\n",
      "48\n",
      "Perform transfer learning ...\n",
      "The number of layers: 16\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f0834679cd0>\n",
      "Use optimizer: Adam from saved model\n",
      "Used optimizer:\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f08bc13ec10>\n",
      "{'scaling_method': 'min_max', 'rt_max': 98.9458507777778, 'rt_min': 0.0}\n",
      "Use ReduceLROnPlateau!\n",
      "Use EarlyStopping: 10\n",
      "Epoch 1/40\n",
      "73/73 [==============================] - 4s 18ms/step - loss: 0.0025 - val_loss: 9.2032e-04\n",
      "\n",
      "Cor: 0.9959 - Cor_val: 0.9929, MAE: 2.2092 - MAE_val: 2.2819, R2: 0.9822 - R2_val: 0.9753, MedianE: 2.0508 - MedianE_val: 2.0704, dt95: 9.1358 - dt95_val: 9.2541                                                                                                    \n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00092, saving model to tf_model/best_model.hdf5\n",
      "Epoch 2/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 5.5528e-04 - val_loss: 5.3574e-04\n",
      "\n",
      "Cor: 0.9971 - Cor_val: 0.9938, MAE: 1.2991 - MAE_val: 1.4461, R2: 0.9925 - R2_val: 0.9856, MedianE: 1.0836 - MedianE_val: 1.1251, dt95: 6.3689 - dt95_val: 7.5151                                                                                                    \n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00092 to 0.00054, saving model to tf_model/best_model.hdf5\n",
      "Epoch 3/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 5.2421e-04 - val_loss: 4.5884e-04\n",
      "\n",
      "Cor: 0.9977 - Cor_val: 0.9944, MAE: 1.0376 - MAE_val: 1.2252, R2: 0.9947 - R2_val: 0.9877, MedianE: 0.7909 - MedianE_val: 0.8055, dt95: 5.6691 - dt95_val: 7.4169                                                                                                    \n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00054 to 0.00046, saving model to tf_model/best_model.hdf5\n",
      "Epoch 4/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 4.3255e-04 - val_loss: 4.6483e-04\n",
      "\n",
      "Cor: 0.998 - Cor_val: 0.9944, MAE: 0.9728 - MAE_val: 1.2173, R2: 0.9953 - R2_val: 0.9875, MedianE: 0.7066 - MedianE_val: 0.7432, dt95: 5.5201 - dt95_val: 7.0593                                                                                                    \n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00046\n",
      "Epoch 5/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.7882e-04 - val_loss: 4.4296e-04\n",
      "\n",
      "Cor: 0.9982 - Cor_val: 0.9941, MAE: 0.8729 - MAE_val: 1.1572, R2: 0.9963 - R2_val: 0.9881, MedianE: 0.6717 - MedianE_val: 0.739, dt95: 4.7868 - dt95_val: 6.6152                                                                                                    \n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00046 to 0.00044, saving model to tf_model/best_model.hdf5\n",
      "Epoch 6/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.8751e-04 - val_loss: 4.4940e-04\n",
      "\n",
      "Cor: 0.9984 - Cor_val: 0.9944, MAE: 0.9022 - MAE_val: 1.1838, R2: 0.9961 - R2_val: 0.988, MedianE: 0.6819 - MedianE_val: 0.7176, dt95: 4.8748 - dt95_val: 6.5639                                                                                                    \n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00044\n",
      "Epoch 7/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.5915e-04 - val_loss: 4.4395e-04\n",
      "\n",
      "Cor: 0.9983 - Cor_val: 0.9943, MAE: 0.9022 - MAE_val: 1.218, R2: 0.9964 - R2_val: 0.9881, MedianE: 0.7353 - MedianE_val: 0.7967, dt95: 4.4824 - dt95_val: 6.9235                                                                                                    \n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00044\n",
      "Epoch 8/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.6572e-04 - val_loss: 4.1049e-04\n",
      "\n",
      "Cor: 0.9987 - Cor_val: 0.9945, MAE: 0.7483 - MAE_val: 1.0882, R2: 0.9974 - R2_val: 0.989, MedianE: 0.5852 - MedianE_val: 0.6846, dt95: 3.9747 - dt95_val: 6.1865                                                                                                    \n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00044 to 0.00041, saving model to tf_model/best_model.hdf5\n",
      "Epoch 9/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.2609e-04 - val_loss: 4.3510e-04\n",
      "\n",
      "Cor: 0.9987 - Cor_val: 0.9942, MAE: 0.7629 - MAE_val: 1.1576, R2: 0.9972 - R2_val: 0.9883, MedianE: 0.5854 - MedianE_val: 0.7513, dt95: 4.1135 - dt95_val: 6.7256                                                                                                    \n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00041\n",
      "Epoch 10/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 3.4966e-04 - val_loss: 4.2918e-04\n",
      "\n",
      "Cor: 0.9988 - Cor_val: 0.9943, MAE: 0.7274 - MAE_val: 1.1215, R2: 0.9975 - R2_val: 0.9885, MedianE: 0.5645 - MedianE_val: 0.7061, dt95: 3.8305 - dt95_val: 6.4909                                                                                                    \n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00041\n",
      "Epoch 11/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 3.3771e-04 - val_loss: 5.3083e-04\n",
      "\n",
      "Cor: 0.9988 - Cor_val: 0.9944, MAE: 1.0501 - MAE_val: 1.3901, R2: 0.9955 - R2_val: 0.9858, MedianE: 0.908 - MedianE_val: 1.0299, dt95: 5.0561 - dt95_val: 7.6147                                                                                                    \n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00041\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 12/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 3.0430e-04 - val_loss: 4.5732e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9944, MAE: 0.7945 - MAE_val: 1.1902, R2: 0.9972 - R2_val: 0.9877, MedianE: 0.6446 - MedianE_val: 0.758, dt95: 4.0368 - dt95_val: 6.8946                                                                                                    \n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00041\n",
      "Epoch 13/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 2.7946e-04 - val_loss: 4.2952e-04\n",
      "\n",
      "Cor: 0.999 - Cor_val: 0.9943, MAE: 0.6663 - MAE_val: 1.1404, R2: 0.9979 - R2_val: 0.9885, MedianE: 0.5231 - MedianE_val: 0.7282, dt95: 3.4446 - dt95_val: 6.9405                                                                                                    \n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00041\n",
      "Epoch 14/40\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 2.7678e-04 - val_loss: 4.3013e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9944, MAE: 0.6456 - MAE_val: 1.1257, R2: 0.998 - R2_val: 0.9885, MedianE: 0.5069 - MedianE_val: 0.7113, dt95: 3.3589 - dt95_val: 6.7504                                                                                                    \n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00041\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 15/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.7616e-04 - val_loss: 4.5562e-04\n",
      "\n",
      "Cor: 0.9991 - Cor_val: 0.9944, MAE: 0.7455 - MAE_val: 1.1893, R2: 0.9975 - R2_val: 0.9878, MedianE: 0.605 - MedianE_val: 0.7556, dt95: 3.8023 - dt95_val: 6.6629                                                                                                    \n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00041\n",
      "Epoch 16/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.7282e-04 - val_loss: 4.1809e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9945, MAE: 0.6077 - MAE_val: 1.1034, R2: 0.9982 - R2_val: 0.9888, MedianE: 0.4731 - MedianE_val: 0.6745, dt95: 3.237 - dt95_val: 6.2267                                                                                                    \n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00041\n",
      "Epoch 17/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.6779e-04 - val_loss: 4.1685e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9946, MAE: 0.6287 - MAE_val: 1.1199, R2: 0.9982 - R2_val: 0.9888, MedianE: 0.504 - MedianE_val: 0.769, dt95: 3.2527 - dt95_val: 6.3815                                                                                                    \n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00041\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/40\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 2.5903e-04 - val_loss: 4.1410e-04\n",
      "\n",
      "Cor: 0.9992 - Cor_val: 0.9946, MAE: 0.603 - MAE_val: 1.1061, R2: 0.9983 - R2_val: 0.9889, MedianE: 0.4896 - MedianE_val: 0.7321, dt95: 3.12 - dt95_val: 6.2297                                                                                                    \n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00041\n",
      "Epoch 00018: early stopping\n",
      "Ensemble learning ...\n",
      "Average ...\n",
      "Load aa coding data from file tf_model/aa.tsv\n",
      "AA types: 21\n",
      "Longest peptide in input data: 30\n",
      "\n",
      "['1', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
      "\n",
      "Deep learning model: 0\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 3.8289e-04\n",
      "Metrics:\n",
      "0.00038288504583761096\n",
      "Cor: 0.9949, MAE: 1.0312, R2: 0.9897, abs_median_e: 0.6902, dt95: 5.4217                                                                                                    \n",
      "\n",
      "Deep learning model: 1\n",
      "17/17 [==============================] - 1s 3ms/step - loss: 4.9553e-04\n",
      "Metrics:\n",
      "0.0004955329932272434\n",
      "Cor: 0.9933, MAE: 1.2387, R2: 0.9867, abs_median_e: 0.7903, dt95: 7.4939                                                                                                    \n",
      "\n",
      "Deep learning model: 2\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 3.5914e-04\n",
      "Metrics:\n",
      "0.00035913693136535585\n",
      "Cor: 0.9952, MAE: 0.9781, R2: 0.9904, abs_median_e: 0.6443, dt95: 5.7413                                                                                                    \n",
      "\n",
      "Deep learning model: 3\n",
      "17/17 [==============================] - 1s 3ms/step - loss: 6.3532e-04\n",
      "Metrics:\n",
      "0.0006353165954351425\n",
      "Cor: 0.9916, MAE: 1.5566, R2: 0.983, abs_median_e: 1.0293, dt95: 8.6302                                                                                                    \n",
      "\n",
      "Deep learning model: 4\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 3.5145e-04\n",
      "Metrics:\n",
      "0.00035145474248565733\n",
      "Cor: 0.9953, MAE: 0.9483, R2: 0.9906, abs_median_e: 0.5864, dt95: 5.3704                                                                                                    \n",
      "\n",
      "Deep learning model: 5\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 4.2032e-04\n",
      "Metrics:\n",
      "0.00042032101191580296\n",
      "Cor: 0.9944, MAE: 1.1498, R2: 0.9887, abs_median_e: 0.7624, dt95: 6.936                                                                                                    \n",
      "\n",
      "Deep learning model: 6\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 3.9327e-04\n",
      "Metrics:\n",
      "0.000393266644096002\n",
      "Cor: 0.9947, MAE: 1.0371, R2: 0.9895, abs_median_e: 0.6136, dt95: 6.1066                                                                                                    \n",
      "\n",
      "Deep learning model: 7\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 4.7770e-04\n",
      "Metrics:\n",
      "0.0004776960704475641\n",
      "Cor: 0.9936, MAE: 1.1902, R2: 0.9872, abs_median_e: 0.821, dt95: 7.1304                                                                                                    \n",
      "\n",
      "Deep learning model: 8\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 4.9758e-04\n",
      "Metrics:\n",
      "0.0004975840565748513\n",
      "Cor: 0.9935, MAE: 1.3212, R2: 0.9867, abs_median_e: 0.8489, dt95: 7.47                                                                                                    \n",
      "\n",
      "Deep learning model: 9\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 4.1049e-04\n",
      "Metrics:\n",
      "0.0004104905528947711\n",
      "Cor: 0.9945, MAE: 1.0882, R2: 0.989, abs_median_e: 0.6846, dt95: 6.1865                                                                                                    \n",
      "Cor: 0.9953, MAE: 0.91, R2: 0.9906, abs_median_e: 0.5424, dt95: 5.59                                                                                                    \n",
      "# of models: 10 \n",
      "Best model combination based on metric: r2\n",
      "[(2, 4, 5, 9), 0.9956727730090412, 0.9913600416320779, 0.8711319049991058, 0.5667608642035802, 5.2435303530815816]\n"
     ]
    }
   ],
   "source": [
    "! python ../autort.py train -i data/28CPTAC_COprospective_W_VU_20150810_05CO037_f01_normal_train.tsv -o tf_model/ -e 40 -b 64 -u m -m ../models/base_models_PXD006109/model.json -rlr -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training is done, the trained model is in the folder **tf_model/** (-o):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 342620\r\n",
      "-rw-r--r-- 1 bw10 zhanglab      100 Aug 19 15:57 aa.tsv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 16077440 Aug 19 15:57 best_model.hdf5\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 40557968 Aug 19 15:49 model_0.h5\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 36550464 Aug 19 15:50 model_1.h5\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 37936544 Aug 19 15:51 model_2.h5\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 17440696 Aug 19 15:52 model_3.h5\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 35733760 Aug 19 15:53 model_4.h5\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 51615344 Aug 19 15:54 model_5.h5\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 40557968 Aug 19 15:55 model_6.h5\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 26949600 Aug 19 15:56 model_7.h5\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 30836848 Aug 19 15:57 model_8.h5\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 16076408 Aug 19 15:57 model_9.h5\r\n",
      "-rw-r--r-- 1 bw10 zhanglab      440 Aug 19 15:57 model_all.json\r\n",
      "-rw-r--r-- 1 bw10 zhanglab      506 Aug 19 15:59 model.json\r\n",
      "-rw-r--r-- 1 bw10 zhanglab   112048 Aug 19 15:59 models_combination_metrics.tsv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    15269 Aug 19 15:57 test_0.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    15288 Aug 19 15:57 test_1.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    15250 Aug 19 15:57 test_2.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    15286 Aug 19 15:58 test_3.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    15270 Aug 19 15:58 test_4.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    15272 Aug 19 15:58 test_5.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    15291 Aug 19 15:58 test_6.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    15258 Aug 19 15:58 test_7.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    15273 Aug 19 15:58 test_8.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    15274 Aug 19 15:58 test_9.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    15120 Aug 19 15:58 test_evaluate.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    20881 Aug 19 15:58 test.tsv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab   143321 Aug 19 15:48 train.tsv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab    15947 Aug 19 15:48 validation.tsv\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l tf_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "There is a testing dataset in the same folder **AutoRT/example/**:data/28CPTAC_COprospective_W_VU_20150810_05CO037_f01_normal_test.tsv.\n",
    "\n",
    "The column **x** is required which contains the peptides. The column \"y\" is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LINNNPEIFGPLK</td>\n",
       "      <td>46.334335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VGDTYERPK</td>\n",
       "      <td>11.445240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSRPENAIIYNNNEDFQVGQAK</td>\n",
       "      <td>33.492008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KQNVVPTVLALGSDVD1DVLTTLSLGDR</td>\n",
       "      <td>83.955305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IVASTLSNPELFEEWTGNVK</td>\n",
       "      <td>64.316923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              x          y\n",
       "0                 LINNNPEIFGPLK  46.334335\n",
       "1                     VGDTYERPK  11.445240\n",
       "2        TSRPENAIIYNNNEDFQVGQAK  33.492008\n",
       "3  KQNVVPTVLALGSDVD1DVLTTLSLGDR  83.955305\n",
       "4          IVASTLSNPELFEEWTGNVK  64.316923"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"data/28CPTAC_COprospective_W_VU_20150810_05CO037_f01_normal_test.tsv\",sep=\"\\t\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-19 15:59:03.754636: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Average ...\n",
      "Load aa coding data from file tf_model/aa.tsv\n",
      "AA types: 21\n",
      "Longest peptide in input data: 35\n",
      "\n",
      "['1', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
      "\n",
      "Deep learning model: 0\n",
      "\n",
      "Deep learning model: 1\n",
      "\n",
      "Deep learning model: 2\n",
      "2021-08-19 15:59:05.133474: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-19 15:59:05.194871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: NVIDIA TITAN Xp COLLECTORS EDITION computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-08-19 15:59:05.195332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-08-19 15:59:05.196264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:0b:00.0 name: NVIDIA TITAN Xp COLLECTORS EDITION computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-08-19 15:59:05.196294: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-19 15:59:05.198859: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-19 15:59:05.198930: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-19 15:59:05.199780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-19 15:59:05.199970: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-19 15:59:05.200711: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-08-19 15:59:05.201326: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-19 15:59:05.201440: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-19 15:59:05.205558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2\n",
      "2021-08-19 15:59:05.205852: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-19 15:59:05.518717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: NVIDIA TITAN Xp COLLECTORS EDITION computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-08-19 15:59:05.519323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-08-19 15:59:05.520262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:0b:00.0 name: NVIDIA TITAN Xp COLLECTORS EDITION computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-08-19 15:59:05.528295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2\n",
      "2021-08-19 15:59:05.528360: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-19 15:59:07.118974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-19 15:59:07.119018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 2 \n",
      "2021-08-19 15:59:07.119036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N Y Y \n",
      "2021-08-19 15:59:07.119041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   Y N Y \n",
      "2021-08-19 15:59:07.119046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2:   Y Y N \n",
      "2021-08-19 15:59:07.125285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11404 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp COLLECTORS EDITION, pci bus id: 0000:05:00.0, compute capability: 6.1)\n",
      "2021-08-19 15:59:07.125985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 2103 MB memory) -> physical GPU (device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "2021-08-19 15:59:07.126858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 11424 MB memory) -> physical GPU (device: 2, name: NVIDIA TITAN Xp COLLECTORS EDITION, pci bus id: 0000:0b:00.0, compute capability: 6.1)\n",
      "2021-08-19 15:59:07.858560: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-19 15:59:07.875410: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3598155000 Hz\n",
      "2021-08-19 15:59:08.376522: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-19 15:59:08.710773: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2021-08-19 15:59:09.104548: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-19 15:59:09.337968: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "18/18 [==============================] - 1s 6ms/step - loss: 2.3926e-04\n",
      "Metrics:\n",
      "0.00023925684217829257\n",
      "Cor: 0.997, MAE: 0.9407, R2: 0.9939, abs_median_e: 0.6182, dt95: 5.6957                                                                                                    \n",
      "\n",
      "Deep learning model: 3\n",
      "\n",
      "Deep learning model: 4\n",
      "18/18 [==============================] - 1s 4ms/step - loss: 2.9477e-04\n",
      "Metrics:\n",
      "0.00029476580675691366\n",
      "Cor: 0.9963, MAE: 1.0092, R2: 0.9924, abs_median_e: 0.584, dt95: 6.4875                                                                                                    \n",
      "\n",
      "Deep learning model: 5\n",
      "18/18 [==============================] - 1s 7ms/step - loss: 2.9983e-04\n",
      "Metrics:\n",
      "0.00029982838896103203\n",
      "Cor: 0.9962, MAE: 1.0976, R2: 0.9923, abs_median_e: 0.7082, dt95: 7.1554                                                                                                    \n",
      "\n",
      "Deep learning model: 6\n",
      "\n",
      "Deep learning model: 7\n",
      "\n",
      "Deep learning model: 8\n",
      "\n",
      "Deep learning model: 9\n",
      "18/18 [==============================] - 1s 4ms/step - loss: 2.8270e-04\n",
      "Metrics:\n",
      "0.00028269606991671026\n",
      "Cor: 0.9964, MAE: 1.0741, R2: 0.9928, abs_median_e: 0.7548, dt95: 6.7134                                                                                                    \n",
      "Cor: 0.9971, MAE: 0.8809, R2: 0.9942, abs_median_e: 0.5339, dt95: 5.574                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "! python ../autort.py predict -t data/28CPTAC_COprospective_W_VU_20150810_05CO037_f01_normal_test.tsv -s tf_model/model.json -o tf_prediction/ -p test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction result is in the file **tf_prediction/test.tsv**. The values in the column **y_pred** are predicted RT. Other files in the same folder are intermediate files which are not useful to users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 124\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 16940 Aug 19 15:59 test_2.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 16952 Aug 19 15:59 test_4.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 16944 Aug 19 15:59 test_5.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 16927 Aug 19 15:59 test_9.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 16733 Aug 19 15:59 test_evaluate.csv\r\n",
      "-rw-r--r-- 1 bw10 zhanglab 23279 Aug 19 15:59 test.tsv\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l tf_prediction/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the performance of the RT prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"316.55625pt\" version=\"1.1\" viewBox=\"0 0 333.165625 316.55625\" width=\"333.165625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 316.55625 \n",
       "L 333.165625 316.55625 \n",
       "L 333.165625 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 46.965625 279 \n",
       "L 325.965625 279 \n",
       "L 325.965625 7.2 \n",
       "L 46.965625 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path d=\"M 0 1 \n",
       "C 0.265203 1 0.51958 0.894634 0.707107 0.707107 \n",
       "C 0.894634 0.51958 1 0.265203 1 0 \n",
       "C 1 -0.265203 0.894634 -0.51958 0.707107 -0.707107 \n",
       "C 0.51958 -0.894634 0.265203 -1 0 -1 \n",
       "C -0.265203 -1 -0.51958 -0.894634 -0.707107 -0.707107 \n",
       "C -0.894634 -0.51958 -1 -0.265203 -1 0 \n",
       "C -1 0.265203 -0.894634 0.51958 -0.707107 0.707107 \n",
       "C -0.51958 0.894634 -0.265203 1 0 1 \n",
       "z\n",
       "\" id=\"m09ebc01211\" style=\"stroke:#0000ff;stroke-opacity:0.5;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pd85fa1285b)\">\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"164.486346\" xlink:href=\"#m09ebc01211\" y=\"162.123356\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"75.994915\" xlink:href=\"#m09ebc01211\" y=\"251.692002\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"131.913535\" xlink:href=\"#m09ebc01211\" y=\"196.305305\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"259.906807\" xlink:href=\"#m09ebc01211\" y=\"72.864681\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"210.096731\" xlink:href=\"#m09ebc01211\" y=\"119.919142\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"156.187958\" xlink:href=\"#m09ebc01211\" y=\"174.306482\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"190.443267\" xlink:href=\"#m09ebc01211\" y=\"134.031368\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"110.697032\" xlink:href=\"#m09ebc01211\" y=\"217.217404\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"108.063995\" xlink:href=\"#m09ebc01211\" y=\"218.022732\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"107.9144\" xlink:href=\"#m09ebc01211\" y=\"218.515718\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"142.430606\" xlink:href=\"#m09ebc01211\" y=\"183.857737\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"181.913493\" xlink:href=\"#m09ebc01211\" y=\"152.138936\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"103.668846\" xlink:href=\"#m09ebc01211\" y=\"223.877818\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"104.319264\" xlink:href=\"#m09ebc01211\" y=\"222.042546\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"182.342864\" xlink:href=\"#m09ebc01211\" y=\"154.755328\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"127.599791\" xlink:href=\"#m09ebc01211\" y=\"200.971508\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"134.642948\" xlink:href=\"#m09ebc01211\" y=\"191.436813\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"111.650664\" xlink:href=\"#m09ebc01211\" y=\"215.661576\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"81.738556\" xlink:href=\"#m09ebc01211\" y=\"246.033484\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"196.217725\" xlink:href=\"#m09ebc01211\" y=\"130.970221\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"129.687095\" xlink:href=\"#m09ebc01211\" y=\"198.671277\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"209.597786\" xlink:href=\"#m09ebc01211\" y=\"126.410128\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"101.23919\" xlink:href=\"#m09ebc01211\" y=\"225.778798\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"154.603549\" xlink:href=\"#m09ebc01211\" y=\"173.836881\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"156.075157\" xlink:href=\"#m09ebc01211\" y=\"169.005117\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"175.417387\" xlink:href=\"#m09ebc01211\" y=\"179.434718\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"117.544945\" xlink:href=\"#m09ebc01211\" y=\"208.671085\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"112.129311\" xlink:href=\"#m09ebc01211\" y=\"214.142533\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"261.461491\" xlink:href=\"#m09ebc01211\" y=\"68.669374\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"101.718617\" xlink:href=\"#m09ebc01211\" y=\"225.723143\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"121.227845\" xlink:href=\"#m09ebc01211\" y=\"207.613321\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"166.976661\" xlink:href=\"#m09ebc01211\" y=\"158.892907\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"195.237612\" xlink:href=\"#m09ebc01211\" y=\"133.487225\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"288.800226\" xlink:href=\"#m09ebc01211\" y=\"45.441346\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"83.469563\" xlink:href=\"#m09ebc01211\" y=\"242.334677\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"186.462447\" xlink:href=\"#m09ebc01211\" y=\"145.909275\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"96.224394\" xlink:href=\"#m09ebc01211\" y=\"229.111283\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"96.162633\" xlink:href=\"#m09ebc01211\" y=\"231.189762\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"189.21479\" xlink:href=\"#m09ebc01211\" y=\"138.876006\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"99.842206\" xlink:href=\"#m09ebc01211\" y=\"228.346487\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"164.375305\" xlink:href=\"#m09ebc01211\" y=\"165.713328\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"181.765638\" xlink:href=\"#m09ebc01211\" y=\"146.51852\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"156.367073\" xlink:href=\"#m09ebc01211\" y=\"173.000975\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"219.637265\" xlink:href=\"#m09ebc01211\" y=\"129.423706\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"145.23769\" xlink:href=\"#m09ebc01211\" y=\"183.004705\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"203.127037\" xlink:href=\"#m09ebc01211\" y=\"126.961381\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"80.150304\" xlink:href=\"#m09ebc01211\" y=\"248.188102\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"148.712833\" xlink:href=\"#m09ebc01211\" y=\"179.845865\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"105.575059\" xlink:href=\"#m09ebc01211\" y=\"221.36077\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"197.484134\" xlink:href=\"#m09ebc01211\" y=\"129.128294\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"73.842198\" xlink:href=\"#m09ebc01211\" y=\"254.782101\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"181.679612\" xlink:href=\"#m09ebc01211\" y=\"149.580725\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"135.453561\" xlink:href=\"#m09ebc01211\" y=\"190.621228\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"182.917428\" xlink:href=\"#m09ebc01211\" y=\"149.958342\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"225.866624\" xlink:href=\"#m09ebc01211\" y=\"102.617762\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"194.356033\" xlink:href=\"#m09ebc01211\" y=\"136.137635\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"210.235038\" xlink:href=\"#m09ebc01211\" y=\"119.027771\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"108.195739\" xlink:href=\"#m09ebc01211\" y=\"218.252221\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"89.145302\" xlink:href=\"#m09ebc01211\" y=\"238.872856\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"182.403613\" xlink:href=\"#m09ebc01211\" y=\"149.410025\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"241.106452\" xlink:href=\"#m09ebc01211\" y=\"87.390414\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"179.452366\" xlink:href=\"#m09ebc01211\" y=\"150.963629\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"142.440395\" xlink:href=\"#m09ebc01211\" y=\"186.613203\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"293.389405\" xlink:href=\"#m09ebc01211\" y=\"47.649563\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"160.676008\" xlink:href=\"#m09ebc01211\" y=\"168.469639\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"142.911222\" xlink:href=\"#m09ebc01211\" y=\"189.863\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"126.402446\" xlink:href=\"#m09ebc01211\" y=\"201.236992\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"175.564974\" xlink:href=\"#m09ebc01211\" y=\"158.832911\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"155.019072\" xlink:href=\"#m09ebc01211\" y=\"172.212444\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"137.691749\" xlink:href=\"#m09ebc01211\" y=\"191.218706\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"159.185279\" xlink:href=\"#m09ebc01211\" y=\"168.148268\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"157.118099\" xlink:href=\"#m09ebc01211\" y=\"170.380139\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"98.858258\" xlink:href=\"#m09ebc01211\" y=\"229.492895\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"91.824755\" xlink:href=\"#m09ebc01211\" y=\"238.399924\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"183.536868\" xlink:href=\"#m09ebc01211\" y=\"145.581843\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"225.72934\" xlink:href=\"#m09ebc01211\" y=\"104.325358\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"155.671441\" xlink:href=\"#m09ebc01211\" y=\"172.409318\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"257.244378\" xlink:href=\"#m09ebc01211\" y=\"80.753033\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"120.127946\" xlink:href=\"#m09ebc01211\" y=\"208.074823\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"88.249343\" xlink:href=\"#m09ebc01211\" y=\"238.053103\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"135.038229\" xlink:href=\"#m09ebc01211\" y=\"195.100324\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"115.559277\" xlink:href=\"#m09ebc01211\" y=\"211.676096\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"75.144693\" xlink:href=\"#m09ebc01211\" y=\"253.026248\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"210.583584\" xlink:href=\"#m09ebc01211\" y=\"117.218586\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"110.32472\" xlink:href=\"#m09ebc01211\" y=\"217.324876\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"101.832269\" xlink:href=\"#m09ebc01211\" y=\"226.353921\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"95.349636\" xlink:href=\"#m09ebc01211\" y=\"232.773741\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"82.631687\" xlink:href=\"#m09ebc01211\" y=\"244.592724\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"135.782789\" xlink:href=\"#m09ebc01211\" y=\"195.56742\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"220.601018\" xlink:href=\"#m09ebc01211\" y=\"98.613086\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"134.50365\" xlink:href=\"#m09ebc01211\" y=\"193.452917\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"123.170215\" xlink:href=\"#m09ebc01211\" y=\"204.181483\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"108.203806\" xlink:href=\"#m09ebc01211\" y=\"219.877743\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"211.074246\" xlink:href=\"#m09ebc01211\" y=\"114.530212\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"197.862307\" xlink:href=\"#m09ebc01211\" y=\"132.97252\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"170.271801\" xlink:href=\"#m09ebc01211\" y=\"155.803018\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"200.317051\" xlink:href=\"#m09ebc01211\" y=\"128.892292\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"202.417748\" xlink:href=\"#m09ebc01211\" y=\"125.717006\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"193.760519\" xlink:href=\"#m09ebc01211\" y=\"134.677679\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"198.56349\" xlink:href=\"#m09ebc01211\" y=\"128.345493\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"163.247685\" xlink:href=\"#m09ebc01211\" y=\"163.95643\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"52.193916\" xlink:href=\"#m09ebc01211\" y=\"262.134331\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"172.110199\" xlink:href=\"#m09ebc01211\" y=\"154.086507\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"141.45461\" xlink:href=\"#m09ebc01211\" y=\"184.905953\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"125.53701\" xlink:href=\"#m09ebc01211\" y=\"204.272484\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"98.506297\" xlink:href=\"#m09ebc01211\" y=\"227.947907\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"75.411504\" xlink:href=\"#m09ebc01211\" y=\"253.674239\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"117.993627\" xlink:href=\"#m09ebc01211\" y=\"211.051055\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"90.273997\" xlink:href=\"#m09ebc01211\" y=\"229.092032\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"127.73142\" xlink:href=\"#m09ebc01211\" y=\"201.118843\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"114.140106\" xlink:href=\"#m09ebc01211\" y=\"213.095634\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"164.646189\" xlink:href=\"#m09ebc01211\" y=\"157.334102\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"205.217032\" xlink:href=\"#m09ebc01211\" y=\"125.238174\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"92.104764\" xlink:href=\"#m09ebc01211\" y=\"235.36509\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"263.943939\" xlink:href=\"#m09ebc01211\" y=\"60.985464\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"150.166608\" xlink:href=\"#m09ebc01211\" y=\"181.001942\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"249.644014\" xlink:href=\"#m09ebc01211\" y=\"78.098017\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"128.595803\" xlink:href=\"#m09ebc01211\" y=\"201.127995\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"156.761412\" xlink:href=\"#m09ebc01211\" y=\"171.650771\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"183.856888\" xlink:href=\"#m09ebc01211\" y=\"144.989074\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"147.155643\" xlink:href=\"#m09ebc01211\" y=\"182.816577\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"117.386291\" xlink:href=\"#m09ebc01211\" y=\"207.526713\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"95.503085\" xlink:href=\"#m09ebc01211\" y=\"232.127803\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"170.347035\" xlink:href=\"#m09ebc01211\" y=\"159.23983\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"162.339125\" xlink:href=\"#m09ebc01211\" y=\"167.567621\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"229.200636\" xlink:href=\"#m09ebc01211\" y=\"105.745464\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"208.902957\" xlink:href=\"#m09ebc01211\" y=\"119.496779\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"179.115892\" xlink:href=\"#m09ebc01211\" y=\"147.827689\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"81.611285\" xlink:href=\"#m09ebc01211\" y=\"245.369974\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"144.718388\" xlink:href=\"#m09ebc01211\" y=\"186.648933\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"93.365906\" xlink:href=\"#m09ebc01211\" y=\"233.384443\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"182.185844\" xlink:href=\"#m09ebc01211\" y=\"145.446252\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"193.728497\" xlink:href=\"#m09ebc01211\" y=\"138.810163\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"104.105451\" xlink:href=\"#m09ebc01211\" y=\"222.333901\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"114.91837\" xlink:href=\"#m09ebc01211\" y=\"212.299941\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"89.902599\" xlink:href=\"#m09ebc01211\" y=\"237.069678\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"118.905599\" xlink:href=\"#m09ebc01211\" y=\"208.135632\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"206.57555\" xlink:href=\"#m09ebc01211\" y=\"121.479644\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"168.870642\" xlink:href=\"#m09ebc01211\" y=\"160.398494\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"151.687769\" xlink:href=\"#m09ebc01211\" y=\"177.440917\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"177.409019\" xlink:href=\"#m09ebc01211\" y=\"154.814489\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"143.930446\" xlink:href=\"#m09ebc01211\" y=\"185.350248\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"152.358933\" xlink:href=\"#m09ebc01211\" y=\"178.669831\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"243.094052\" xlink:href=\"#m09ebc01211\" y=\"98.430201\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"120.691087\" xlink:href=\"#m09ebc01211\" y=\"206.386162\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"145.231998\" xlink:href=\"#m09ebc01211\" y=\"182.491075\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"239.495575\" xlink:href=\"#m09ebc01211\" y=\"91.356841\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"97.714295\" xlink:href=\"#m09ebc01211\" y=\"228.458624\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"133.38114\" xlink:href=\"#m09ebc01211\" y=\"196.355775\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"123.128322\" xlink:href=\"#m09ebc01211\" y=\"206.134094\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"115.308376\" xlink:href=\"#m09ebc01211\" y=\"212.153669\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"154.984621\" xlink:href=\"#m09ebc01211\" y=\"176.006646\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"92.677994\" xlink:href=\"#m09ebc01211\" y=\"231.521067\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"80.140358\" xlink:href=\"#m09ebc01211\" y=\"246.841074\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"162.082118\" xlink:href=\"#m09ebc01211\" y=\"174.04913\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"177.977417\" xlink:href=\"#m09ebc01211\" y=\"150.674416\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"146.597881\" xlink:href=\"#m09ebc01211\" y=\"179.07529\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"260.152592\" xlink:href=\"#m09ebc01211\" y=\"70.193085\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"213.708302\" xlink:href=\"#m09ebc01211\" y=\"110.717007\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"212.367164\" xlink:href=\"#m09ebc01211\" y=\"119.93583\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"127.913205\" xlink:href=\"#m09ebc01211\" y=\"199.636574\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"143.123586\" xlink:href=\"#m09ebc01211\" y=\"181.443562\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"186.87645\" xlink:href=\"#m09ebc01211\" y=\"144.585684\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"216.984339\" xlink:href=\"#m09ebc01211\" y=\"111.422451\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"129.588038\" xlink:href=\"#m09ebc01211\" y=\"193.922844\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"146.800682\" xlink:href=\"#m09ebc01211\" y=\"179.057203\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"116.331314\" xlink:href=\"#m09ebc01211\" y=\"216.549413\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"97.316076\" xlink:href=\"#m09ebc01211\" y=\"230.14375\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"156.392934\" xlink:href=\"#m09ebc01211\" y=\"170.560058\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"164.749281\" xlink:href=\"#m09ebc01211\" y=\"165.32985\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"147.674109\" xlink:href=\"#m09ebc01211\" y=\"180.094624\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"176.820948\" xlink:href=\"#m09ebc01211\" y=\"147.770129\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"177.794085\" xlink:href=\"#m09ebc01211\" y=\"152.757852\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"215.625679\" xlink:href=\"#m09ebc01211\" y=\"112.430187\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"221.941261\" xlink:href=\"#m09ebc01211\" y=\"104.697007\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"170.00858\" xlink:href=\"#m09ebc01211\" y=\"158.397966\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"199.305751\" xlink:href=\"#m09ebc01211\" y=\"134.660412\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"184.683658\" xlink:href=\"#m09ebc01211\" y=\"146.279455\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"165.952291\" xlink:href=\"#m09ebc01211\" y=\"159.72734\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"210.929883\" xlink:href=\"#m09ebc01211\" y=\"116.90079\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"206.841607\" xlink:href=\"#m09ebc01211\" y=\"122.25336\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"211.187152\" xlink:href=\"#m09ebc01211\" y=\"109.016735\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"257.244689\" xlink:href=\"#m09ebc01211\" y=\"77.888657\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"127.833039\" xlink:href=\"#m09ebc01211\" y=\"201.903596\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"196.996604\" xlink:href=\"#m09ebc01211\" y=\"129.292189\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"149.894488\" xlink:href=\"#m09ebc01211\" y=\"177.290019\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"131.715188\" xlink:href=\"#m09ebc01211\" y=\"195.689692\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"138.905779\" xlink:href=\"#m09ebc01211\" y=\"188.906444\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"275.495769\" xlink:href=\"#m09ebc01211\" y=\"50.502892\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"135.99109\" xlink:href=\"#m09ebc01211\" y=\"189.379769\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"159.379608\" xlink:href=\"#m09ebc01211\" y=\"168.509594\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"128.908534\" xlink:href=\"#m09ebc01211\" y=\"197.804039\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"279.550795\" xlink:href=\"#m09ebc01211\" y=\"46.278317\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"132.720229\" xlink:href=\"#m09ebc01211\" y=\"195.237402\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"179.245228\" xlink:href=\"#m09ebc01211\" y=\"148.911571\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"93.834395\" xlink:href=\"#m09ebc01211\" y=\"233.777916\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"173.35753\" xlink:href=\"#m09ebc01211\" y=\"154.655799\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"133.995753\" xlink:href=\"#m09ebc01211\" y=\"192.938533\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"230.887519\" xlink:href=\"#m09ebc01211\" y=\"97.067779\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"203.438221\" xlink:href=\"#m09ebc01211\" y=\"128.0803\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"91.428567\" xlink:href=\"#m09ebc01211\" y=\"236.009792\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"134.179101\" xlink:href=\"#m09ebc01211\" y=\"194.57086\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"211.169597\" xlink:href=\"#m09ebc01211\" y=\"118.996269\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"84.075736\" xlink:href=\"#m09ebc01211\" y=\"243.309203\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"243.296695\" xlink:href=\"#m09ebc01211\" y=\"76.869234\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"207.50389\" xlink:href=\"#m09ebc01211\" y=\"118.691891\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"89.389874\" xlink:href=\"#m09ebc01211\" y=\"238.150877\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"152.44083\" xlink:href=\"#m09ebc01211\" y=\"176.68687\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"210.0014\" xlink:href=\"#m09ebc01211\" y=\"114.845614\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"151.140241\" xlink:href=\"#m09ebc01211\" y=\"178.453263\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"199.798408\" xlink:href=\"#m09ebc01211\" y=\"126.348625\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"146.446692\" xlink:href=\"#m09ebc01211\" y=\"183.383552\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"246.612805\" xlink:href=\"#m09ebc01211\" y=\"83.740573\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"103.569208\" xlink:href=\"#m09ebc01211\" y=\"223.880821\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"208.131437\" xlink:href=\"#m09ebc01211\" y=\"119.519927\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"85.616709\" xlink:href=\"#m09ebc01211\" y=\"243.381991\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"171.378585\" xlink:href=\"#m09ebc01211\" y=\"153.378784\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"173.720789\" xlink:href=\"#m09ebc01211\" y=\"158.18259\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"158.843732\" xlink:href=\"#m09ebc01211\" y=\"171.245896\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"142.801324\" xlink:href=\"#m09ebc01211\" y=\"187.730252\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"242.796534\" xlink:href=\"#m09ebc01211\" y=\"88.067567\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"168.30155\" xlink:href=\"#m09ebc01211\" y=\"160.024101\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"207.224139\" xlink:href=\"#m09ebc01211\" y=\"123.305943\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"144.988834\" xlink:href=\"#m09ebc01211\" y=\"179.676408\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"156.442961\" xlink:href=\"#m09ebc01211\" y=\"169.660148\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"217.10362\" xlink:href=\"#m09ebc01211\" y=\"112.312596\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"175.339775\" xlink:href=\"#m09ebc01211\" y=\"154.19054\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"127.37797\" xlink:href=\"#m09ebc01211\" y=\"204.481229\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"264.848977\" xlink:href=\"#m09ebc01211\" y=\"64.147239\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"137.466019\" xlink:href=\"#m09ebc01211\" y=\"192.248388\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"187.520687\" xlink:href=\"#m09ebc01211\" y=\"143.570214\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"94.133483\" xlink:href=\"#m09ebc01211\" y=\"231.945801\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"141.596178\" xlink:href=\"#m09ebc01211\" y=\"183.508588\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"141.926108\" xlink:href=\"#m09ebc01211\" y=\"188.723696\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"178.072748\" xlink:href=\"#m09ebc01211\" y=\"150.721188\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"201.52062\" xlink:href=\"#m09ebc01211\" y=\"128.549797\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"212.52642\" xlink:href=\"#m09ebc01211\" y=\"118.945035\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"206.294243\" xlink:href=\"#m09ebc01211\" y=\"122.758179\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"203.672429\" xlink:href=\"#m09ebc01211\" y=\"125.133205\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"111.716267\" xlink:href=\"#m09ebc01211\" y=\"216.23265\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"158.198473\" xlink:href=\"#m09ebc01211\" y=\"168.875931\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"139.136981\" xlink:href=\"#m09ebc01211\" y=\"190.018091\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"131.364617\" xlink:href=\"#m09ebc01211\" y=\"198.458452\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"237.775071\" xlink:href=\"#m09ebc01211\" y=\"95.274208\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"149.472489\" xlink:href=\"#m09ebc01211\" y=\"176.981214\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"176.614034\" xlink:href=\"#m09ebc01211\" y=\"155.605036\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"120.845316\" xlink:href=\"#m09ebc01211\" y=\"215.582776\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"163.400561\" xlink:href=\"#m09ebc01211\" y=\"166.744912\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"213.851633\" xlink:href=\"#m09ebc01211\" y=\"117.482899\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"116.702548\" xlink:href=\"#m09ebc01211\" y=\"210.354787\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"180.873098\" xlink:href=\"#m09ebc01211\" y=\"146.629669\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"263.324664\" xlink:href=\"#m09ebc01211\" y=\"69.299999\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"184.935486\" xlink:href=\"#m09ebc01211\" y=\"144.281317\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"157.167432\" xlink:href=\"#m09ebc01211\" y=\"173.573628\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"130.984069\" xlink:href=\"#m09ebc01211\" y=\"198.663906\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"79.200241\" xlink:href=\"#m09ebc01211\" y=\"247.466142\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"142.854979\" xlink:href=\"#m09ebc01211\" y=\"180.431854\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"159.370978\" xlink:href=\"#m09ebc01211\" y=\"169.691247\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"83.705672\" xlink:href=\"#m09ebc01211\" y=\"244.10303\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"123.873413\" xlink:href=\"#m09ebc01211\" y=\"202.031389\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"82.180631\" xlink:href=\"#m09ebc01211\" y=\"244.552293\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"147.392607\" xlink:href=\"#m09ebc01211\" y=\"181.575919\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"139.43915\" xlink:href=\"#m09ebc01211\" y=\"189.259349\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"185.644809\" xlink:href=\"#m09ebc01211\" y=\"141.745571\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"124.14008\" xlink:href=\"#m09ebc01211\" y=\"202.706195\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"222.295532\" xlink:href=\"#m09ebc01211\" y=\"105.721076\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"189.23977\" xlink:href=\"#m09ebc01211\" y=\"139.81331\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"97.11091\" xlink:href=\"#m09ebc01211\" y=\"230.089887\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"108.60836\" xlink:href=\"#m09ebc01211\" y=\"218.426533\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"88.287146\" xlink:href=\"#m09ebc01211\" y=\"240.304862\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"87.201398\" xlink:href=\"#m09ebc01211\" y=\"239.661751\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"240.753122\" xlink:href=\"#m09ebc01211\" y=\"82.064765\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"94.665658\" xlink:href=\"#m09ebc01211\" y=\"233.407749\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"189.616089\" xlink:href=\"#m09ebc01211\" y=\"135.884427\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"116.595818\" xlink:href=\"#m09ebc01211\" y=\"211.461987\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"148.430397\" xlink:href=\"#m09ebc01211\" y=\"182.607002\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"195.176302\" xlink:href=\"#m09ebc01211\" y=\"126.921609\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"156.683982\" xlink:href=\"#m09ebc01211\" y=\"172.245028\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"171.440099\" xlink:href=\"#m09ebc01211\" y=\"159.45686\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"203.786687\" xlink:href=\"#m09ebc01211\" y=\"126.975119\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"151.693798\" xlink:href=\"#m09ebc01211\" y=\"177.141023\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"155.509845\" xlink:href=\"#m09ebc01211\" y=\"171.190906\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"106.32488\" xlink:href=\"#m09ebc01211\" y=\"223.494783\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"178.884688\" xlink:href=\"#m09ebc01211\" y=\"155.252722\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"167.412558\" xlink:href=\"#m09ebc01211\" y=\"159.948432\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"222.742215\" xlink:href=\"#m09ebc01211\" y=\"112.875198\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"221.018322\" xlink:href=\"#m09ebc01211\" y=\"110.629042\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"239.748296\" xlink:href=\"#m09ebc01211\" y=\"91.066163\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"197.614051\" xlink:href=\"#m09ebc01211\" y=\"128.859291\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"177.587073\" xlink:href=\"#m09ebc01211\" y=\"149.5457\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"144.629476\" xlink:href=\"#m09ebc01211\" y=\"174.406838\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"144.056927\" xlink:href=\"#m09ebc01211\" y=\"180.661016\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"152.512112\" xlink:href=\"#m09ebc01211\" y=\"175.073719\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"143.436814\" xlink:href=\"#m09ebc01211\" y=\"183.994741\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"102.294449\" xlink:href=\"#m09ebc01211\" y=\"224.861549\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"100.833186\" xlink:href=\"#m09ebc01211\" y=\"227.058271\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"212.433256\" xlink:href=\"#m09ebc01211\" y=\"115.557295\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"133.559762\" xlink:href=\"#m09ebc01211\" y=\"196.236603\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"167.926592\" xlink:href=\"#m09ebc01211\" y=\"157.818029\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"203.53144\" xlink:href=\"#m09ebc01211\" y=\"126.381211\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"137.001851\" xlink:href=\"#m09ebc01211\" y=\"191.37845\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"113.424097\" xlink:href=\"#m09ebc01211\" y=\"213.616892\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"140.373245\" xlink:href=\"#m09ebc01211\" y=\"190.643839\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"191.078794\" xlink:href=\"#m09ebc01211\" y=\"137.777052\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"216.820141\" xlink:href=\"#m09ebc01211\" y=\"97.356505\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"101.693204\" xlink:href=\"#m09ebc01211\" y=\"223.325642\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"149.695791\" xlink:href=\"#m09ebc01211\" y=\"174.533576\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"171.357159\" xlink:href=\"#m09ebc01211\" y=\"160.980422\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"256.990527\" xlink:href=\"#m09ebc01211\" y=\"72.328037\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"236.121\" xlink:href=\"#m09ebc01211\" y=\"93.768522\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"203.924326\" xlink:href=\"#m09ebc01211\" y=\"124.442141\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"164.661831\" xlink:href=\"#m09ebc01211\" y=\"165.650967\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"65.938753\" xlink:href=\"#m09ebc01211\" y=\"258.091365\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"77.257928\" xlink:href=\"#m09ebc01211\" y=\"251.237402\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"218.754436\" xlink:href=\"#m09ebc01211\" y=\"108.934814\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"115.935492\" xlink:href=\"#m09ebc01211\" y=\"211.222403\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"113.423752\" xlink:href=\"#m09ebc01211\" y=\"215.987699\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"193.45404\" xlink:href=\"#m09ebc01211\" y=\"136.057316\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"114.713017\" xlink:href=\"#m09ebc01211\" y=\"212.329469\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"259.044404\" xlink:href=\"#m09ebc01211\" y=\"66.754975\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"232.810781\" xlink:href=\"#m09ebc01211\" y=\"95.4874\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"223.680874\" xlink:href=\"#m09ebc01211\" y=\"103.863298\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"197.149121\" xlink:href=\"#m09ebc01211\" y=\"130.022187\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"132.202256\" xlink:href=\"#m09ebc01211\" y=\"195.962585\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"129.704275\" xlink:href=\"#m09ebc01211\" y=\"197.477\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"139.394703\" xlink:href=\"#m09ebc01211\" y=\"188.977295\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"97.480987\" xlink:href=\"#m09ebc01211\" y=\"229.915999\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"165.055587\" xlink:href=\"#m09ebc01211\" y=\"170.84399\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"125.194781\" xlink:href=\"#m09ebc01211\" y=\"202.248829\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"123.918208\" xlink:href=\"#m09ebc01211\" y=\"211.036435\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"173.818153\" xlink:href=\"#m09ebc01211\" y=\"156.670443\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"206.621352\" xlink:href=\"#m09ebc01211\" y=\"123.674849\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"186.589654\" xlink:href=\"#m09ebc01211\" y=\"144.479207\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"242.905693\" xlink:href=\"#m09ebc01211\" y=\"92.832567\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"148.065289\" xlink:href=\"#m09ebc01211\" y=\"183.900936\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"190.388202\" xlink:href=\"#m09ebc01211\" y=\"140.012747\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"218.079459\" xlink:href=\"#m09ebc01211\" y=\"110.544562\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"166.779772\" xlink:href=\"#m09ebc01211\" y=\"161.229885\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"172.28057\" xlink:href=\"#m09ebc01211\" y=\"153.55856\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"232.556177\" xlink:href=\"#m09ebc01211\" y=\"99.398563\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"197.11418\" xlink:href=\"#m09ebc01211\" y=\"133.313075\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"250.696304\" xlink:href=\"#m09ebc01211\" y=\"99.254163\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"245.675013\" xlink:href=\"#m09ebc01211\" y=\"83.378498\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"176.801136\" xlink:href=\"#m09ebc01211\" y=\"150.800563\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"251.937175\" xlink:href=\"#m09ebc01211\" y=\"82.77311\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"170.859042\" xlink:href=\"#m09ebc01211\" y=\"168.50887\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"105.539741\" xlink:href=\"#m09ebc01211\" y=\"216.396874\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"104.680093\" xlink:href=\"#m09ebc01211\" y=\"223.720926\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"153.961549\" xlink:href=\"#m09ebc01211\" y=\"173.994658\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"209.463593\" xlink:href=\"#m09ebc01211\" y=\"121.253326\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"135.082634\" xlink:href=\"#m09ebc01211\" y=\"190.601424\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"120.055363\" xlink:href=\"#m09ebc01211\" y=\"206.449375\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"122.834558\" xlink:href=\"#m09ebc01211\" y=\"203.494788\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"147.470051\" xlink:href=\"#m09ebc01211\" y=\"179.498403\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"206.43168\" xlink:href=\"#m09ebc01211\" y=\"127.043183\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"197.370753\" xlink:href=\"#m09ebc01211\" y=\"132.440246\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"195.503087\" xlink:href=\"#m09ebc01211\" y=\"140.825289\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"80.271004\" xlink:href=\"#m09ebc01211\" y=\"245.980743\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"165.892079\" xlink:href=\"#m09ebc01211\" y=\"161.475256\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"260.122506\" xlink:href=\"#m09ebc01211\" y=\"75.679936\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"236.931394\" xlink:href=\"#m09ebc01211\" y=\"91.803359\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"94.255545\" xlink:href=\"#m09ebc01211\" y=\"233.576695\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"140.379875\" xlink:href=\"#m09ebc01211\" y=\"186.113882\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"162.088815\" xlink:href=\"#m09ebc01211\" y=\"162.020863\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"86.331025\" xlink:href=\"#m09ebc01211\" y=\"240.169142\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"148.726101\" xlink:href=\"#m09ebc01211\" y=\"182.77094\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"184.742239\" xlink:href=\"#m09ebc01211\" y=\"143.612894\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"213.290806\" xlink:href=\"#m09ebc01211\" y=\"129.845661\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"104.942805\" xlink:href=\"#m09ebc01211\" y=\"221.658394\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"188.403223\" xlink:href=\"#m09ebc01211\" y=\"141.848905\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"157.523453\" xlink:href=\"#m09ebc01211\" y=\"168.803565\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"180.086722\" xlink:href=\"#m09ebc01211\" y=\"151.230124\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"165.642111\" xlink:href=\"#m09ebc01211\" y=\"161.889485\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"80.982676\" xlink:href=\"#m09ebc01211\" y=\"244.922482\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"153.108517\" xlink:href=\"#m09ebc01211\" y=\"174.678742\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"269.352348\" xlink:href=\"#m09ebc01211\" y=\"72.293703\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"121.497412\" xlink:href=\"#m09ebc01211\" y=\"206.430332\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"157.270207\" xlink:href=\"#m09ebc01211\" y=\"169.014835\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"84.535746\" xlink:href=\"#m09ebc01211\" y=\"241.73411\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"212.224382\" xlink:href=\"#m09ebc01211\" y=\"116.926327\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"141.43902\" xlink:href=\"#m09ebc01211\" y=\"185.612263\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"237.599385\" xlink:href=\"#m09ebc01211\" y=\"94.623383\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"228.835396\" xlink:href=\"#m09ebc01211\" y=\"100.892746\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"156.921007\" xlink:href=\"#m09ebc01211\" y=\"172.306474\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"200.019743\" xlink:href=\"#m09ebc01211\" y=\"131.019577\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"207.946892\" xlink:href=\"#m09ebc01211\" y=\"121.47193\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"181.53586\" xlink:href=\"#m09ebc01211\" y=\"148.821358\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"134.675021\" xlink:href=\"#m09ebc01211\" y=\"192.547042\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"141.687993\" xlink:href=\"#m09ebc01211\" y=\"182.6335\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"146.308518\" xlink:href=\"#m09ebc01211\" y=\"181.827211\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"179.121719\" xlink:href=\"#m09ebc01211\" y=\"151.195397\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"79.883821\" xlink:href=\"#m09ebc01211\" y=\"245.937749\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"102.657926\" xlink:href=\"#m09ebc01211\" y=\"224.6404\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"163.733128\" xlink:href=\"#m09ebc01211\" y=\"163.529555\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"108.473109\" xlink:href=\"#m09ebc01211\" y=\"223.164042\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"132.619257\" xlink:href=\"#m09ebc01211\" y=\"195.119431\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"196.872427\" xlink:href=\"#m09ebc01211\" y=\"129.015242\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"156.193694\" xlink:href=\"#m09ebc01211\" y=\"172.753491\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"97.348215\" xlink:href=\"#m09ebc01211\" y=\"231.116937\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"153.312918\" xlink:href=\"#m09ebc01211\" y=\"176.955821\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"189.790943\" xlink:href=\"#m09ebc01211\" y=\"138.769744\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"143.353365\" xlink:href=\"#m09ebc01211\" y=\"183.289015\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"211.741559\" xlink:href=\"#m09ebc01211\" y=\"119.297436\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"199.532752\" xlink:href=\"#m09ebc01211\" y=\"131.059023\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"116.077757\" xlink:href=\"#m09ebc01211\" y=\"212.676095\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"107.022076\" xlink:href=\"#m09ebc01211\" y=\"220.278677\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"136.662504\" xlink:href=\"#m09ebc01211\" y=\"190.832533\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"249.549802\" xlink:href=\"#m09ebc01211\" y=\"82.667593\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"166.893388\" xlink:href=\"#m09ebc01211\" y=\"158.526046\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"265.737205\" xlink:href=\"#m09ebc01211\" y=\"70.39985\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"156.205163\" xlink:href=\"#m09ebc01211\" y=\"173.180141\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"175.855256\" xlink:href=\"#m09ebc01211\" y=\"149.477204\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"90.058715\" xlink:href=\"#m09ebc01211\" y=\"237.895983\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"271.150178\" xlink:href=\"#m09ebc01211\" y=\"55.577274\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"133.742906\" xlink:href=\"#m09ebc01211\" y=\"195.986582\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"119.602561\" xlink:href=\"#m09ebc01211\" y=\"207.391864\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"211.971465\" xlink:href=\"#m09ebc01211\" y=\"124.860342\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"213.834394\" xlink:href=\"#m09ebc01211\" y=\"118.057312\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"115.691338\" xlink:href=\"#m09ebc01211\" y=\"213.247859\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"97.33575\" xlink:href=\"#m09ebc01211\" y=\"230.593552\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"170.497713\" xlink:href=\"#m09ebc01211\" y=\"156.961565\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"93.03755\" xlink:href=\"#m09ebc01211\" y=\"231.843211\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"186.593449\" xlink:href=\"#m09ebc01211\" y=\"149.181046\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"165.472485\" xlink:href=\"#m09ebc01211\" y=\"166.486552\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"87.458746\" xlink:href=\"#m09ebc01211\" y=\"239.023424\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"147.831472\" xlink:href=\"#m09ebc01211\" y=\"183.133961\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"267.508377\" xlink:href=\"#m09ebc01211\" y=\"70.857448\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"167.664713\" xlink:href=\"#m09ebc01211\" y=\"160.800357\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"201.265773\" xlink:href=\"#m09ebc01211\" y=\"123.118252\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"151.586676\" xlink:href=\"#m09ebc01211\" y=\"169.256821\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"81.25365\" xlink:href=\"#m09ebc01211\" y=\"246.615158\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"96.728274\" xlink:href=\"#m09ebc01211\" y=\"228.228326\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"129.22557\" xlink:href=\"#m09ebc01211\" y=\"199.41055\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"188.997801\" xlink:href=\"#m09ebc01211\" y=\"140.835921\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"107.006562\" xlink:href=\"#m09ebc01211\" y=\"221.1597\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"208.575716\" xlink:href=\"#m09ebc01211\" y=\"120.095342\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"152.692681\" xlink:href=\"#m09ebc01211\" y=\"179.350381\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"142.2242\" xlink:href=\"#m09ebc01211\" y=\"185.420021\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"205.539149\" xlink:href=\"#m09ebc01211\" y=\"125.538226\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"184.167238\" xlink:href=\"#m09ebc01211\" y=\"140.640025\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"204.137768\" xlink:href=\"#m09ebc01211\" y=\"131.106442\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"100.048336\" xlink:href=\"#m09ebc01211\" y=\"228.067645\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"87.330584\" xlink:href=\"#m09ebc01211\" y=\"241.286265\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"164.36603\" xlink:href=\"#m09ebc01211\" y=\"170.00307\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"185.98983\" xlink:href=\"#m09ebc01211\" y=\"144.648635\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"119.959936\" xlink:href=\"#m09ebc01211\" y=\"208.651548\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"200.986121\" xlink:href=\"#m09ebc01211\" y=\"138.059674\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"210.788257\" xlink:href=\"#m09ebc01211\" y=\"117.058237\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"88.402457\" xlink:href=\"#m09ebc01211\" y=\"242.061962\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"198.343916\" xlink:href=\"#m09ebc01211\" y=\"130.565721\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"104.566781\" xlink:href=\"#m09ebc01211\" y=\"221.151108\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"138.485201\" xlink:href=\"#m09ebc01211\" y=\"190.231217\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"109.290892\" xlink:href=\"#m09ebc01211\" y=\"215.763894\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"124.870252\" xlink:href=\"#m09ebc01211\" y=\"201.633751\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"251.166964\" xlink:href=\"#m09ebc01211\" y=\"79.24018\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"87.93872\" xlink:href=\"#m09ebc01211\" y=\"240.308847\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"70.84886\" xlink:href=\"#m09ebc01211\" y=\"256.830311\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"78.812564\" xlink:href=\"#m09ebc01211\" y=\"248.654486\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"85.301612\" xlink:href=\"#m09ebc01211\" y=\"241.196657\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"128.348369\" xlink:href=\"#m09ebc01211\" y=\"202.636189\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"187.094689\" xlink:href=\"#m09ebc01211\" y=\"145.083127\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"140.287788\" xlink:href=\"#m09ebc01211\" y=\"185.635959\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"137.808372\" xlink:href=\"#m09ebc01211\" y=\"193.859554\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"108.556914\" xlink:href=\"#m09ebc01211\" y=\"218.670024\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"219.097598\" xlink:href=\"#m09ebc01211\" y=\"114.333232\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"149.788605\" xlink:href=\"#m09ebc01211\" y=\"177.443141\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"237.975298\" xlink:href=\"#m09ebc01211\" y=\"91.405864\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"154.049854\" xlink:href=\"#m09ebc01211\" y=\"176.096708\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"174.282378\" xlink:href=\"#m09ebc01211\" y=\"153.880912\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"125.055702\" xlink:href=\"#m09ebc01211\" y=\"204.358042\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"240.469825\" xlink:href=\"#m09ebc01211\" y=\"90.865738\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"74.114404\" xlink:href=\"#m09ebc01211\" y=\"254.831215\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"139.126754\" xlink:href=\"#m09ebc01211\" y=\"187.975356\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"132.84358\" xlink:href=\"#m09ebc01211\" y=\"193.063245\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"155.933071\" xlink:href=\"#m09ebc01211\" y=\"172.371587\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"142.003827\" xlink:href=\"#m09ebc01211\" y=\"186.683352\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"192.476518\" xlink:href=\"#m09ebc01211\" y=\"133.840441\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"90.572418\" xlink:href=\"#m09ebc01211\" y=\"239.511747\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"116.872519\" xlink:href=\"#m09ebc01211\" y=\"209.833058\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"162.623916\" xlink:href=\"#m09ebc01211\" y=\"204.198747\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"83.056369\" xlink:href=\"#m09ebc01211\" y=\"243.946159\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"73.606408\" xlink:href=\"#m09ebc01211\" y=\"255.053444\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"266.165211\" xlink:href=\"#m09ebc01211\" y=\"67.578319\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"233.123195\" xlink:href=\"#m09ebc01211\" y=\"99.667645\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"141.681352\" xlink:href=\"#m09ebc01211\" y=\"185.577201\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"205.497545\" xlink:href=\"#m09ebc01211\" y=\"125.837809\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"165.821011\" xlink:href=\"#m09ebc01211\" y=\"170.711297\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"116.308224\" xlink:href=\"#m09ebc01211\" y=\"210.124163\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"197.619802\" xlink:href=\"#m09ebc01211\" y=\"136.027799\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"230.916852\" xlink:href=\"#m09ebc01211\" y=\"101.559632\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"105.144246\" xlink:href=\"#m09ebc01211\" y=\"222.868304\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"96.032069\" xlink:href=\"#m09ebc01211\" y=\"230.448737\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"148.907824\" xlink:href=\"#m09ebc01211\" y=\"182.448669\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"217.91996\" xlink:href=\"#m09ebc01211\" y=\"104.111995\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"201.149362\" xlink:href=\"#m09ebc01211\" y=\"129.980313\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"205.785296\" xlink:href=\"#m09ebc01211\" y=\"124.134577\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"72.064366\" xlink:href=\"#m09ebc01211\" y=\"255.842554\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"219.383037\" xlink:href=\"#m09ebc01211\" y=\"113.549385\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"142.965453\" xlink:href=\"#m09ebc01211\" y=\"188.889817\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"150.337192\" xlink:href=\"#m09ebc01211\" y=\"180.927577\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"152.506258\" xlink:href=\"#m09ebc01211\" y=\"176.525791\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"92.419938\" xlink:href=\"#m09ebc01211\" y=\"237.946834\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"229.718039\" xlink:href=\"#m09ebc01211\" y=\"104.708497\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"167.871676\" xlink:href=\"#m09ebc01211\" y=\"162.080051\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"190.580532\" xlink:href=\"#m09ebc01211\" y=\"138.526014\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"188.475378\" xlink:href=\"#m09ebc01211\" y=\"139.947194\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"207.881963\" xlink:href=\"#m09ebc01211\" y=\"121.929547\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"91.78499\" xlink:href=\"#m09ebc01211\" y=\"236.010694\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"115.116079\" xlink:href=\"#m09ebc01211\" y=\"214.396352\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"167.258633\" xlink:href=\"#m09ebc01211\" y=\"162.196923\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"158.718741\" xlink:href=\"#m09ebc01211\" y=\"174.13382\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"136.693959\" xlink:href=\"#m09ebc01211\" y=\"190.00316\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"160.930913\" xlink:href=\"#m09ebc01211\" y=\"163.798351\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"262.31861\" xlink:href=\"#m09ebc01211\" y=\"62.625925\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"80.288986\" xlink:href=\"#m09ebc01211\" y=\"246.604291\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"159.527844\" xlink:href=\"#m09ebc01211\" y=\"169.589467\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"114.355261\" xlink:href=\"#m09ebc01211\" y=\"213.746557\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"193.998772\" xlink:href=\"#m09ebc01211\" y=\"137.885211\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"157.641905\" xlink:href=\"#m09ebc01211\" y=\"171.061341\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"77.560663\" xlink:href=\"#m09ebc01211\" y=\"249.980826\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"174.607305\" xlink:href=\"#m09ebc01211\" y=\"154.894168\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"179.867933\" xlink:href=\"#m09ebc01211\" y=\"153.728309\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"76.674121\" xlink:href=\"#m09ebc01211\" y=\"252.269231\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"173.907509\" xlink:href=\"#m09ebc01211\" y=\"157.328105\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"163.275606\" xlink:href=\"#m09ebc01211\" y=\"168.224513\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"100.138503\" xlink:href=\"#m09ebc01211\" y=\"226.883749\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"104.162916\" xlink:href=\"#m09ebc01211\" y=\"222.558343\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"150.900432\" xlink:href=\"#m09ebc01211\" y=\"178.576176\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"247.394944\" xlink:href=\"#m09ebc01211\" y=\"79.945145\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"252.550907\" xlink:href=\"#m09ebc01211\" y=\"80.990453\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"171.890032\" xlink:href=\"#m09ebc01211\" y=\"159.066256\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"194.397239\" xlink:href=\"#m09ebc01211\" y=\"139.729532\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"112.525825\" xlink:href=\"#m09ebc01211\" y=\"215.161588\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"91.123984\" xlink:href=\"#m09ebc01211\" y=\"236.699025\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"107.70783\" xlink:href=\"#m09ebc01211\" y=\"220.120668\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"183.281074\" xlink:href=\"#m09ebc01211\" y=\"153.94781\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"158.396478\" xlink:href=\"#m09ebc01211\" y=\"167.809845\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"93.501541\" xlink:href=\"#m09ebc01211\" y=\"234.257324\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"92.428871\" xlink:href=\"#m09ebc01211\" y=\"234.831512\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"124.509854\" xlink:href=\"#m09ebc01211\" y=\"203.352214\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"201.497228\" xlink:href=\"#m09ebc01211\" y=\"127.115541\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"168.295863\" xlink:href=\"#m09ebc01211\" y=\"160.046211\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"139.416869\" xlink:href=\"#m09ebc01211\" y=\"188.639769\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"207.287797\" xlink:href=\"#m09ebc01211\" y=\"122.848441\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"198.568304\" xlink:href=\"#m09ebc01211\" y=\"133.305613\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"253.019025\" xlink:href=\"#m09ebc01211\" y=\"76.209501\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"90.325349\" xlink:href=\"#m09ebc01211\" y=\"236.910972\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"176.82924\" xlink:href=\"#m09ebc01211\" y=\"152.745248\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"111.868085\" xlink:href=\"#m09ebc01211\" y=\"215.461737\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"172.408061\" xlink:href=\"#m09ebc01211\" y=\"151.526694\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"149.743841\" xlink:href=\"#m09ebc01211\" y=\"177.586355\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"197.763381\" xlink:href=\"#m09ebc01211\" y=\"131.916305\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"101.009667\" xlink:href=\"#m09ebc01211\" y=\"226.745462\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"102.073974\" xlink:href=\"#m09ebc01211\" y=\"225.772007\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"178.552203\" xlink:href=\"#m09ebc01211\" y=\"146.128727\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"293.257152\" xlink:href=\"#m09ebc01211\" y=\"43.13279\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"151.939906\" xlink:href=\"#m09ebc01211\" y=\"175.637778\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"126.428897\" xlink:href=\"#m09ebc01211\" y=\"201.076516\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"140.198117\" xlink:href=\"#m09ebc01211\" y=\"189.640339\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"127.358672\" xlink:href=\"#m09ebc01211\" y=\"203.691522\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"133.416578\" xlink:href=\"#m09ebc01211\" y=\"193.790594\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"217.097841\" xlink:href=\"#m09ebc01211\" y=\"113.536769\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"129.122547\" xlink:href=\"#m09ebc01211\" y=\"197.954249\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"154.586303\" xlink:href=\"#m09ebc01211\" y=\"172.124689\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"166.050632\" xlink:href=\"#m09ebc01211\" y=\"163.542745\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"139.789333\" xlink:href=\"#m09ebc01211\" y=\"188.976561\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"146.102893\" xlink:href=\"#m09ebc01211\" y=\"182.47642\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"131.450321\" xlink:href=\"#m09ebc01211\" y=\"195.474321\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"106.888367\" xlink:href=\"#m09ebc01211\" y=\"219.399943\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"95.388523\" xlink:href=\"#m09ebc01211\" y=\"231.253788\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"168.41054\" xlink:href=\"#m09ebc01211\" y=\"160.99378\"/>\n",
       "     <use style=\"fill:#0000ff;fill-opacity:0.5;stroke:#0000ff;stroke-opacity:0.5;\" x=\"84.490229\" xlink:href=\"#m09ebc01211\" y=\"243.562706\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path clip-path=\"url(#pd85fa1285b)\" d=\"M 46.965625 279 \n",
       "L 46.965625 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"mbb1f8598c1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mbb1f8598c1\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(43.784375 293.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path clip-path=\"url(#pd85fa1285b)\" d=\"M 97.692898 279 \n",
       "L 97.692898 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"97.692898\" xlink:href=\"#mbb1f8598c1\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(91.330398 293.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path clip-path=\"url(#pd85fa1285b)\" d=\"M 148.42017 279 \n",
       "L 148.42017 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"148.42017\" xlink:href=\"#mbb1f8598c1\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <defs>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(142.05767 293.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path clip-path=\"url(#pd85fa1285b)\" d=\"M 199.147443 279 \n",
       "L 199.147443 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"199.147443\" xlink:href=\"#mbb1f8598c1\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(192.784943 293.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path clip-path=\"url(#pd85fa1285b)\" d=\"M 249.874716 279 \n",
       "L 249.874716 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"249.874716\" xlink:href=\"#mbb1f8598c1\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(243.512216 293.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path clip-path=\"url(#pd85fa1285b)\" d=\"M 300.601989 279 \n",
       "L 300.601989 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"300.601989\" xlink:href=\"#mbb1f8598c1\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 100 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(291.058239 293.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Observed RT (Minute) -->\n",
       "     <defs>\n",
       "      <path d=\"M 39.40625 66.21875 \n",
       "Q 28.65625 66.21875 22.328125 58.203125 \n",
       "Q 16.015625 50.203125 16.015625 36.375 \n",
       "Q 16.015625 22.609375 22.328125 14.59375 \n",
       "Q 28.65625 6.59375 39.40625 6.59375 \n",
       "Q 50.140625 6.59375 56.421875 14.59375 \n",
       "Q 62.703125 22.609375 62.703125 36.375 \n",
       "Q 62.703125 50.203125 56.421875 58.203125 \n",
       "Q 50.140625 66.21875 39.40625 66.21875 \n",
       "z\n",
       "M 39.40625 74.21875 \n",
       "Q 54.734375 74.21875 63.90625 63.9375 \n",
       "Q 73.09375 53.65625 73.09375 36.375 \n",
       "Q 73.09375 19.140625 63.90625 8.859375 \n",
       "Q 54.734375 -1.421875 39.40625 -1.421875 \n",
       "Q 24.03125 -1.421875 14.8125 8.828125 \n",
       "Q 5.609375 19.09375 5.609375 36.375 \n",
       "Q 5.609375 53.65625 14.8125 63.9375 \n",
       "Q 24.03125 74.21875 39.40625 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-79\"/>\n",
       "      <path d=\"M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "M 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "z\n",
       "\" id=\"DejaVuSans-98\"/>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "      <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "      <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "      <path d=\"M 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 8.796875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "L 35.6875 0 \n",
       "L 23.484375 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-118\"/>\n",
       "      <path d=\"M 45.40625 46.390625 \n",
       "L 45.40625 75.984375 \n",
       "L 54.390625 75.984375 \n",
       "L 54.390625 0 \n",
       "L 45.40625 0 \n",
       "L 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "z\n",
       "M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-100\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "      <path d=\"M 44.390625 34.1875 \n",
       "Q 47.5625 33.109375 50.5625 29.59375 \n",
       "Q 53.5625 26.078125 56.59375 19.921875 \n",
       "L 66.609375 0 \n",
       "L 56 0 \n",
       "L 46.6875 18.703125 \n",
       "Q 43.0625 26.03125 39.671875 28.421875 \n",
       "Q 36.28125 30.8125 30.421875 30.8125 \n",
       "L 19.671875 30.8125 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "L 9.8125 72.90625 \n",
       "L 32.078125 72.90625 \n",
       "Q 44.578125 72.90625 50.734375 67.671875 \n",
       "Q 56.890625 62.453125 56.890625 51.90625 \n",
       "Q 56.890625 45.015625 53.6875 40.46875 \n",
       "Q 50.484375 35.9375 44.390625 34.1875 \n",
       "z\n",
       "M 19.671875 64.796875 \n",
       "L 19.671875 38.921875 \n",
       "L 32.078125 38.921875 \n",
       "Q 39.203125 38.921875 42.84375 42.21875 \n",
       "Q 46.484375 45.515625 46.484375 51.90625 \n",
       "Q 46.484375 58.296875 42.84375 61.546875 \n",
       "Q 39.203125 64.796875 32.078125 64.796875 \n",
       "z\n",
       "\" id=\"DejaVuSans-82\"/>\n",
       "      <path d=\"M -0.296875 72.90625 \n",
       "L 61.375 72.90625 \n",
       "L 61.375 64.59375 \n",
       "L 35.5 64.59375 \n",
       "L 35.5 0 \n",
       "L 25.59375 0 \n",
       "L 25.59375 64.59375 \n",
       "L -0.296875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-84\"/>\n",
       "      <path d=\"M 31 75.875 \n",
       "Q 24.46875 64.65625 21.28125 53.65625 \n",
       "Q 18.109375 42.671875 18.109375 31.390625 \n",
       "Q 18.109375 20.125 21.3125 9.0625 \n",
       "Q 24.515625 -2 31 -13.1875 \n",
       "L 23.1875 -13.1875 \n",
       "Q 15.875 -1.703125 12.234375 9.375 \n",
       "Q 8.59375 20.453125 8.59375 31.390625 \n",
       "Q 8.59375 42.28125 12.203125 53.3125 \n",
       "Q 15.828125 64.359375 23.1875 75.875 \n",
       "z\n",
       "\" id=\"DejaVuSans-40\"/>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 24.515625 72.90625 \n",
       "L 43.109375 23.296875 \n",
       "L 61.8125 72.90625 \n",
       "L 76.515625 72.90625 \n",
       "L 76.515625 0 \n",
       "L 66.890625 0 \n",
       "L 66.890625 64.015625 \n",
       "L 48.09375 14.015625 \n",
       "L 38.1875 14.015625 \n",
       "L 19.390625 64.015625 \n",
       "L 19.390625 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-77\"/>\n",
       "      <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "      <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-117\"/>\n",
       "      <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "      <path d=\"M 8.015625 75.875 \n",
       "L 15.828125 75.875 \n",
       "Q 23.140625 64.359375 26.78125 53.3125 \n",
       "Q 30.421875 42.28125 30.421875 31.390625 \n",
       "Q 30.421875 20.453125 26.78125 9.375 \n",
       "Q 23.140625 -1.703125 15.828125 -13.1875 \n",
       "L 8.015625 -13.1875 \n",
       "Q 14.5 -2 17.703125 9.0625 \n",
       "Q 20.90625 20.125 20.90625 31.390625 \n",
       "Q 20.90625 42.671875 17.703125 53.65625 \n",
       "Q 14.5 64.65625 8.015625 75.875 \n",
       "z\n",
       "\" id=\"DejaVuSans-41\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(131.728906 307.276562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-79\"/>\n",
       "      <use x=\"78.710938\" xlink:href=\"#DejaVuSans-98\"/>\n",
       "      <use x=\"142.1875\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"194.287109\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"255.810547\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"296.923828\" xlink:href=\"#DejaVuSans-118\"/>\n",
       "      <use x=\"356.103516\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"417.626953\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"481.103516\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"512.890625\" xlink:href=\"#DejaVuSans-82\"/>\n",
       "      <use x=\"582.263672\" xlink:href=\"#DejaVuSans-84\"/>\n",
       "      <use x=\"643.347656\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"675.134766\" xlink:href=\"#DejaVuSans-40\"/>\n",
       "      <use x=\"714.148438\" xlink:href=\"#DejaVuSans-77\"/>\n",
       "      <use x=\"800.427734\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"828.210938\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"891.589844\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "      <use x=\"954.96875\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"994.177734\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"1055.701172\" xlink:href=\"#DejaVuSans-41\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path clip-path=\"url(#pd85fa1285b)\" d=\"M 46.965625 279 \n",
       "L 325.965625 279 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m6c159ffc6b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m6c159ffc6b\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(33.603125 282.799219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path clip-path=\"url(#pd85fa1285b)\" d=\"M 46.965625 229.581818 \n",
       "L 325.965625 229.581818 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m6c159ffc6b\" y=\"229.581818\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(27.240625 233.381037)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path clip-path=\"url(#pd85fa1285b)\" d=\"M 46.965625 180.163636 \n",
       "L 325.965625 180.163636 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m6c159ffc6b\" y=\"180.163636\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(27.240625 183.962855)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path clip-path=\"url(#pd85fa1285b)\" d=\"M 46.965625 130.745455 \n",
       "L 325.965625 130.745455 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m6c159ffc6b\" y=\"130.745455\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(27.240625 134.544673)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path clip-path=\"url(#pd85fa1285b)\" d=\"M 46.965625 81.327273 \n",
       "L 325.965625 81.327273 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m6c159ffc6b\" y=\"81.327273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(27.240625 85.126491)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path clip-path=\"url(#pd85fa1285b)\" d=\"M 46.965625 31.909091 \n",
       "L 325.965625 31.909091 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m6c159ffc6b\" y=\"31.909091\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(20.878125 35.70831)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- Predicted RT (Minute) -->\n",
       "     <defs>\n",
       "      <path d=\"M 19.671875 64.796875 \n",
       "L 19.671875 37.40625 \n",
       "L 32.078125 37.40625 \n",
       "Q 38.96875 37.40625 42.71875 40.96875 \n",
       "Q 46.484375 44.53125 46.484375 51.125 \n",
       "Q 46.484375 57.671875 42.71875 61.234375 \n",
       "Q 38.96875 64.796875 32.078125 64.796875 \n",
       "z\n",
       "M 9.8125 72.90625 \n",
       "L 32.078125 72.90625 \n",
       "Q 44.34375 72.90625 50.609375 67.359375 \n",
       "Q 56.890625 61.8125 56.890625 51.125 \n",
       "Q 56.890625 40.328125 50.609375 34.8125 \n",
       "Q 44.34375 29.296875 32.078125 29.296875 \n",
       "L 19.671875 29.296875 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-80\"/>\n",
       "      <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(14.798438 197.447656)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-80\"/>\n",
       "      <use x=\"60.287109\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"101.369141\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"162.892578\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"226.369141\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"254.152344\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"309.132812\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"348.341797\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"409.865234\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"473.341797\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"505.128906\" xlink:href=\"#DejaVuSans-82\"/>\n",
       "      <use x=\"574.501953\" xlink:href=\"#DejaVuSans-84\"/>\n",
       "      <use x=\"635.585938\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"667.373047\" xlink:href=\"#DejaVuSans-40\"/>\n",
       "      <use x=\"706.386719\" xlink:href=\"#DejaVuSans-77\"/>\n",
       "      <use x=\"792.666016\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"820.449219\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"883.828125\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "      <use x=\"947.207031\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"986.416016\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"1047.939453\" xlink:href=\"#DejaVuSans-41\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_25\">\n",
       "    <path clip-path=\"url(#pd85fa1285b)\" d=\"M 46.965625 279 \n",
       "L 325.965625 7.2 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 46.965625 279 \n",
       "L 46.965625 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 325.965625 279 \n",
       "L 325.965625 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 46.965625 279 \n",
       "L 325.965625 279 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 46.965625 7.2 \n",
       "L 325.965625 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <!-- MAE=0.88 minute -->\n",
       "    <defs>\n",
       "     <path d=\"M 34.1875 63.1875 \n",
       "L 20.796875 26.90625 \n",
       "L 47.609375 26.90625 \n",
       "z\n",
       "M 28.609375 72.90625 \n",
       "L 39.796875 72.90625 \n",
       "L 67.578125 0 \n",
       "L 57.328125 0 \n",
       "L 50.6875 18.703125 \n",
       "L 17.828125 18.703125 \n",
       "L 11.1875 0 \n",
       "L 0.78125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-65\"/>\n",
       "     <path d=\"M 9.8125 72.90625 \n",
       "L 55.90625 72.90625 \n",
       "L 55.90625 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.015625 \n",
       "L 54.390625 43.015625 \n",
       "L 54.390625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 8.296875 \n",
       "L 56.78125 8.296875 \n",
       "L 56.78125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-69\"/>\n",
       "     <path d=\"M 10.59375 45.40625 \n",
       "L 73.1875 45.40625 \n",
       "L 73.1875 37.203125 \n",
       "L 10.59375 37.203125 \n",
       "z\n",
       "M 10.59375 25.484375 \n",
       "L 73.1875 25.484375 \n",
       "L 73.1875 17.1875 \n",
       "L 10.59375 17.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-61\"/>\n",
       "     <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "     <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(59.647443 34.222557)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#DejaVuSans-77\"/>\n",
       "     <use x=\"86.279297\" xlink:href=\"#DejaVuSans-65\"/>\n",
       "     <use x=\"154.6875\" xlink:href=\"#DejaVuSans-69\"/>\n",
       "     <use x=\"217.871094\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "     <use x=\"301.660156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "     <use x=\"365.283203\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "     <use x=\"397.070312\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "     <use x=\"460.693359\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "     <use x=\"524.316406\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"556.103516\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "     <use x=\"653.515625\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "     <use x=\"681.298828\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     <use x=\"744.677734\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"808.056641\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "     <use x=\"847.265625\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "    </g>\n",
       "    <!-- $R^2$=0.9942 -->\n",
       "    <defs>\n",
       "     <path d=\"M 25.203125 64.796875 \n",
       "L 20.21875 38.921875 \n",
       "L 32.90625 38.921875 \n",
       "Q 40.375 38.921875 44.984375 43.046875 \n",
       "Q 49.609375 47.171875 49.609375 53.8125 \n",
       "Q 49.609375 59.125 46.5 61.953125 \n",
       "Q 43.40625 64.796875 37.59375 64.796875 \n",
       "z\n",
       "M 43.3125 35.015625 \n",
       "Q 46.4375 34.28125 48.515625 31.390625 \n",
       "Q 50.59375 28.515625 53.328125 19.921875 \n",
       "L 59.515625 0 \n",
       "L 49.125 0 \n",
       "L 43.40625 18.703125 \n",
       "Q 41.21875 25.921875 38.328125 28.359375 \n",
       "Q 35.453125 30.8125 29.5 30.8125 \n",
       "L 18.609375 30.8125 \n",
       "L 12.59375 0 \n",
       "L 2.6875 0 \n",
       "L 16.890625 72.90625 \n",
       "L 39.109375 72.90625 \n",
       "Q 49.21875 72.90625 54.609375 68.328125 \n",
       "Q 60.015625 63.765625 60.015625 55.171875 \n",
       "Q 60.015625 47.5625 55.421875 41.984375 \n",
       "Q 50.828125 36.421875 43.3125 35.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-Oblique-82\"/>\n",
       "     <path d=\"M 10.984375 1.515625 \n",
       "L 10.984375 10.5 \n",
       "Q 14.703125 8.734375 18.5 7.8125 \n",
       "Q 22.3125 6.890625 25.984375 6.890625 \n",
       "Q 35.75 6.890625 40.890625 13.453125 \n",
       "Q 46.046875 20.015625 46.78125 33.40625 \n",
       "Q 43.953125 29.203125 39.59375 26.953125 \n",
       "Q 35.25 24.703125 29.984375 24.703125 \n",
       "Q 19.046875 24.703125 12.671875 31.3125 \n",
       "Q 6.296875 37.9375 6.296875 49.421875 \n",
       "Q 6.296875 60.640625 12.9375 67.421875 \n",
       "Q 19.578125 74.21875 30.609375 74.21875 \n",
       "Q 43.265625 74.21875 49.921875 64.515625 \n",
       "Q 56.59375 54.828125 56.59375 36.375 \n",
       "Q 56.59375 19.140625 48.40625 8.859375 \n",
       "Q 40.234375 -1.421875 26.421875 -1.421875 \n",
       "Q 22.703125 -1.421875 18.890625 -0.6875 \n",
       "Q 15.09375 0.046875 10.984375 1.515625 \n",
       "z\n",
       "M 30.609375 32.421875 \n",
       "Q 37.25 32.421875 41.125 36.953125 \n",
       "Q 45.015625 41.5 45.015625 49.421875 \n",
       "Q 45.015625 57.28125 41.125 61.84375 \n",
       "Q 37.25 66.40625 30.609375 66.40625 \n",
       "Q 23.96875 66.40625 20.09375 61.84375 \n",
       "Q 16.21875 57.28125 16.21875 49.421875 \n",
       "Q 16.21875 41.5 20.09375 36.953125 \n",
       "Q 23.96875 32.421875 30.609375 32.421875 \n",
       "z\n",
       "\" id=\"DejaVuSans-57\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(59.647443 45.420369)scale(0.1 -0.1)\">\n",
       "     <use transform=\"translate(0 0.765625)\" xlink:href=\"#DejaVuSans-Oblique-82\"/>\n",
       "     <use transform=\"translate(76.499193 39.046875)scale(0.7)\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "     <use transform=\"translate(123.769701 0.765625)\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "     <use transform=\"translate(207.558763 0.765625)\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "     <use transform=\"translate(271.18181 0.765625)\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "     <use transform=\"translate(302.968919 0.765625)\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "     <use transform=\"translate(366.591966 0.765625)\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "     <use transform=\"translate(430.215013 0.765625)\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "     <use transform=\"translate(493.83806 0.765625)\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "    </g>\n",
       "    <!-- N=572 -->\n",
       "    <defs>\n",
       "     <path d=\"M 9.8125 72.90625 \n",
       "L 23.09375 72.90625 \n",
       "L 55.421875 11.921875 \n",
       "L 55.421875 72.90625 \n",
       "L 64.984375 72.90625 \n",
       "L 64.984375 0 \n",
       "L 51.703125 0 \n",
       "L 19.390625 60.984375 \n",
       "L 19.390625 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-78\"/>\n",
       "     <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "     <path d=\"M 8.203125 72.90625 \n",
       "L 55.078125 72.90625 \n",
       "L 55.078125 68.703125 \n",
       "L 28.609375 0 \n",
       "L 18.3125 0 \n",
       "L 43.21875 64.59375 \n",
       "L 8.203125 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-55\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(59.647443 56.618182)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#DejaVuSans-78\"/>\n",
       "     <use x=\"74.804688\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "     <use x=\"222.216797\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "     <use x=\"285.839844\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pd85fa1285b\">\n",
       "   <rect height=\"271.8\" width=\"279\" x=\"46.965625\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 750x750 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "pred_data = pd.read_csv(\"tf_prediction/test.tsv\",sep=\"\\t\")\n",
    "pred_data.head()\n",
    "\n",
    "cor = scipy.stats.pearsonr(pred_data['y'], pred_data['y_pred'])[0]\n",
    "mae = sklearn.metrics.mean_absolute_error(pred_data['y'], pred_data['y_pred'])\n",
    "r2 = sklearn.metrics.r2_score(pred_data['y'], pred_data['y_pred'])\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.scatter(pred_data['y'], pred_data['y_pred'],s=4, c=\"blue\", alpha=0.5)\n",
    "plt.text(5, 90, \"MAE=\"+\"{:.2f}\".format(mae)+\" minute\\n$R^2$=\"+\"{:.4f}\".format(r2)+\"\\nN=\"+str(pred_data.shape[0]))\n",
    "plt.plot( [0,110],[0,110] )\n",
    "plt.xlabel('Observed RT (Minute)')\n",
    "plt.ylabel('Predicted RT (Minute)')\n",
    "plt.xlim(0,110)\n",
    "plt.ylim(0,110)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autort",
   "language": "python",
   "name": "autort"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
